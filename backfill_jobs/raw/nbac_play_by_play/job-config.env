# File: backfill_jobs/raw/nbac_play_by_play/job-config.env
# Description: Cloud Run job configuration for NBA.com play-by-play processor backfill

# CRITICAL: Use unique name - add "processor" to distinguish from scraper jobs
JOB_NAME="nbac-play-by-play-processor-backfill"
JOB_SCRIPT="backfill_jobs/raw/nbac_play_by_play/nbac_play_by_play_raw_backfill.py"
JOB_DESCRIPTION="Process NBA.com play-by-play data from GCS to BigQuery"

# Resources (play-by-play data is large with 500-800 events per game)
TASK_TIMEOUT="3600"  # 1 hour for large batches
MEMORY="8Gi"         # Increased memory for processing large JSON files
CPU="4"              # More CPU for JSON parsing and BigQuery operations

# Default date ranges
START_DATE="2021-10-01"  # Start of 2021-22 NBA season
END_DATE="2025-06-30"    # End of 2024-25 NBA season
BUCKET_NAME="nba-scraped-data"

# Processing specific
DEFAULT_LIMIT="100"      # Default file limit for testing