# backfill_jobs/raw/bdl_active_players/job-config.env
# CRITICAL: Use unique name - add "processor" to distinguish from scraper jobs
JOB_NAME="bdl-active-players-processor-backfill"  # NOT "bdl-active-players-backfill"
JOB_SCRIPT="backfill_jobs/raw/bdl_active_players/bdl_active_players_raw_backfill.py"
JOB_DESCRIPTION="Process Ball Don't Lie Active Players data from GCS to BigQuery with NBA.com validation"

# Resources - Current-state data with validation, moderate processing
TASK_TIMEOUT="1800"  # 30 minutes (validation queries add overhead)
MEMORY="4Gi"         # Need memory for NBA.com player lookup data
CPU="2"

# Date defaults - Focus on recent data since this is current-state validation
START_DATE="2024-10-01"  # Current NBA season start
END_DATE="2025-06-30"    # Through playoffs
BUCKET_NAME="nba-scraped-data"

# Processing notes:
# - Uses MERGE_UPDATE strategy (replaces all data each run)
# - Includes validation against NBA.com player list 
# - Takes latest file per date (current-state data)
# - ~500 players per file, validation adds processing time