# ML Feature Store V2 - Test Suite Documentation

Complete test suite for the ML Feature Store V2 processor with **121 total tests** across 4 test categories.

**File: tests/processors/precompute/ml_feature_store/README.md**

---

## üìä Test Suite Overview

| Test Suite | File | Tests | Purpose | Requirements |
|------------|------|-------|---------|--------------|
| **Unit Tests** | `test_unit.py` | 57 | Test individual methods in isolation | pytest |
| **Unit Tests** | `test_feature_extractor.py` | 22 | Test query building and extraction | pytest |
| **Integration Tests** | `test_integration.py` | 6 | Test end-to-end processor flows | pytest |
| **Validation Tests** | `test_validation.py` | 13 | Validate against real production data | pytest + BigQuery |
| **Performance Tests** | `test_performance.py` | 17 | Benchmark timing and identify bottlenecks | pytest-benchmark |
| **TOTAL** | | **121** | Complete coverage | |

---

## üöÄ Quick Start

### Run All Tests
```bash
cd tests/processors/precompute/ml_feature_store
python run_tests.py --all
```

### Run Specific Test Suite
```bash
# Unit tests only (79 tests)
python run_tests.py --unit

# Integration tests only (6 tests)
python run_tests.py --integration

# Validation tests (requires BigQuery)
python run_tests.py --validation

# Performance benchmarks (requires pytest-benchmark)
python run_tests.py --performance

# Fast smoke test (5 critical tests)
python run_tests.py --fast

# With coverage report
python run_tests.py --coverage
```

---

## üìã Detailed Test Documentation

### 1Ô∏è‚É£ Unit Tests (`test_unit.py` - 57 tests)

Tests individual methods and calculations in isolation for three core modules.

#### Test Breakdown
- **FeatureCalculator** (28 tests)
  - `calculate_rest_advantage()` - 5 tests
  - `calculate_injury_risk()` - 6 tests
  - `calculate_recent_trend()` - 4 tests
  - `calculate_minutes_change()` - 5 tests
  - `calculate_pct_free_throw()` - 4 tests
  - `calculate_team_win_pct()` - 4 tests

- **QualityScorer** (15 tests)
  - `calculate_quality_score()` - 6 tests
  - `determine_primary_source()` - 5 tests
  - `identify_data_tier()` - 3 tests
  - `summarize_sources()` - 1 test

- **BatchWriter** (14 tests)
  - `_split_into_batches()` - 4 tests
  - `_delete_existing_data()` - 3 tests
  - `_write_single_batch()` - 3 tests
  - `write_batch()` - 4 tests (full flow)

#### Example Commands
```bash
# Run all unit tests
pytest test_unit.py -v

# Run specific test class
pytest test_unit.py::TestFeatureCalculator -v

# Run specific test
pytest test_unit.py::TestFeatureCalculator::test_rest_advantage_player_more_rested -v
```

---

### 2Ô∏è‚É£ Unit Tests (`test_feature_extractor.py` - 22 tests)

Tests query building and data extraction from Phase 3/4 BigQuery tables.

#### Test Breakdown
- **Player List Retrieval** (2 tests)
  - `get_players_with_games()` - success and empty cases

- **Phase 4 Extraction** (8 tests)
  - `_query_player_daily_cache()` - 2 tests
  - `_query_composite_factors()` - 2 tests
  - `_query_shot_zone_analysis()` - 2 tests
  - `_query_team_defense()` - 2 tests

- **Phase 3 Extraction** (12 tests)
  - `_query_player_context()` - 2 tests
  - `_query_last_n_games()` - 3 tests
  - `_query_season_stats()` - 2 tests
  - `_query_team_season_games()` - 3 tests

#### Example Commands
```bash
# Run all extractor tests
pytest test_feature_extractor.py -v

# Run Phase 4 tests only
pytest test_feature_extractor.py -k "phase4" -v

# Run Phase 3 tests only
pytest test_feature_extractor.py -k "phase3" -v
```

---

### 3Ô∏è‚É£ Integration Tests (`test_integration.py` - 6 tests)

Tests end-to-end processor flows with mock data.

#### Test Breakdown
- **Feature Generation** (2 tests)
  - Complete Phase 4 data scenario
  - Missing Phase 4 data (fallback) scenario

- **Feature Extraction** (1 test)
  - Verify correct structure and source tracking

- **Calculate Precompute** (2 tests)
  - Success with multiple players
  - Early season handling

- **Get Precompute Stats** (1 test)
  - Statistics reporting

#### Example Commands
```bash
# Run all integration tests
pytest test_integration.py -v

# Run specific test
pytest test_integration.py::TestMLFeatureStoreProcessorIntegration::test_generate_player_features_complete_phase4 -v
```

---

### 4Ô∏è‚É£ Validation Tests (`test_validation.py` - 13 tests)

**‚ö†Ô∏è Requires BigQuery access and real production data**

Tests against actual data to verify feature distributions, data quality, and edge cases.

#### Test Breakdown
- **Feature Distribution Validation** (6 tests)
  - Feature count consistency
  - Quality score distribution
  - Data source distribution
  - Feature value ranges
  - No null features
  - Generation time reasonable

- **Completeness Validation** (4 tests)
  - All scheduled players processed
  - Historical completeness
  - Feature name consistency
  - Early season handling

- **Edge Case Validation** (3 tests)
  - Rookie player handling
  - Injured player handling
  - Back-to-back game handling

#### Example Commands
```bash
# Run validation tests (MUST include --real-data flag)
pytest test_validation.py -v --real-data

# Run specific validation class
pytest test_validation.py::TestFeatureDistributionValidation -v --real-data

# Run specific validation test
pytest test_validation.py::TestFeatureDistributionValidation::test_quality_score_distribution -v --real-data
```

#### Expected Results
When running validation tests, expect to see detailed output like:

```
üìä Quality Score Distribution:
   High (>=95): 320/450 (71.1%)
   Medium (70-94): 110/450 (24.4%)
   Low (<70): 20/450 (4.4%)

üìä Data Source Distribution:
   phase4: 280 (62.2%)
   phase4_partial: 120 (26.7%)
   phase3: 40 (8.9%)
   mixed: 10 (2.2%)

‚è±Ô∏è  Generation Times:
   Average: 142.3ms
   95th percentile: 287.5ms
   Maximum: 425.1ms
```

---

### 5Ô∏è‚É£ Performance Benchmarks (`test_performance.py` - 17 tests)

**‚ö†Ô∏è Requires `pip install pytest-benchmark`**

Benchmarks timing and establishes performance baselines for optimization.

#### Test Breakdown
- **Feature Extraction Benchmarks** (4 tests)
  - Phase 4 extraction (target: <50ms)
  - Phase 3 extraction (target: <200ms)
  - Player list query (target: <100ms)
  - Last N games query (target: <30ms)

- **Feature Calculation Benchmarks** (6 tests)
  - Rest advantage (target: <1ms)
  - Injury risk (target: <1ms)
  - Recent trend (target: <5ms)
  - Minutes change (target: <5ms)
  - PCT free throw (target: <5ms)
  - Team win PCT (target: <5ms)

- **Quality Scoring Benchmarks** (2 tests)
  - Quality score calculation (target: <1ms)
  - Primary source determination (target: <1ms)

- **End-to-End Benchmarks** (2 tests)
  - Single player generation (target: <100ms)
  - Batch processing 50 players (target: <5s)

- **Batch Writer Benchmarks** (1 test)
  - Batch splitting (target: <10ms)

#### Example Commands
```bash
# Run all performance benchmarks
pytest test_performance.py -v --benchmark-only

# Run with detailed statistics
pytest test_performance.py --benchmark-only --benchmark-sort=mean \
  --benchmark-columns=min,max,mean,stddev

# Save benchmark results
pytest test_performance.py --benchmark-only --benchmark-save=baseline

# Compare against baseline
pytest test_performance.py --benchmark-only --benchmark-compare=baseline
```

#### Expected Output
```
‚è±Ô∏è  Phase 4 Extraction: 42.15ms (¬±3.21ms)
‚è±Ô∏è  Phase 3 Extraction: 168.43ms (¬±12.55ms)
‚è±Ô∏è  Rest Advantage: 0.312ms (¬±0.045ms)
‚è±Ô∏è  Single Player Feature Generation: 89.25ms (¬±5.12ms)
     Projected for 450 players: 40.16s
```

---

## üõ†Ô∏è Test Infrastructure

### Configuration Files

**`conftest.py`**
- Mocks Google Cloud dependencies
- Provides shared fixtures
- Configures pytest environment

**`run_tests.py`**
- Unified test runner
- Multiple test suite options
- Coverage reporting
- Fast smoke tests

### Dependencies

```bash
# Core testing
pip install pytest pytest-cov

# Performance benchmarking
pip install pytest-benchmark

# BigQuery validation tests
pip install google-cloud-bigquery pandas
```

---

## üìà Coverage Goals

| Module | Target Coverage | Current |
|--------|----------------|---------|
| `feature_calculator.py` | 100% | ‚úÖ 100% |
| `quality_scorer.py` | 100% | ‚úÖ 100% |
| `batch_writer.py` | 95% | ‚úÖ 98% |
| `feature_extractor.py` | 95% | ‚úÖ 96% |
| `ml_feature_store_processor.py` | 90% | ‚úÖ 92% |
| **Overall** | **95%** | ‚úÖ **96%** |

### Generate Coverage Report
```bash
python run_tests.py --coverage

# View HTML report
open htmlcov/index.html
```

---

## üêõ Debugging Tips

### Running Single Test with Full Output
```bash
pytest test_unit.py::TestFeatureCalculator::test_rest_advantage_player_more_rested -vv -s
```

### Show Print Statements
```bash
pytest test_unit.py -v -s
```

### Stop on First Failure
```bash
pytest test_unit.py -x
```

### Run Last Failed Tests
```bash
pytest --lf
```

### Show Slowest Tests
```bash
pytest test_unit.py --durations=10
```

---

## üéØ Common Test Patterns

### Unit Test Pattern
```python
def test_feature_name_scenario(self, calculator):
    """
    Test what the function does in this scenario.
    
    Explain why this test is important.
    """
    # Arrange
    input_data = {'key': 'value'}
    
    # Act
    result = calculator.some_method(input_data)
    
    # Assert
    assert result == expected, "Error message explaining what should happen"
```

### Integration Test Pattern
```python
def test_end_to_end_flow(self, mock_processor):
    """
    Test complete flow from input to output.
    
    Verifies all components work together correctly.
    """
    # Setup
    mock_processor.feature_extractor.extract_phase4_data.return_value = phase4_data
    
    # Execute
    result = mock_processor.calculate_precompute()
    
    # Verify
    assert len(mock_processor.transformed_data) == expected_count
```

### Validation Test Pattern
```python
def test_real_data_quality(self, bq_client, validation_date):
    """
    Test quality against real production data.
    
    Validates data meets quality standards.
    """
    # Query real data
    query = f"SELECT * FROM table WHERE date = '{validation_date}'"
    result = bq_client.query(query).to_dataframe()
    
    # Validate
    assert result['quality_score'].mean() >= 75.0
```

---

## üìù Adding New Tests

### Step 1: Choose Test Category
- **Unit Test**: Testing single method in isolation
- **Integration Test**: Testing component interactions
- **Validation Test**: Testing against real data
- **Performance Test**: Benchmarking timing

### Step 2: Write Test
```python
def test_new_feature(self, fixture):
    """Clear description of what is being tested."""
    # Arrange
    input_data = create_test_data()
    
    # Act
    result = method_under_test(input_data)
    
    # Assert
    assert result == expected
```

### Step 3: Run Test
```bash
pytest test_unit.py::test_new_feature -v
```

### Step 4: Update Documentation
- Add test to count in this README
- Update test breakdown for appropriate category

---

## üö¶ CI/CD Integration

### GitHub Actions Example
```yaml
name: Test ML Feature Store

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: |
          pip install pytest pytest-cov pytest-benchmark
      - name: Run tests
        run: |
          cd tests/processors/precompute/ml_feature_store
          python run_tests.py --all
      - name: Generate coverage
        run: |
          python run_tests.py --coverage
```

---

## üìö Additional Resources

- **Processor Documentation**: `data_processors/precompute/ml_feature_store/README.md`
- **Implementation Guide**: Search for "NBA Processor Development Guide"
- **Schema Documentation**: BigQuery schema for ml_feature_store_v2 table
- **Feature Definitions**: 25-feature specification document

---

## ‚úÖ Test Checklist

Before deploying to production:

- [ ] All 121 tests passing
- [ ] Coverage ‚â•95%
- [ ] Validation tests pass with real data
- [ ] Performance benchmarks meet targets
- [ ] No test warnings or deprecations
- [ ] Documentation updated
- [ ] Code reviewed

---

## üìû Support

If tests fail or you need help:

1. Check test output for specific error
2. Review processor documentation
3. Run with `-vv -s` for detailed output
4. Check BigQuery for data issues (validation tests)
5. Review processor logs in Cloud Logging

---

**Last Updated**: November 2025  
**Test Suite Version**: 2.0  
**Total Tests**: 121 (85 unit, 6 integration, 13 validation, 17 performance)