# WEEK 0 SECURITY ADDENDUM - BLOCKING FIXES
## NBA Daily Orchestration Improvements - Pre-Phase A

**Date:** January 19, 2026
**Status:** üî¥ BLOCKING PHASE A DEPLOYMENT
**Total Effort:** 9.25-11.25 hours
**Related Documents:**
- FINAL-IMPLEMENTATION-PLAN-2026-01-19.md (main plan)
- OPUS-STRATEGIC-REVIEW-2026-01-19.md (strategic review)

---

## EXECUTIVE SUMMARY

### Critical Additions from Final Review

This addendum documents **6 security vulnerabilities** that MUST be fixed before Phase A deployment:

| # | Issue | Severity | Effort | Status |
|---|-------|----------|--------|--------|
| **1** | **Hardcoded BettingPros API Key** | **CRITICAL** | 30 min | ‚ö†Ô∏è **NEW** |
| **2** | **SQL Injection (8 queries)** | **CRITICAL** | 3 hours | From Opus |
| **3** | **Fail-Open Error Handling** | **CRITICAL** | 1.25 hours | From Opus |
| **4** | **Input Validation (date + project)** | **MAJOR** | 1.5 hours | Updated |
| **5** | **Stubbed Cloud Logging** | **MAJOR** | 30 min | From Opus |
| **6** | **Project ID Injection** | **MAJOR** | +30 min | ‚ö†Ô∏è **NEW** |

**Changes from Original Plan:**
- üÜï **2 NEW critical issues found** (API key, project ID validation)
- ‚¨ÜÔ∏è **Fail-closed now includes degraded mode** (+15 min)
- ‚úÖ **All issues must be fixed together** (no partial deployment)

---

## SECTION 1: CRITICAL SECURITY VULNERABILITIES

### üî¥ ISSUE #1: Hardcoded BettingPros API Key (NEW)

**Severity:** CRITICAL
**Priority:** #1 (Fix First)
**Effort:** 30 minutes
**Discovered By:** Sonnet review (2026-01-19)

#### Location

**File:** `scrapers/utils/nba_header_utils.py`
**Lines:** 129-156

#### Vulnerable Code

```python
BETTINGPROS_HEADERS = {
    'User-Agent': 'Mozilla/5.0...',
    'Accept': 'application/json',
    'X-Api-Key': 'CHi8Hy5CEE4khd46XNYL23dCFX96oUdw6qOt1Dnh',  # üî¥ HARDCODED!
}
```

#### Security Risks

1. **Credential Exposure:** API key visible in git history to anyone with repo access
2. **Service Abuse:** Third parties could use the key to abuse BettingPros API
3. **No Rotation:** If BettingPros rotates the key, all code breaks
4. **Violates Best Practices:** Secrets should never be in source code

#### Attack Scenario

```bash
# Attacker with repo access:
git log --all -p | grep "X-Api-Key"
# Finds: CHi8Hy5CEE4khd46XNYL23dCFX96oUdw6qOt1Dnh

# Attacker uses key to:
# - Make unlimited API calls on your quota
# - DOS the API endpoint
# - Access premium data without paying
```

#### Required Fix

```python
import os

BETTINGPROS_HEADERS = {
    'User-Agent': 'Mozilla/5.0...',
    'Accept': 'application/json',
    'X-Api-Key': os.environ.get('BETTINGPROS_API_KEY', ''),
}

# Validation
if not BETTINGPROS_HEADERS['X-Api-Key']:
    logger.warning("BETTINGPROS_API_KEY environment variable not set")
```

#### Implementation Steps

**Step 1: Update Code (5 min)**
- [ ] Open `scrapers/utils/nba_header_utils.py`
- [ ] Replace hardcoded key with `os.environ.get('BETTINGPROS_API_KEY', '')`
- [ ] Add validation to warn if key is missing

**Step 2: Set Environment Variable (5 min)**
- [ ] Add to Cloud Run environment variables:
  ```bash
  gcloud run services update <service-name> \
    --update-env-vars BETTINGPROS_API_KEY=CHi8Hy5CEE4khd46XNYL23dCFX96oUdw6qOt1Dnh
  ```
- [ ] Add to local `.env` file (for development):
  ```bash
  BETTINGPROS_API_KEY=CHi8Hy5CEE4khd46XNYL23dCFX96oUdw6qOt1Dnh
  ```

**Step 3: Update Documentation (5 min)**
- [ ] Document in README: Required environment variables
- [ ] Add to deployment guide: Set BETTINGPROS_API_KEY before deployment
- [ ] Update `.env.example` with placeholder

**Step 4: Rotate API Key (10 min) - POST-DEPLOYMENT**
- [ ] After deployment verified working, contact BettingPros
- [ ] Request new API key
- [ ] Update environment variable
- [ ] Verify services still working
- [ ] Invalidate old key

**Step 5: Security Audit (5 min)**
- [ ] Search for other hardcoded secrets:
  ```bash
  grep -r "api.*key.*=.*['\"]" --include="*.py" scrapers/ shared/
  grep -r "password.*=.*['\"]" --include="*.py" .
  grep -r "token.*=.*['\"]" --include="*.py" .
  ```

**Total: 30 minutes**

---

### üî¥ ISSUE #2: SQL Injection Vulnerabilities

**Severity:** CRITICAL
**Priority:** #2
**Effort:** 3 hours
**Discovered By:** Opus 4.5 security audit

#### Locations (8 Total Queries)

**File 1:** `data_processors/analytics/main_analytics_service.py`
- Line 74-80: Scheduled games query
- Line 90-94: BDL boxscore query

**File 2:** `bin/monitoring/diagnose_prediction_batch.py`
- Line 99: Predictions count query
- Line 130: Worker runs query
- Line 157: Consolidation query
- Line 183: Grading query
- Line 227+: Error analysis queries (2 queries)

#### Vulnerable Pattern

```python
# üî¥ VULNERABLE:
scheduled_query = f"""
SELECT game_id, home_team_tricode, away_team_tricode
FROM `{project_id}.nba_raw.nbac_schedule`
WHERE game_date = '{game_date}'  -- SQL INJECTION RISK
  AND game_status_text = 'Final'
"""
```

#### Attack Vector

```python
# Attacker controls game_date:
game_date = "2026-01-19' OR '1'='1"

# Query becomes:
# WHERE game_date = '2026-01-19' OR '1'='1'
# Returns ALL games regardless of date ‚Üí Information disclosure

# OR worse:
game_date = "2026-01-19'; DROP TABLE nba_raw.nbac_schedule; --"
# Could delete data (if permissions allow)
```

#### Required Fix: Parameterized Queries

```python
# ‚úÖ SECURE:
from google.cloud import bigquery

query = """
SELECT game_id, home_team_tricode, away_team_tricode
FROM `{project_id}.nba_raw.nbac_schedule`
WHERE game_date = @game_date
  AND game_status_text = 'Final'
"""

job_config = bigquery.QueryJobConfig(
    query_parameters=[
        bigquery.ScalarQueryParameter("game_date", "DATE", game_date),
    ]
)

scheduled_result = list(bq_client.query(query, job_config=job_config).result())
```

#### Implementation Steps

**File 1: main_analytics_service.py (1 hour)**

- [ ] **Query 1: Scheduled Games (Line 74-80)** - 20 min
  - [ ] Convert to parameterized query with `@game_date`
  - [ ] Add `QueryJobConfig` with `ScalarQueryParameter`
  - [ ] Test with valid date
  - [ ] Test with SQL injection attempt (should fail safely)

- [ ] **Query 2: BDL Boxscores (Line 90-94)** - 20 min
  - [ ] Convert to parameterized query with `@game_date`
  - [ ] Add `QueryJobConfig` with `ScalarQueryParameter`
  - [ ] Test query returns correct results

- [ ] **Unit Tests** - 20 min
  - [ ] Test: Valid date returns correct data
  - [ ] Test: SQL injection attempt fails safely
  - [ ] Test: Query still performant (no regression)

**File 2: diagnose_prediction_batch.py (1.5 hours)**

- [ ] **Query 1: Predictions Count (Line 99)** - 15 min
  - [ ] Convert to parameterized query
  - [ ] Test

- [ ] **Query 2: Worker Runs (Line 130)** - 15 min
  - [ ] Convert to parameterized query
  - [ ] Test

- [ ] **Query 3: Consolidation (Line 157)** - 15 min
  - [ ] Convert to parameterized query
  - [ ] Test

- [ ] **Query 4: Grading (Line 183)** - 15 min
  - [ ] Convert to parameterized query
  - [ ] Test

- [ ] **Queries 5-6: Error Analysis** - 15 min
  - [ ] Convert both to parameterized queries
  - [ ] Test

- [ ] **Unit Tests** - 15 min
  - [ ] Test each query with valid input
  - [ ] Test SQL injection attempts blocked

**Security Audit (30 min)**

- [ ] **Search for other SQL injections:**
  ```bash
  # Find f-string SQL queries:
  grep -r "f\"\"\".*SELECT" --include="*.py" data_processors/ orchestration/
  grep -r "f'''.*SELECT" --include="*.py" data_processors/ orchestration/

  # Find .format() SQL queries:
  grep -r "\.format(.*SELECT" --include="*.py" data_processors/ orchestration/

  # Find string interpolation in WHERE clauses:
  grep -r "WHERE.*{" --include="*.py" data_processors/ orchestration/
  ```

- [ ] **Review findings and fix any additional vulnerabilities**

**Total: 3 hours**

---

### üî¥ ISSUE #3: Fail-Open Error Handling

**Severity:** CRITICAL
**Priority:** #3
**Effort:** 1.25 hours (updated: +15 min for degraded mode)
**Discovered By:** Opus 4.5 security audit

#### Location

**File:** `data_processors/analytics/main_analytics_service.py`
**Lines:** 139-150

#### Vulnerable Code

```python
# üî¥ DANGEROUS:
except Exception as e:
    logger.error(f"Boxscore completeness check failed: {e}", exc_info=True)
    # On error, assume complete to allow analytics to proceed
    return {
        "complete": True,  # ‚Üê FAIL-OPEN: Returns success on ANY error
        "coverage_pct": 0,
        "expected_games": 0,
        "actual_games": 0,
        "missing_games": [],
        "error": str(e)
    }
```

#### Why This Is Critical

**Failure Scenarios That Silently Report "Complete":**
- BigQuery client crashes ‚Üí Returns "complete" ‚úÖ (WRONG!)
- Invalid project_id ‚Üí Returns "complete" ‚úÖ (WRONG!)
- Network timeout ‚Üí Returns "complete" ‚úÖ (WRONG!)
- Out of memory ‚Üí Returns "complete" ‚úÖ (WRONG!)

**Business Impact:**
- **Defeats the entire purpose of Session 98**
- Jan 18 boxscore gap (2/6 games) would repeat undetected
- Analytics proceeds with incomplete data
- ML models trained on bad data
- Predictions degraded without alerting

#### Required Fix: Fail-Closed with Degraded Mode

```python
# ‚úÖ SECURE:
except Exception as e:
    logger.error(f"Boxscore completeness check FAILED: {e}", exc_info=True)

    # FAIL-CLOSED: Conservative assumption on error
    result = {
        "complete": False,  # ‚Üê Safer default
        "coverage_pct": 0,
        "expected_games": 0,
        "actual_games": 0,
        "missing_games": [],
        "error": str(e),
        "is_error_state": True  # Flag for downstream handling
    }

    # Optional: Degraded mode escape hatch (logged + alerted)
    if os.getenv('ALLOW_DEGRADED_MODE', 'false').lower() == 'true':
        logger.critical("üö® DEGRADED MODE ACTIVE - Proceeding despite completeness check error")
        # Send alert (Slack, PagerDuty, etc.)
        result['complete'] = True
        result['degraded_mode'] = True

    return result
```

#### Implementation Steps

**Step 1: Change Fail-Open to Fail-Closed (30 min)**

- [ ] **Update `verify_boxscore_completeness()` (Line 139-150):**
  - [ ] Change `"complete": True` ‚Üí `"complete": False`
  - [ ] Add `"is_error_state": True` to error response
  - [ ] Update error log message to emphasize failure

- [ ] **Test error scenarios:**
  - [ ] Mock BigQuery client failure ‚Üí Should return `complete: False`
  - [ ] Mock network timeout ‚Üí Should return `complete: False`
  - [ ] Mock invalid project_id ‚Üí Should return `complete: False`
  - [ ] Verify `is_error_state: True` in all error cases

**Step 2: Add Degraded Mode Escape Hatch (15 min - NEW)**

- [ ] **Add environment variable check:**
  ```python
  ALLOW_DEGRADED_MODE = os.getenv('ALLOW_DEGRADED_MODE', 'false').lower() == 'true'
  ```

- [ ] **Add degraded mode logic after fail-closed:**
  ```python
  if ALLOW_DEGRADED_MODE:
      logger.critical("üö® DEGRADED MODE ACTIVE")
      # TODO: Send alert to ops team
      result['complete'] = True
      result['degraded_mode'] = True
  ```

- [ ] **Document degraded mode:**
  - When to use: Completeness check has a bug, must process urgently
  - Alert ops team when activated
  - Should be temporary (fix underlying issue)

**Step 3: Update Downstream Error Handling (30 min)**

- [ ] **Update `process_analytics()` (Line 343):**
  ```python
  completeness = verify_boxscore_completeness(game_date, opts['project_id'])

  # Handle error state
  if completeness.get('is_error_state'):
      if completeness.get('degraded_mode'):
          logger.warning("Proceeding in degraded mode")
          # Continue but log warning
      else:
          logger.error(f"Completeness check errored - cannot proceed safely")
          return {
              "status": "error",
              "reason": "completeness_check_failed",
              "error": completeness.get('error')
          }

  # Handle incomplete data
  if not completeness['complete']:
      logger.warning(f"Boxscore data incomplete: {completeness}")
      # Existing logic...
  ```

- [ ] **Test downstream handling:**
  - [ ] Test: Error state without degraded mode ‚Üí Returns error, stops processing
  - [ ] Test: Error state with degraded mode ‚Üí Logs warning, continues processing
  - [ ] Test: Incomplete (no error) ‚Üí Existing behavior (trigger auto-heal)

**Step 4: Unit Tests (15 min)**

- [ ] **Test fail-closed behavior:**
  - [ ] Test: BigQuery client creation fails ‚Üí `complete: False, is_error_state: True`
  - [ ] Test: Query timeout ‚Üí `complete: False, is_error_state: True`
  - [ ] Test: Network error ‚Üí `complete: False, is_error_state: True`

- [ ] **Test degraded mode:**
  - [ ] Test: `ALLOW_DEGRADED_MODE=false` ‚Üí Error stops processing
  - [ ] Test: `ALLOW_DEGRADED_MODE=true` ‚Üí Error logged, processing continues
  - [ ] Test: Degraded mode flag present in response

**Total: 1.25 hours (1 hour original + 15 min degraded mode)**

---

### üî¥ ISSUE #4: Input Validation (Date + Project ID)

**Severity:** MAJOR
**Priority:** #4
**Effort:** 1.5 hours (updated: +30 min for project ID)
**Discovered By:** Opus 4.5 (game_date) + Sonnet review (project_id)

#### Locations

**Files:**
- `data_processors/analytics/main_analytics_service.py` (Line 52, 300, 341)
- `bin/monitoring/diagnose_prediction_batch.py` (Line 39)

#### Vulnerable Code

```python
# üî¥ NO VALIDATION:
game_date = message.get('game_date')  # Could be None, malformed, SQL injection
project_id = opts.get('project_id')  # Could be malicious project ID

# Used directly in queries without validation:
completeness = verify_boxscore_completeness(game_date, project_id)
```

#### Attack Vectors

**game_date Injection:**
```python
game_date = "2026-01-19' OR '1'='1"  # SQL injection
game_date = "invalid-date"            # Causes query errors
game_date = None                      # Crashes
```

**project_id Injection:**
```python
project_id = "victim-project` OR 1=1; --"  # SQL injection
project_id = "attacker-project"             # Access other GCP projects
project_id = "../../../etc/passwd"          # Path traversal (if used in file paths)
```

#### Required Fix: Input Validation

**Create Validation Utilities:**

```python
# shared/utils/validation.py

import re
from datetime import datetime, date, timedelta
from typing import Tuple

def validate_game_date(game_date: str) -> Tuple[bool, str]:
    """
    Validate game date format and range.

    Args:
        game_date: Expected YYYY-MM-DD format in ET timezone

    Returns:
        (is_valid, error_message)
    """
    if not game_date or not isinstance(game_date, str):
        return False, "game_date is required and must be a string"

    # Check format (YYYY-MM-DD)
    if not re.match(r'^\d{4}-\d{2}-\d{2}$', game_date):
        return False, f"game_date must be YYYY-MM-DD format, got: {game_date}"

    try:
        parsed_date = datetime.strptime(game_date, '%Y-%m-%d').date()
    except (ValueError, TypeError) as e:
        return False, f"Invalid date: {e}"

    # Check reasonable range
    min_date = date(1946, 11, 1)  # First NBA game
    max_date = date.today() + timedelta(days=365)  # Allow future scheduling

    if not (min_date <= parsed_date <= max_date):
        return False, f"game_date {game_date} outside valid range ({min_date} to {max_date})"

    return True, ""


def validate_project_id(project_id: str) -> Tuple[bool, str]:
    """
    Validate GCP project ID against allowlist.

    Args:
        project_id: GCP project ID

    Returns:
        (is_valid, error_message)
    """
    # Allowlist of valid project IDs
    VALID_PROJECT_IDS = [
        'nba-props-platform',
        'nba-props-staging',
        'nba-props-dev',
    ]

    if not project_id or not isinstance(project_id, str):
        return False, "project_id is required and must be a string"

    # Check against allowlist
    if project_id not in VALID_PROJECT_IDS:
        return False, f"Invalid project_id: {project_id}. Must be one of: {VALID_PROJECT_IDS}"

    # Additional format validation (GCP project ID rules)
    if not re.match(r'^[a-z][a-z0-9-]{4,28}[a-z0-9]$', project_id):
        return False, f"project_id format invalid: {project_id}"

    return True, ""
```

#### Implementation Steps

**Step 1: Create Validation Module (30 min)**

- [ ] **Create `shared/utils/validation.py`:**
  - [ ] Implement `validate_game_date()` - 15 min
  - [ ] Implement `validate_project_id()` - 15 min

- [ ] **Unit tests for validation:**
  ```python
  # test_validation.py
  def test_validate_game_date_valid():
      assert validate_game_date("2026-01-19") == (True, "")

  def test_validate_game_date_invalid_format():
      is_valid, error = validate_game_date("01-19-2026")
      assert not is_valid
      assert "YYYY-MM-DD" in error

  def test_validate_game_date_sql_injection():
      is_valid, error = validate_game_date("2026-01-19' OR '1'='1")
      assert not is_valid

  def test_validate_project_id_valid():
      assert validate_project_id("nba-props-platform") == (True, "")

  def test_validate_project_id_not_in_allowlist():
      is_valid, error = validate_project_id("attacker-project")
      assert not is_valid
      assert "Invalid project_id" in error
  ```

**Step 2: Add Validation to main_analytics_service.py (30 min)**

- [ ] **Import validation functions:**
  ```python
  from shared.utils.validation import validate_game_date, validate_project_id
  ```

- [ ] **Add validation in `process_analytics()` (Line 300):**
  ```python
  game_date = message.get('game_date')
  project_id = opts.get('project_id', 'nba-props-platform')

  # Validate game_date
  is_valid, error = validate_game_date(game_date)
  if not is_valid:
      logger.error(f"Invalid game_date: {error}")
      return {"status": "error", "reason": f"invalid_game_date: {error}"}

  # Validate project_id
  is_valid, error = validate_project_id(project_id)
  if not is_valid:
      logger.error(f"Invalid project_id: {error}")
      return {"status": "error", "reason": f"invalid_project_id: {error}"}

  # Continue processing...
  completeness = verify_boxscore_completeness(game_date, project_id)
  ```

- [ ] **Test validation:**
  - [ ] Test: Valid inputs ‚Üí Processing continues
  - [ ] Test: Invalid game_date ‚Üí Returns error, stops processing
  - [ ] Test: Invalid project_id ‚Üí Returns error, stops processing
  - [ ] Test: SQL injection attempts ‚Üí Blocked

**Step 3: Add Validation to diagnose_prediction_batch.py (30 min)**

- [ ] **Import validation functions**

- [ ] **Add validation in `__init__()` or `diagnose()` method:**
  ```python
  # Validate game_date
  is_valid, error = validate_game_date(game_date)
  if not is_valid:
      raise ValueError(f"Invalid game_date: {error}")

  # Validate project_id
  is_valid, error = validate_project_id(self.project_id)
  if not is_valid:
      raise ValueError(f"Invalid project_id: {error}")
  ```

- [ ] **Test validation:**
  - [ ] Test: Valid inputs ‚Üí Diagnostic runs successfully
  - [ ] Test: Invalid inputs ‚Üí Raises ValueError

**Total: 1.5 hours**

---

### üî¥ ISSUE #5: Stubbed Cloud Logging

**Severity:** MAJOR
**Priority:** #5
**Effort:** 30 minutes
**Discovered By:** Opus 4.5 security audit

#### Location

**File:** `bin/monitoring/diagnose_prediction_batch.py`
**Lines:** 223-240

#### Vulnerable Code

```python
# üî¥ HARDCODED:
def _count_worker_errors(self, game_date: str) -> int:
    """Count prediction worker errors for game_date."""
    try:
        log_filter = f'''
        resource.type="cloud_run_revision"
        AND resource.labels.service_name="prediction-worker"
        AND severity>=ERROR
        AND timestamp>="{game_date}T00:00:00Z"
        AND timestamp<"{game_date}T23:59:59Z"
        '''
        return 0  # üî¥ Placeholder - would need logging client setup
    except Exception:
        return 0
```

#### Impact

- Diagnostic tool shows "0 errors" even when hundreds of worker errors exist
- False "healthy" status in diagnostics
- Incidents go undetected
- Operators have false confidence

#### Required Fix

```python
# ‚úÖ SECURE:
def _count_worker_errors(self, game_date: str) -> int:
    """Count prediction worker errors for game_date."""
    try:
        from google.cloud import logging as cloud_logging

        # Initialize logging client (lazy init)
        if not hasattr(self, 'log_client'):
            self.log_client = cloud_logging.Client(project=self.project_id)

        log_filter = f'''
        resource.type="cloud_run_revision"
        AND resource.labels.service_name="prediction-worker"
        AND severity>=ERROR
        AND timestamp>="{game_date}T00:00:00Z"
        AND timestamp<"{game_date}T23:59:59Z"
        '''

        entries = list(self.log_client.list_entries(filter_=log_filter, page_size=1000))
        return len(entries)

    except Exception as e:
        logger.error(f"Failed to count worker errors: {e}")
        return -1  # Return -1 to indicate error (vs 0 = actually no errors)
```

#### Implementation Steps

**Step 1: Implement Cloud Logging Client (15 min)**

- [ ] **Update `_count_worker_errors()` method:**
  - [ ] Add Cloud Logging import
  - [ ] Initialize `self.log_client` (lazy)
  - [ ] Call `log_client.list_entries()`
  - [ ] Return actual count

- [ ] **Update error handling:**
  - [ ] Change `return 0` ‚Üí `return -1` to distinguish error from "no errors"
  - [ ] Log exception details

**Step 2: Test Cloud Logging (10 min)**

- [ ] **Test with real data:**
  - [ ] Run diagnostic on date with known errors
  - [ ] Verify count is accurate (compare with Cloud Console)
  - [ ] Verify count > 0 when errors exist

- [ ] **Test error handling:**
  - [ ] Mock logging client failure
  - [ ] Verify returns -1 (not 0)

**Step 3: Update Diagnostic Output (5 min)**

- [ ] **Handle -1 return value in display:**
  ```python
  error_count = self._count_worker_errors(game_date)
  if error_count == -1:
      print("‚ö†Ô∏è  Worker errors: Unable to fetch (logging client error)")
  elif error_count == 0:
      print("‚úÖ Worker errors: 0")
  else:
      print(f"üî¥ Worker errors: {error_count}")
  ```

**Total: 30 minutes**

---

### üî¥ ISSUE #6: Project ID SQL Injection (NEW)

**Severity:** MAJOR
**Priority:** #6 (Covered by Issue #4)
**Effort:** +30 minutes to Issue #4
**Discovered By:** Sonnet review (2026-01-19)

#### Location

**Files:** All files with SQL queries using `{project_id}` interpolation

#### Vulnerable Pattern

```python
# üî¥ VULNERABLE:
query = f"""
SELECT * FROM `{project_id}.nba_raw.nbac_schedule`
WHERE game_date = @game_date
"""
```

#### Attack Vector

```python
project_id = "attacker-project` OR 1=1; --"

# Query becomes:
# SELECT * FROM `attacker-project` OR 1=1; --.nba_raw.nbac_schedule`
# Could access other projects or bypass security
```

#### Required Fix

**Already covered in Issue #4 - Validate project_id against allowlist.**

This ensures `project_id` can only be one of:
- `nba-props-platform`
- `nba-props-staging`
- `nba-props-dev`

Even though we're using parameterized queries for `game_date`, we should validate `project_id` since it's used in table references (which can't be parameterized in BigQuery).

**No additional work beyond Issue #4 validation.**

---

## SECTION 2: ENHANCEMENTS (NON-BLOCKING)

### Enhancement #1: Verification Script for Pooling

**Status:** Add to Phase B preparation
**Effort:** 15 minutes
**Recommended By:** Sonnet review

#### Purpose

Before deploying Phase B (connection pooling), verify no files were missed.

#### Script

```bash
#!/bin/bash
# verify_pooling_complete.sh

echo "=== Checking for missed BigQuery client instantiations ==="

# Find direct BigQuery.Client() calls
echo -e "\n1. Direct bigquery.Client() instantiations:"
grep -r "bigquery\.Client(" --include="*.py" \
  data_processors/ orchestration/ scrapers/ | \
  grep -v "test" | \
  grep -v "bigquery_pool.py" | \
  grep -v "#.*bigquery.Client"

# Find child class overrides
echo -e "\n2. Child classes overriding pooled client:"
grep -r "self\.bq_client.*=.*bigquery\.Client" --include="*.py" \
  data_processors/ orchestration/

# Find requests without http_pool
echo -e "\n3. Direct requests usage (should use get_http_session):"
grep -r "requests\.(get|post|Session)" --include="*.py" \
  scrapers/ backfill_jobs/ | \
  grep -v "http_pool.py" | \
  grep -v "test" | \
  grep -v "import requests"

echo -e "\n=== Verification complete ==="
echo "If any results above, review and add to Phase B deployment."
```

#### Usage

```bash
# Before Phase B deployment:
chmod +x verify_pooling_complete.sh
./verify_pooling_complete.sh

# Review output, fix any findings
```

---

### Enhancement #2: Phase A Monitoring Metrics

**Status:** Add to Phase A deployment
**Effort:** 30 minutes
**Recommended By:** Sonnet review

#### Metrics to Track

Add these to Cloud Monitoring dashboards:

| Metric | Target | Alert Threshold | Measurement |
|--------|--------|-----------------|-------------|
| Completeness check execution time | <5 seconds | >10 seconds | Cloud Logging |
| Completeness check success rate | >99% | <95% | BigQuery logs |
| False positive rate | <1% | >5% | Manual verification |
| Auto-heal trigger rate | Track baseline | >2x baseline | Pub/Sub metrics |
| Degraded mode activation count | 0 | >0 | Log metric filter |

#### Implementation

```python
# Add to Cloud Logging metric filters:

# Metric 1: Execution time
# Filter: jsonPayload.message=~"Completeness check completed in .*"
# Extract: jsonPayload.duration_seconds

# Metric 2: Success rate
# Filter: jsonPayload.message="Completeness check complete"
# Count: Group by success/failure

# Metric 3: False positives
# Filter: jsonPayload.message="Completeness false positive detected"
# Count: Increments

# Metric 4: Auto-heal triggers
# Filter: topic="auto-heal-trigger"
# Count: Pub/Sub message count

# Metric 5: Degraded mode
# Filter: jsonPayload.message=~"DEGRADED MODE ACTIVE"
# Count: Should be 0 in production
```

---

## SECTION 3: PRIORITY & SEQUENCING

### Recommended Fix Order

**DO NOT SPLIT SECURITY FIXES** - All must be completed together for consistent security posture.

#### Priority Sequence (Total: ~9.5 hours)

1. **Issue #1: BettingPros API Key** (30 min) - PRIORITY 1
   - Exposed credentials, immediate risk
   - Quick fix with high impact

2. **Issue #3: Fail-Open to Fail-Closed** (1.25 hours) - PRIORITY 2
   - Affects data integrity daily
   - Core business logic fix
   - Includes degraded mode (15 min)

3. **Issue #2: SQL Injection (main_analytics)** (1 hour) - PRIORITY 3
   - Runs daily in production
   - File 1 only: `main_analytics_service.py`

4. **Issue #4: Input Validation** (1.5 hours) - PRIORITY 4
   - Defense in depth
   - Validates both game_date AND project_id
   - Blocks SQL injection attempts

5. **Issue #2: SQL Injection (diagnostic)** (1.5 hours) - PRIORITY 5
   - Less frequent execution
   - File 2: `diagnose_prediction_batch.py`

6. **Issue #5: Cloud Logging** (30 min) - PRIORITY 6
   - Fixes false "healthy" status
   - Improves operational visibility

7. **Security Audit** (30 min) - PRIORITY 7
   - Search for other hardcoded secrets
   - Search for other SQL injections
   - Final verification

8. **Documentation** (2 hours) - PRIORITY 8
   - Update README.md
   - Update IMPLEMENTATION-TRACKING.md
   - Update JITTER-ADOPTION-TRACKING.md

9. **Verification** (1.25 hours) - PRIORITY 9
   - Test merge to main
   - Implement feature flags
   - Run all unit tests

**Total Effort: 9.5-11 hours**

---

## SECTION 4: TESTING & VALIDATION

### Pre-Deployment Testing Checklist

**Unit Tests (Included in fixes above):**
- [ ] All parameterized queries tested
- [ ] Fail-closed behavior tested (3 scenarios)
- [ ] Degraded mode tested
- [ ] Input validation tested (game_date + project_id)
- [ ] Cloud Logging integration tested

**Integration Tests:**
- [ ] End-to-end test: Valid game_date ‚Üí Completeness check ‚Üí Analytics
- [ ] End-to-end test: Invalid game_date ‚Üí Error returned
- [ ] End-to-end test: Incomplete boxscores ‚Üí Auto-heal triggered
- [ ] End-to-end test: Completeness check errors ‚Üí Fail-closed behavior

**Security Tests:**
- [ ] SQL injection attempt blocked (game_date)
- [ ] SQL injection attempt blocked (project_id)
- [ ] Hardcoded API key no longer in code
- [ ] Environment variable fallback works
- [ ] All tests pass

**Performance Tests:**
- [ ] Parameterized queries no slower than f-strings
- [ ] Input validation adds <50ms overhead
- [ ] Cloud Logging query completes in <2 seconds

### Test Merge to Main

```bash
# Create temporary branch
git checkout session-98-docs-with-redactions
git checkout -b test-merge-main-week0

# Attempt merge
git merge origin/main

# If conflicts:
# - Resolve each conflict
# - Document resolution decisions
# - Run full test suite

# Verify tests pass
pytest tests/
python -m pytest data_processors/analytics/test_main_analytics_service.py

# If successful:
git branch -D test-merge-main-week0

# If >10 conflicts:
# - Stop and reassess merge strategy
# - Consider rebasing instead
```

---

## SECTION 5: FEATURE FLAGS

### Feature Flag Configuration

**Phase A Feature Flag:**

```bash
# Environment variable for analytics-processor Cloud Run
DISABLE_COMPLETENESS_CHECK=false  # Default: enabled

# To disable completeness check (rollback):
DISABLE_COMPLETENESS_CHECK=true
```

**Degraded Mode Feature Flag:**

```bash
# Environment variable for analytics-processor Cloud Run
ALLOW_DEGRADED_MODE=false  # Default: disabled

# Emergency escape hatch (logs + alerts when used):
ALLOW_DEGRADED_MODE=true
```

**Phase B Feature Flag (for later):**

```bash
# Environment variable for all services using pooling
USE_BIGQUERY_POOLING=true  # Default: enabled

# To disable pooling (rollback):
USE_BIGQUERY_POOLING=false
```

### Deployment

```bash
# Set environment variables in Cloud Run:
gcloud run services update analytics-processor \
  --update-env-vars DISABLE_COMPLETENESS_CHECK=false,ALLOW_DEGRADED_MODE=false \
  --region us-central1
```

---

## SECTION 6: GO/NO-GO CRITERIA

### REQUIRED FOR GO (Phase A Deployment)

‚úÖ **All Security Fixes Complete:**
- [ ] Issue #1: API key moved to environment variable
- [ ] Issue #2: All 8 SQL queries parameterized
- [ ] Issue #3: Fail-closed implemented + degraded mode
- [ ] Issue #4: Input validation for game_date + project_id
- [ ] Issue #5: Cloud Logging implemented
- [ ] Issue #6: Project ID validated (covered by #4)

‚úÖ **All Tests Passing:**
- [ ] Unit tests: 100% pass
- [ ] Integration tests: 100% pass
- [ ] Security tests: All injection attempts blocked

‚úÖ **Documentation Updated:**
- [ ] README.md: Phase 1-2 marked as DEPLOYED
- [ ] IMPLEMENTATION-TRACKING.md: Accurate progress
- [ ] Feature flags documented

‚úÖ **Merge Validated:**
- [ ] Test merge successful
- [ ] Conflicts resolved (<10 conflicts)
- [ ] Tests pass post-merge

‚úÖ **Feature Flags Implemented:**
- [ ] `DISABLE_COMPLETENESS_CHECK` configured
- [ ] `ALLOW_DEGRADED_MODE` configured
- [ ] Rollback procedures documented

### REQUIRED FOR NO-GO (Block Deployment)

‚ö†Ô∏è **Any Security Fix Incomplete:**
- Any of Issues #1-6 not fully implemented
- Security review fails
- Hardcoded secrets still present

‚ö†Ô∏è **Tests Failing:**
- Unit test failures
- Security tests show vulnerabilities
- Integration tests fail

‚ö†Ô∏è **Merge Issues:**
- >10 unresolved conflicts
- Tests fail after merge
- Code review not complete

---

## SECTION 7: ROLLBACK PROCEDURES

### If Issues Discovered During Week 0 Work

**Scenario:** Security fix introduces a bug or breaks tests

**Action:**
1. Do NOT proceed with deployment
2. Fix the issue in Week 0
3. Re-run tests
4. Only proceed when all tests pass

### If Issues Discovered After Phase A Deployment

**See FINAL-IMPLEMENTATION-PLAN-2026-01-19.md Section 9 for full rollback procedures.**

**Quick Rollback (Feature Flag - INSTANT):**
```bash
# Disable completeness check
gcloud run services update analytics-processor \
  --update-env-vars DISABLE_COMPLETENESS_CHECK=true
```

---

## SECTION 8: WEEK 0 CHECKLIST

### Complete Checklist (9.5-11 hours)

**DAY 1: Security Fixes (6-7 hours)**

- [ ] **Issue #1: BettingPros API Key** (30 min)
  - [ ] Move to environment variable
  - [ ] Update Cloud Run config
  - [ ] Update documentation
  - [ ] Plan key rotation post-deployment

- [ ] **Issue #3: Fail-Closed + Degraded Mode** (1.25 hours)
  - [ ] Change error handling to fail-closed
  - [ ] Add degraded mode logic
  - [ ] Update downstream error handling
  - [ ] Unit tests

- [ ] **Issue #2: SQL Injection - Analytics** (1 hour)
  - [ ] Parameterize 2 queries in `main_analytics_service.py`
  - [ ] Unit tests

- [ ] **Issue #4: Input Validation** (1.5 hours)
  - [ ] Create validation module
  - [ ] Validate game_date
  - [ ] Validate project_id
  - [ ] Add to both files
  - [ ] Unit tests

- [ ] **Issue #2: SQL Injection - Diagnostic** (1.5 hours)
  - [ ] Parameterize 6 queries in `diagnose_prediction_batch.py`
  - [ ] Unit tests

- [ ] **Issue #5: Cloud Logging** (30 min)
  - [ ] Implement logging client
  - [ ] Fix return value (-1 for errors)
  - [ ] Test

**DAY 2: Validation & Documentation (3-4 hours)**

- [ ] **Security Audit** (30 min)
  - [ ] Search for other hardcoded secrets
  - [ ] Search for other SQL injections
  - [ ] Document findings

- [ ] **Documentation Updates** (2 hours)
  - [ ] README.md: Phase 1-2 status
  - [ ] IMPLEMENTATION-TRACKING.md: Accurate progress
  - [ ] JITTER-ADOPTION-TRACKING.md: File counts
  - [ ] Feature flag documentation

- [ ] **Test Merge** (30 min)
  - [ ] Create test branch
  - [ ] Merge main
  - [ ] Resolve conflicts
  - [ ] Verify tests pass

- [ ] **Feature Flags** (30 min)
  - [ ] Implement DISABLE_COMPLETENESS_CHECK
  - [ ] Implement ALLOW_DEGRADED_MODE
  - [ ] Document usage

- [ ] **Final Validation** (30 min)
  - [ ] All unit tests pass
  - [ ] All integration tests pass
  - [ ] Security tests pass
  - [ ] Code review complete

**TOTAL: 9.5-11 hours over 2 days**

---

## SECTION 9: SUCCESS CRITERIA

### Week 0 Complete When:

‚úÖ **All 6 security issues fixed and tested**
‚úÖ **No hardcoded secrets in codebase**
‚úÖ **All SQL queries use parameterized queries**
‚úÖ **Input validation prevents injection attacks**
‚úÖ **Fail-closed behavior prevents silent failures**
‚úÖ **Documentation accurate and up-to-date**
‚úÖ **Test merge successful (or conflicts resolved)**
‚úÖ **Feature flags implemented and tested**
‚úÖ **All tests passing (unit + integration + security)**
‚úÖ **Security review sign-off obtained**

### Ready for Phase A Deployment When:

‚úÖ All Week 0 success criteria met
‚úÖ Security team approves fixes
‚úÖ Code review complete
‚úÖ Deployment plan reviewed
‚úÖ Rollback procedures documented and tested

---

## DOCUMENT METADATA

**Document:** WEEK-0-SECURITY-ADDENDUM.md
**Created:** January 19, 2026
**Version:** 1.0
**Related Plan:** FINAL-IMPLEMENTATION-PLAN-2026-01-19.md
**Status:** üî¥ BLOCKING PHASE A DEPLOYMENT
**Total Effort:** 9.5-11 hours
**Target Completion:** 2 days

**Critical Additions:**
- Issue #1: Hardcoded BettingPros API Key (NEW - 30 min)
- Issue #6: Project ID validation (NEW - +30 min to Issue #4)
- Degraded mode escape hatch (NEW - +15 min to Issue #3)

**Next Action:** Start Day 1 security fixes (6-7 hours)

---

**END OF ADDENDUM**
