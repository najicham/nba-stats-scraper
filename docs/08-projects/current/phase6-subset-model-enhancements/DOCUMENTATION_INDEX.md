# Phase 6 Enhancement Documentation Index

**Last Updated:** 2026-02-03
**Status:** Ready for implementation

## Quick Start Guide

### For Implementation (Start Here)

1. **Read:** `IMPLEMENTATION_UPDATE.md` ‚≠ê
   - Current approach: single file, clean API
   - Exporter specifications
   - Testing procedures

2. **Reference:** `CLEAN_API_STRUCTURE.md` üé®
   - JSON structure specifications
   - What to show/hide
   - Security checklist

3. **Reference:** `CODENAME_EXAMPLES.md` üè∑Ô∏è
   - Model codename mappings (926A, 926B)
   - Group name mappings (Top 5, Best Value)

4. **Reference:** `ACTION_PLAN.md` üìÖ
   - Implementation timeline
   - Step-by-step guide
   - Verification commands

### For Context (Background Reading)

5. **Read:** `FINDINGS_SUMMARY.md` üìä
   - Why we're building this
   - What's currently missing
   - Business value

6. **Read:** `OPUS_REVIEW_FINDINGS.md` ‚úÖ
   - Architectural review results
   - What was verified
   - Critical fixes applied

## Document Status

### Current Implementation Docs (Use These)

| Document | Purpose | Status |
|----------|---------|--------|
| `IMPLEMENTATION_UPDATE.md` | Current approach specs | ‚úÖ Current |
| `CLEAN_API_STRUCTURE.md` | Clean JSON design | ‚úÖ Current |
| `CODENAME_EXAMPLES.md` | Model/group codenames | ‚úÖ Current |
| `ACTION_PLAN.md` | Implementation timeline | ‚úÖ Current |

### Background/Reference Docs

| Document | Purpose | Status |
|----------|---------|--------|
| `FINDINGS_SUMMARY.md` | Research summary | ‚úÖ Reference |
| `IMPLEMENTATION_PLAN.md` | Original detailed plan | ‚ö†Ô∏è Superseded by UPDATE |
| `JSON_EXAMPLES.md` | Original API examples | ‚ö†Ô∏è Superseded by CLEAN |
| `MODEL_DISPLAY_NAMES.md` | Display name strategy | üìã Future branding |
| `OPUS_REVIEW_FINDINGS.md` | Review results | ‚úÖ Reference |

### Review Prompts (Archive)

| Document | Purpose | Status |
|----------|---------|--------|
| `OPUS_REVIEW_PROMPT.md` | Detailed review prompt | üì¶ Archive |
| `OPUS_REVIEW_PROMPT_SHORT.txt` | Quick review prompt | üì¶ Archive |

## Key Implementation Changes

### Original Plan ‚Üí Current Plan

| Aspect | Original | Current | Reason |
|--------|----------|---------|--------|
| **Files per day** | 9 separate | 1 combined | Simpler testing |
| **Endpoint** | `/subsets/{id}/{date}` | `/picks/{date}` | One API call |
| **Group names** | `v9_high_edge_top5` | "Top 5" or "2" | Hide internals |
| **Model names** | `catboost_v9` | "926A" | Testing codename |
| **Technical details** | Included | **Removed** | Prevent reverse-engineering |

## Implementation Checklist

### Phase 0: Prerequisites ‚úÖ
- [x] Model attribution deployed (prediction-worker rev 00081-z97)
- [x] Waiting for verification (next prediction run)

### Phase 1: Subset Exporters (3-4 days)
- [ ] Create `shared/config/model_codenames.py` ‚úÖ Done
- [ ] Create `shared/config/subset_public_names.py`
- [ ] Create `SubsetDefinitionsExporter`
- [ ] Create `DailySignalsExporter`
- [ ] Create `AllSubsetsPicksExporter` (main endpoint)
- [ ] Create `SubsetPerformanceExporter`
- [ ] Update `daily_export.py` orchestration
- [ ] Integration testing

### Phase 2: Model Attribution (2-3 days)
- [ ] Create `ModelRegistryExporter`
- [ ] Modify `SystemPerformanceExporter`
- [ ] Modify `PredictionsExporter`
- [ ] Modify `BestBetsExporter`
- [ ] Integration testing

## Quick Reference

### Endpoints Being Created

| Endpoint | Purpose | File Count |
|----------|---------|------------|
| `/picks/{date}.json` | **All 9 groups' picks** | 1/day |
| `/signals/{date}.json` | Daily market signal | 1/day |
| `/systems/subsets.json` | Group definitions | 1 total |
| `/subsets/performance.json` | Group comparison | 1 total |
| `/systems/models.json` | Model registry | 1 total |

### Codename Mappings

**Models:**
- catboost_v9 ‚Üí 926A
- catboost_v9_202602 ‚Üí 926B
- ensemble_v1 ‚Üí E01

**Groups:**
- v9_high_edge_top1 ‚Üí "Top Pick" or "1"
- v9_high_edge_top5 ‚Üí "Top 5" or "2"
- v9_high_edge_top10 ‚Üí "Top 10" or "3"
- v9_high_edge_balanced ‚Üí "Best Value" or "4"

### What NOT to Export

**Never include in API responses:**
- ‚ùå `system_id` (catboost_v9)
- ‚ùå `subset_id` (v9_high_edge_top5)
- ‚ùå `confidence_score`
- ‚ùå `edge` / `line_margin`
- ‚ùå `composite_score`
- ‚ùå Algorithm names
- ‚ùå Feature counts
- ‚ùå Training details
- ‚ùå Formulas or thresholds

## Testing Commands

```bash
# Verify clean API
gsutil cat gs://nba-props-platform-api/v1/picks/$(date +%Y-%m-%d).json | \
  grep -E "(system_id|subset_id|confidence|edge|composite)" && \
  echo "‚ùå Leaked!" || echo "‚úÖ Clean!"

# Verify structure
gsutil cat gs://nba-props-platform-api/v1/picks/$(date +%Y-%m-%d).json | \
  jq '{model, groups: (.groups | length)}'
# Expected: {"model": "926A", "groups": 9}

# Verify pick fields
gsutil cat gs://nba-props-platform-api/v1/picks/$(date +%Y-%m-%d).json | \
  jq '.groups[0].picks[0] | keys'
# Expected: ["player", "team", "opponent", "prediction", "line", "direction"]
```

## Questions?

1. **Implementation questions** ‚Üí See `IMPLEMENTATION_UPDATE.md`
2. **API design questions** ‚Üí See `CLEAN_API_STRUCTURE.md`
3. **Timeline questions** ‚Üí See `ACTION_PLAN.md`
4. **"Why these decisions?"** ‚Üí See `FINDINGS_SUMMARY.md`
5. **"Was this validated?"** ‚Üí See `OPUS_REVIEW_FINDINGS.md`

## Next Steps

1. Wait for model attribution verification (tomorrow morning)
2. Create config files (`model_codenames.py`, `subset_public_names.py`)
3. Begin Phase 1 exporter implementation
4. Test with clean API structure
5. Deploy and monitor

**Ready to implement!** üöÄ
