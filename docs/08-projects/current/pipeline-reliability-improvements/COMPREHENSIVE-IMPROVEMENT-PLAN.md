# Comprehensive Pipeline Improvement Plan
**Created**: 2026-01-01
**Status**: Ready for Implementation
**Based On**: Deep investigation + PIPELINE_SCAN_REPORT + Current system state

---

## üìä Current State Summary

### ‚úÖ What's Working
- **Predictions**: Generating successfully (340 for tonight)
- **Core data**: Gamebook, BDL, Schedule all fresh
- **Schedulers**: All 30 running correctly
- **Fallback systems**: Verified working
- **Recent fixes**: PlayerGameSummaryProcessor (100% success), BigQuery timeouts, Security

### ‚ö†Ô∏è What Needs Improvement
- **Monitoring gaps**: Issues detected manually, not automatically
- **Workflow failures**: 4 workflows failing 18-22% of executions
- **Circuit breaker**: 954 players locked (30-40% of roster)
- **Logging**: Cloud Run warnings with "No message"
- **Historical issues**: 348K processor failures need investigation
- **Player registry**: 929 unresolved names

---

## üéØ Improvement Categories

### TIER 1: Quick Wins (< 30 minutes each)
**Impact**: HIGH | **Effort**: LOW | **Risk**: MINIMAL

### TIER 2: Medium Effort (1-2 hours each)
**Impact**: HIGH | **Effort**: MEDIUM | **Risk**: LOW

### TIER 3: Strategic Projects (> 4 hours)
**Impact**: VERY HIGH | **Effort**: HIGH | **Risk**: MEDIUM

---

## üöÄ TIER 1: QUICK WINS (Implement Today)

### 1.1 Clean Up Backup Files ‚ö°
**Time**: 2 minutes | **Impact**: Code hygiene

**Issue**: 3 Dockerfile backup files in repo root
```bash
Dockerfile.backup.1767290347
Dockerfile.backup.1767291073
Dockerfile.backup.1767302325
```

**Fix**:
```bash
rm Dockerfile.backup.*
git add -u
git commit -m "chore: Remove Dockerfile backup files"
```

**Value**: Clean repository, no functional impact

---

### 1.2 Create API Health Check Script ‚ö°
**Time**: 15 minutes | **Impact**: Faster issue detection

**Issue**: NBA.com API outage took 5 days to discover manually

**Fix**: Create `bin/monitoring/check_api_health.sh`

```bash
#!/bin/bash
# Check critical API endpoints

echo "=== NBA Stats API Health Check ==="
echo "Time: $(date)"

# Test NBA stats API
timeout 10 curl -s "https://stats.nba.com/stats/boxscoretraditionalv2?GameID=0022500001" \
  -H "User-Agent: Mozilla/5.0" > /dev/null 2>&1

if [ $? -eq 0 ]; then
  echo "‚úì NBA Stats API: OK"
else
  echo "‚úó NBA Stats API: DOWN"
fi

# Test BDL API
timeout 10 curl -s -H "Authorization: $(gcloud secrets versions access latest --secret='BALLDONTLIE_API_KEY')" \
  "https://api.balldontlie.io/v1/players?per_page=1" > /dev/null 2>&1

if [ $? -eq 0 ]; then
  echo "‚úì BDL API: OK"
else
  echo "‚úó BDL API: DOWN"
fi

# Test Odds API
timeout 10 curl -s -H "x-rapidapi-key: $(gcloud secrets versions access latest --secret='ODDS_API_KEY')" \
  "https://api.the-odds-api.com/v4/sports" > /dev/null 2>&1

if [ $? -eq 0 ]; then
  echo "‚úì Odds API: OK"
else
  echo "‚úó Odds API: DOWN"
fi
```

**Deploy**: Add to cron (daily 6 AM)

**Value**: Early detection of API outages

---

### 1.3 Add Scraper Failure Alert Query ‚ö°
**Time**: 10 minutes | **Impact**: Proactive failure detection

**Issue**: Scrapers failing for days without alerts

**Fix**: Create `bin/monitoring/check_scraper_failures.sh`

```bash
#!/bin/bash
# Alert on sustained scraper failures

FAILURES=$(bq query --use_legacy_sql=false --format=csv "
SELECT
  scraper_name,
  COUNT(*) as failures
FROM \`nba-props-platform.nba_orchestration.scraper_execution_log\`
WHERE status = 'failed'
  AND triggered_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
GROUP BY scraper_name
HAVING COUNT(*) >= 10
ORDER BY failures DESC
")

if [ -n "$FAILURES" ]; then
  echo "üö® ALERT: Scrapers with >10 failures in last 24h:"
  echo "$FAILURES"
  # TODO: Send email alert
else
  echo "‚úÖ No scraper failure spikes detected"
fi
```

**Value**: Catch issues within 24h instead of 5+ days

---

### 1.4 Document Orchestration Dual Paths ‚ö°
**Time**: 20 minutes | **Impact**: Developer clarity

**Issue**: Confusion about same-day predictions vs full pipeline

**Fix**: Create `docs/03-architecture/ORCHESTRATION-PATHS.md`

**Content**:
```markdown
# Orchestration Paths

## Path 1: Full Pipeline (Historical/Backfill)
Phase 1 ‚Üí Phase 2 ‚Üí Phase 3 ‚Üí Phase 4 ‚Üí Phase 5
- Event-driven via Pub/Sub
- Firestore tracks completion per phase per date
- Used for: Historical data, backfills, batch processing

## Path 2: Same-Day Predictions (Live)
Phase 1/2 ‚Üí Phase 5 (direct)
- Time-driven via Cloud Scheduler
- Bypasses Phases 3-4 for speed
- Used for: Tonight's games, live predictions
- Schedulers:
  - overnight-predictions: 7 AM (uses yesterday's data)
  - evening-predictions: 4 PM (uses today's data)

## Why Two Paths?
- Speed: Same-day needs <2h, full pipeline takes 6-8h
- Coverage: Full pipeline ensures complete analytics
- Reliability: Both paths can generate predictions
```

**Value**: Eliminates confusion about "missing" orchestration events

---

### 1.5 Add Workflow Failure Threshold Monitoring ‚ö°
**Time**: 15 minutes | **Impact**: Escalate recurring issues

**Issue**: Workflows failing 11-12 times without escalation

**Fix**: Create `bin/monitoring/check_workflow_health.sh`

```bash
#!/bin/bash
# Check for workflow failure patterns

bq query --use_legacy_sql=false --format=pretty "
WITH recent_failures AS (
  SELECT
    workflow_name,
    DATE(execution_time) as date,
    COUNT(*) as failures,
    COUNT(DISTINCT execution_id) as attempts
  FROM \`nba-props-platform.nba_orchestration.workflow_executions\`
  WHERE status = 'failed'
    AND execution_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 48 HOUR)
  GROUP BY workflow_name, date
)
SELECT
  workflow_name,
  SUM(failures) as total_failures,
  ROUND(100.0 * SUM(failures) / SUM(attempts), 1) as failure_rate_pct
FROM recent_failures
GROUP BY workflow_name
HAVING SUM(failures) >= 5
ORDER BY total_failures DESC
" | tee /tmp/workflow_health.txt

if [ -s /tmp/workflow_health.txt ]; then
  echo "üö® ALERT: Workflows with >=5 failures in 48h detected"
fi
```

**Value**: Detect systemic issues within 2 days

---

## üîß TIER 2: MEDIUM EFFORT (Implement This Week)

### 2.1 Circuit Breaker Auto-Reset Logic üîß
**Time**: 1-2 hours | **Impact**: Improve prediction coverage

**Issue**: 954 players locked until Jan 5, reducing prediction coverage

**Current Behavior**:
```python
# Circuit breaker trips on upstream failures
# Locks entity for 3-5 days
# No auto-reset when upstream data becomes available
```

**Improved Behavior**:
```python
def should_reset_breaker(self, entity_id, upstream_table):
    """Reset breaker if upstream data now available"""
    # Check if upstream table has data for this entity
    query = f"""
    SELECT COUNT(*) as cnt
    FROM `{upstream_table}`
    WHERE entity_id = @entity_id
      AND data_date >= @breaker_trip_date
    """

    result = self.bq_client.query(query, ...).result()
    if result[0].cnt > 0:
        # Upstream data available - reset breaker
        self.reset_circuit_breaker(entity_id)
        return True
    return False
```

**Files to Modify**:
- `shared/processors/patterns/circuit_breaker_mixin.py`
- `data_processors/analytics/upcoming_player_game_context/...`

**Testing**:
```sql
-- Before: 954 locked
SELECT COUNT(*) FROM nba_analytics.circuit_breaker_state WHERE tripped = true

-- After fix + backfill: Should be <50
```

**Value**: Restore prediction coverage for 900+ players

---

### 2.2 Fix Cloud Run Logging Configuration üîß
**Time**: 1 hour | **Impact**: Diagnosable service issues

**Issue**: 50+ warnings with "No message" from Phase 4 precompute service

**Root Cause**: Structured logging not properly configured

**Current Code** (likely):
```python
logger.warning({"status": "degraded", "memory_mb": 450})  # Logged as dict
```

**Fixed Code**:
```python
import json
logger.warning(json.dumps({"status": "degraded", "memory_mb": 450}))
# OR
logger.warning("Service degraded", extra={"memory_mb": 450})
```

**Investigation Steps**:
1. Check Cloud Monitoring for Phase 4 memory/CPU metrics
2. Review `data_processors/precompute/precompute_base.py` logging calls
3. Test locally with `PYTHONPATH=. python3 -m data_processors.precompute.player_daily_cache...`
4. Fix logging format in base class
5. Redeploy Phase 4

**Value**: Ability to diagnose precompute service issues

---

### 2.3 Expand Data Freshness Monitoring üîß
**Time**: 1-2 hours | **Impact**: Catch stale data faster

**Issue**: Injuries data was 41 days stale before detection

**Current**: `boxscore-completeness-check` only checks gamebook/BDL player data

**Expand To**:
- nba_raw.bdl_injuries (threshold: 24h)
- nba_raw.odds_api_player_points_props (threshold: 12h)
- nba_raw.bettingpros_player_points_props (threshold: 12h)
- nba_analytics.player_game_summary (threshold: 24h)
- nba_predictions.player_composite_factors (threshold: 24h)

**Implementation**:

Update `functions/monitoring/data_completeness_checker/main.py`:

```python
FRESHNESS_CHECKS = [
    {
        'table': 'nba_raw.bdl_injuries',
        'threshold_hours': 24,
        'timestamp_column': 'processed_at',
        'severity': 'CRITICAL'
    },
    {
        'table': 'nba_raw.odds_api_player_points_props',
        'threshold_hours': 12,
        'timestamp_column': 'created_at',
        'severity': 'WARNING'
    },
    # ... more tables
]

def check_freshness():
    alerts = []
    for check in FRESHNESS_CHECKS:
        query = f"""
        SELECT
          TIMESTAMP_DIFF(CURRENT_TIMESTAMP(), MAX({check['timestamp_column']}), HOUR) as hours_stale
        FROM `nba-props-platform.{check['table']}`
        """
        result = bq_client.query(query).result()
        hours_stale = list(result)[0].hours_stale

        if hours_stale > check['threshold_hours']:
            alerts.append({
                'table': check['table'],
                'hours_stale': hours_stale,
                'threshold': check['threshold_hours'],
                'severity': check['severity']
            })

    if alerts:
        send_alert_email(alerts)
```

**Value**: Detect stale data within 24h instead of 41 days

---

### 2.4 Workflow Auto-Retry with Exponential Backoff üîß
**Time**: 1-2 hours | **Impact**: Reduce workflow failures

**Issue**: Workflows failing on transient errors (rate limits, API timeouts)

**Current**: Single attempt, fail immediately

**Improved**: Retry 3 times with exponential backoff

**Implementation**:

Update `orchestration/cloud_functions/workflow_orchestrator/workflow_executor.py`:

```python
import time
from google.api_core import retry

@retry.Retry(
    predicate=retry.if_transient_error,
    initial=1.0,
    maximum=60.0,
    multiplier=2.0,
    deadline=300.0
)
def execute_scraper(scraper_name, params):
    """Execute scraper with automatic retry"""
    response = requests.post(
        SCRAPER_ENDPOINT,
        json={'scraper': scraper_name, **params},
        timeout=120
    )
    response.raise_for_status()
    return response.json()

# In workflow execution
for scraper in scrapers_to_run:
    try:
        result = execute_scraper(scraper, params)
        scrapers_succeeded += 1
    except Exception as e:
        # Log but don't fail workflow if <3 scrapers
        if scrapers_failed < 3:
            logger.warning(f"Scraper {scraper} failed: {e}")
            scrapers_failed += 1
        else:
            raise  # Fail workflow if too many failures
```

**Value**: Reduce workflow failure rate from 18-22% to <5%

---

### 2.5 Player Registry Resolution Batch Job üîß
**Time**: 2 hours | **Impact**: Resolve 929 unresolved names

**Issue**: 929 players with unresolved names affecting data linkage

**Current**: Manual resolution tool exists but not run systematically

**Solution**: Create automated batch resolution job

**Implementation**:

Create `bin/registry/run_weekly_resolution.sh`:

```bash
#!/bin/bash
# Weekly player name resolution job

echo "=== Player Registry Resolution Job ==="
date

# Step 1: Identify unresolved names
UNRESOLVED=$(bq query --use_legacy_sql=false --format=csv "
SELECT DISTINCT player_lookup
FROM nba_reference.player_registry_unresolved
WHERE resolved_player_id IS NULL
LIMIT 100
" | tail -n +2)

# Step 2: Attempt resolution for each batch
echo "Found $(echo "$UNRESOLVED" | wc -l) unresolved names"

# Step 3: Run resolution tool
PYTHONPATH=. python3 tools/player_registry/resolve_unresolved_batch.py \
  --batch-size 100 \
  --confidence-threshold 0.85

# Step 4: Report results
REMAINING=$(bq query --use_legacy_sql=false --format=csv "
SELECT COUNT(DISTINCT player_lookup)
FROM nba_reference.player_registry_unresolved
WHERE resolved_player_id IS NULL
" | tail -n +2)

echo "Remaining unresolved: $REMAINING"

if [ "$REMAINING" -lt 100 ]; then
  echo "‚úÖ Registry mostly resolved (<100 remaining)"
else
  echo "‚ö†Ô∏è  Still $REMAINING unresolved names - manual review needed"
fi
```

**Schedule**: Weekly Sunday 2 AM

**Value**: Improve data linkage accuracy, reduce manual work

---

## üèóÔ∏è TIER 3: STRATEGIC PROJECTS (Next 2-4 Weeks)

### 3.1 Comprehensive Monitoring Dashboard üìä
**Time**: 4-6 hours | **Impact**: Proactive issue detection

**Goal**: Single pane of glass for pipeline health

**Components**:

1. **API Health Dashboard**
   - NBA.com Stats API uptime
   - BDL API uptime
   - Odds API uptime
   - Response time trends

2. **Scraper Health Dashboard**
   - Success rate by scraper (last 7 days)
   - Failure spike detection
   - Top 10 failing scrapers

3. **Data Freshness Dashboard**
   - Hours stale for critical tables
   - Color coding: Green (<6h), Yellow (6-24h), Red (>24h)
   - Trend lines

4. **Workflow Health Dashboard**
   - Success rate by workflow
   - Average execution time
   - Failure patterns by hour of day

5. **Prediction Coverage Dashboard**
   - Players with predictions (today)
   - Prediction count trend
   - Circuit breaker status

**Implementation**: Google Data Studio + BigQuery views

**Value**: Shift from reactive to proactive operations

---

### 3.2 Dead Letter Queue (DLQ) Infrastructure üì¶
**Time**: 3-4 hours | **Impact**: Message recovery capability

**Current**: Failed messages lost forever

**Goal**: Capture and replay failed messages

**Components**:

1. **Create DLQ Subscriptions**:
```bash
# For each main subscription
gcloud pubsub topics create nba-phase1-scrapers-complete-dlq
gcloud pubsub subscriptions create nba-phase1-scrapers-complete-dlq-sub \
  --topic=nba-phase1-scrapers-complete-dlq \
  --ack-deadline=600

# Update main subscription with DLQ
gcloud pubsub subscriptions update nba-phase1-scrapers-complete-sub \
  --dead-letter-topic=nba-phase1-scrapers-complete-dlq \
  --max-delivery-attempts=5
```

2. **Deploy DLQ Monitor Function**:
   - Already exists: `orchestration/cloud_functions/dlq_monitor/main.py`
   - Deploy with scheduler (daily 9 AM)
   - Email alerts when DLQ has messages

3. **Create Replay Tool**:
```python
# bin/dlq/replay_messages.py
def replay_dlq_messages(subscription_name, limit=10):
    """Pull messages from DLQ and republish to main topic"""
    subscriber = pubsub_v1.SubscriberClient()
    response = subscriber.pull(subscription_name, max_messages=limit)

    for msg in response.received_messages:
        # Republish to main topic
        publisher.publish(main_topic, msg.message.data)
        # Acknowledge DLQ message
        subscriber.acknowledge(subscription_name, [msg.ack_id])
```

**Value**: Recover from edge case failures, audit trail

---

### 3.3 Investigate 348K Processor Failures üîç
**Time**: 4-8 hours | **Impact**: Understand historical reliability

**Goal**: Determine if 348K NbacPlayerBoxscoreProcessor failures are:
- Historical bug (now fixed)
- Ongoing issue
- Data quality problem
- Systemic design flaw

**Investigation Plan**:

1. **Temporal Analysis**:
```sql
SELECT
  DATE(run_start_at) as date,
  status,
  COUNT(*) as runs
FROM nba_reference.processor_run_history
WHERE processor_name = 'NbacPlayerBoxscoreProcessor'
  AND run_start_at >= '2024-01-01'
GROUP BY date, status
ORDER BY date
```

2. **Error Pattern Analysis**:
```sql
SELECT
  LEFT(error_message, 100) as error_pattern,
  COUNT(*) as occurrences,
  MIN(run_start_at) as first_seen,
  MAX(run_start_at) as last_seen
FROM nba_reference.processor_run_history
WHERE processor_name = 'NbacPlayerBoxscoreProcessor'
  AND status = 'failed'
GROUP BY error_pattern
ORDER BY occurrences DESC
LIMIT 20
```

3. **Recent Status Check**:
```sql
-- Are failures still happening?
SELECT DATE(run_start_at) as date, status, COUNT(*)
FROM nba_reference.processor_run_history
WHERE processor_name = 'NbacPlayerBoxscoreProcessor'
  AND run_start_at >= CURRENT_DATE() - 30
GROUP BY date, status
ORDER BY date DESC
```

4. **Code History Review**:
```bash
git log --all --oneline -- data_processors/raw/nbacom/nbac_player_boxscore_processor.py
# Check for major changes around failure spikes
```

**Outcomes**:
- If historical: Document and close
- If ongoing: Fix root cause
- If design flaw: Refactor processor

**Value**: Prevent future cascading failures

---

### 3.4 Enhanced Alert System with PagerDuty üì¢
**Time**: 3-4 hours | **Impact**: Faster incident response

**Current**: Email alerts (may be ignored/delayed)

**Goal**: Tiered alerting with escalation

**Implementation**:

1. **Severity Levels**:
   - **P0 (Page immediately)**: Predictions not generating, API down >4h
   - **P1 (Alert within 1h)**: Scraper failures >20 in 24h, data >24h stale
   - **P2 (Email)**: Workflow failures, non-critical warnings
   - **P3 (Log)**: Informational, metrics

2. **Integration**:
```python
# shared/alerts/pagerduty_integration.py
def send_pagerduty_alert(severity, title, message, details):
    if severity == 'P0':
        # Page on-call
        requests.post(
            'https://events.pagerduty.com/v2/enqueue',
            json={
                'routing_key': PAGERDUTY_KEY,
                'event_action': 'trigger',
                'payload': {
                    'summary': title,
                    'severity': 'critical',
                    'source': 'nba-pipeline',
                    'custom_details': details
                }
            }
        )
    elif severity in ['P1', 'P2']:
        # Email alert
        send_email_alert(title, message)
```

3. **Alert Rules**:
   - Predictions not running: P0
   - API down >4h: P0
   - Data stale >48h: P1
   - Scraper failures >20/24h: P1
   - Workflow failures >5/24h: P2

**Value**: Reduce MTTR (mean time to recovery)

---

## üìÖ Recommended Implementation Schedule

### Week 1 (Jan 2-8)
**Focus**: Quick wins + critical monitoring

**Day 1-2 (Jan 2-3)**:
- ‚úÖ 1.1 Clean up backup files (2 min)
- ‚úÖ 1.2 API health check script (15 min)
- ‚úÖ 1.3 Scraper failure alerts (10 min)
- ‚úÖ 1.4 Document orchestration paths (20 min)
- ‚úÖ 1.5 Workflow failure monitoring (15 min)
- ‚è±Ô∏è Total: ~1 hour

**Day 3-4 (Jan 4-5)**:
- ‚úÖ 2.1 Circuit breaker auto-reset (1-2h)
- ‚úÖ 2.2 Fix Cloud Run logging (1h)
- ‚è±Ô∏è Total: ~3 hours

**Day 5 (Jan 6)**:
- ‚úÖ 2.3 Expand freshness monitoring (2h)
- Test all new monitoring scripts

### Week 2 (Jan 9-15)
**Focus**: Workflow reliability + registry

**Day 1-2**:
- ‚úÖ 2.4 Workflow auto-retry logic (2h)
- Deploy and test

**Day 3-4**:
- ‚úÖ 2.5 Player registry resolution (2h)
- Run initial batch, validate results

**Day 5**:
- ‚úÖ Monitor NBA API for recovery
- Backfill team boxscore when API restored

### Week 3-4 (Jan 16-31)
**Focus**: Strategic projects

**Week 3**:
- ‚úÖ 3.1 Monitoring dashboard (4-6h over week)

**Week 4**:
- ‚úÖ 3.2 DLQ infrastructure (3-4h)
- ‚úÖ 3.3 Investigate 348K failures (4-8h)

### Ongoing
- Daily: Run new monitoring scripts
- Weekly: Player registry resolution
- Monthly: Review processor failure patterns

---

## üìä Success Metrics

### Week 1 Targets
- ‚úÖ All 5 quick wins deployed
- ‚úÖ Monitoring scripts running daily
- ‚úÖ Circuit breaker locked players <100 (from 954)
- ‚úÖ Cloud Run warnings have messages

### Month 1 Targets
- Workflow failure rate <5% (from 18-22%)
- Data freshness alerts triggered within 24h
- Player registry unresolved <100 (from 929)
- Monitoring dashboard operational

### Quarter 1 Targets
- Zero data >48h stale without alert
- DLQ infrastructure operational
- 348K processor failure investigation complete
- Alert escalation system live

---

## üéØ Quick Start Guide

**To start improving today:**

1. **Clone and branch**:
```bash
git checkout -b improvements/week1-quick-wins
```

2. **Run quick wins in order**:
```bash
# 1.1 Clean up
rm Dockerfile.backup.*

# 1.2-1.5 Create monitoring scripts
mkdir -p bin/monitoring
# Create scripts from templates above
chmod +x bin/monitoring/*.sh
```

3. **Test monitoring**:
```bash
./bin/monitoring/check_api_health.sh
./bin/monitoring/check_scraper_failures.sh
./bin/monitoring/check_workflow_health.sh
```

4. **Commit and deploy**:
```bash
git add bin/monitoring/ docs/
git commit -m "feat: Add monitoring scripts and documentation"
git push origin improvements/week1-quick-wins
```

5. **Schedule jobs**:
```bash
# Add to Cloud Scheduler
gcloud scheduler jobs create http api-health-check \
  --schedule="0 6 * * *" \
  --uri="<cloud-function-url>" \
  --http-method=GET
```

---

## üöÄ Ready to Start?

**Recommended first session**: Implement all 5 quick wins (~1 hour total)

This will give immediate value:
- ‚úÖ Cleaner repository
- ‚úÖ Proactive API monitoring
- ‚úÖ Early failure detection
- ‚úÖ Better team understanding
- ‚úÖ Workflow health visibility

**Next session**: Circuit breaker + logging fixes (3-4 hours)

---

**Created by**: Claude Code
**Date**: 2026-01-01
**Status**: Ready for implementation
**Estimated Total Time**: ~30-40 hours over 4 weeks
**Expected Impact**: 10x improvement in reliability and observability
