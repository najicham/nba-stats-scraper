# Data Quality Investigation - Session Handoff
**Date**: 2026-01-28
**Session Duration**: 4+ hours
**Previous Session**: 2026-01-27 (Opus)
**Model**: Opus 4.5

---

## Executive Summary

### âœ… Major Accomplishments

1. **Fixed 4 Critical Code Bugs**:
   - Coordinator import path (`data_loaders` â†’ `predictions.worker.data_loaders`)
   - Coordinator syntax error (missing comma in `coverage_monitor.py`)
   - Pub/Sub IAM permissions (granted `iam.serviceAccountTokenCreator`)
   - **20.0 placeholder line bug** (v3.11 fix - skip 20.0 in line spread generation)

2. **Deployed All Fixes**:
   - Coordinator revision 00092-ch2 deployed
   - No more LINE QUALITY validation errors
   - Workers processing requests successfully (204 responses)

3. **Pushed 34 Commits to Origin**

4. **Comprehensive Data Validation Completed**:
   - Jan 20-27: HEALTHY (0 duplicates, 93-99% usage_rate)
   - Last 2 months: Found December analytics gap
   - Full season: Identified critical issues

5. **Triggered Phase 3 Analytics for Jan 27**:
   - 212 player_game_summary records created
   - 6 of 7 games processed

---

## âš ï¸ CRITICAL: Root Cause Investigation Required

**KEY INSIGHT**: We've been fixing symptoms (bugs, missing data) without understanding WHY these issues occur. The next session MUST focus on understanding root causes and systemic improvements.

### ğŸ” Fundamental Questions That Need Answers

#### Question #1: Why Does December Have a 15-Day Analytics Gap?
**Facts**:
- Raw data exists (nbac_gamebook has 3,500+ records for Dec 16-31)
- Analytics has only 51-82% of those records
- **Missing ~2,000 player-game records**

**Root Cause Unknown**:
- Did Phase 3 analytics processor fail silently?
- Was there a code bug during December that's now fixed?
- Is there a data quality filter excluding records?
- Were games marked with wrong status during December?

**Investigation Required**:
```bash
# Check processor run history for December
SELECT processor_name, data_date, status, skip_reason, errors, warnings
FROM `nba-props-platform.nba_reference.processor_run_history`
WHERE data_date BETWEEN '2025-12-16' AND '2025-12-31'
  AND processor_name LIKE '%player_game%'
ORDER BY data_date

# Compare raw vs analytics to find patterns
SELECT
  r.game_date,
  COUNT(DISTINCT r.player_lookup) as raw_players,
  COUNT(DISTINCT a.player_lookup) as analytics_players,
  COUNT(DISTINCT r.player_lookup) - COUNT(DISTINCT a.player_lookup) as missing
FROM `nba-props-platform.nba_raw.nbac_gamebook` r
LEFT JOIN `nba-props-platform.nba_analytics.player_game_summary` a
  ON r.player_lookup = a.player_lookup AND r.game_date = a.game_date
WHERE r.game_date BETWEEN '2025-12-16' AND '2025-12-31'
GROUP BY r.game_date
ORDER BY missing DESC
```

#### Question #2: Why Did November Have Duplicates?
**Facts**:
- 123 duplicate records on Nov 10 and Nov 13
- ALL duplicates are from November (none before/after)
- Same game processed twice somehow

**Root Cause Unknown**:
- Was there a deployment during November that caused double-processing?
- Did a manual backfill overlap with scheduled processing?
- Is there a race condition in the analytics processor?
- Why only these 2 specific dates?

**Investigation Required**:
```bash
# Find the duplicate records and their timestamps
SELECT game_date, game_id, player_lookup,
  COUNT(*) as count,
  STRING_AGG(CAST(processed_at AS STRING)) as processed_times
FROM `nba-props-platform.nba_analytics.player_game_summary`
WHERE game_date IN ('2025-11-10', '2025-11-13')
GROUP BY game_date, game_id, player_lookup
HAVING count > 1
ORDER BY count DESC

# Check processor run history for double-runs
SELECT data_date, processor_name, run_id, started_at, status, trigger_source
FROM `nba-props-platform.nba_reference.processor_run_history`
WHERE data_date IN ('2025-11-10', '2025-11-13')
  AND processor_name LIKE '%player_game%'
ORDER BY data_date, started_at
```

#### Question #3: Why Is usage_rate Coverage Only 60%?
**Facts**:
- 60% of active players have usage_rate in January
- 0% coverage in October-November
- 40% of players missing usage_rate even with minutes played

**Root Cause Unknown**:
- Is 60% expected (DNPs, garbage time players)?
- Is team_offense_game_summary incomplete?
- Was usage_rate calculation disabled until late December?
- What changed around Dec 29 to jump from 0% to 60%?

**Investigation Required**:
```bash
# Check team stats availability
SELECT
  p.game_date,
  COUNT(DISTINCT p.player_lookup) as players_with_minutes,
  COUNT(DISTINCT CASE WHEN p.usage_rate IS NOT NULL THEN p.player_lookup END) as players_with_usage,
  COUNT(DISTINCT t.game_id) as games_with_team_stats
FROM `nba-props-platform.nba_analytics.player_game_summary` p
LEFT JOIN `nba-props-platform.nba_analytics.team_offense_game_summary` t
  ON p.game_id = t.game_id
WHERE p.game_date >= '2025-12-01' AND p.minutes_played > 0
GROUP BY p.game_date
ORDER BY p.game_date
```

#### Question #4: Why Are There usage_rate Values > 100%?
**Facts**:
- 27 players have usage_rate > 50%
- Some exceed 100% (physically impossible)
- Example: deandreayton at 264.9% on Jan 24

**Root Cause Unknown**:
- Bug in usage_rate calculation formula?
- Team stats corrupted for specific games?
- Division by zero or null handling issue?
- Data type overflow?

**Investigation Required**:
```bash
# Find the source data for anomalous values
SELECT
  p.player_lookup, p.game_date, p.game_id,
  p.usage_rate,
  p.field_goal_attempts as fga,
  p.free_throw_attempts as fta,
  p.turnovers as tov,
  p.minutes_played as mp,
  t.field_goal_attempts as team_fga,
  t.free_throw_attempts as team_fta,
  t.turnovers as team_tov,
  t.minutes_played as team_mp
FROM `nba-props-platform.nba_analytics.player_game_summary` p
LEFT JOIN `nba-props-platform.nba_analytics.team_offense_game_summary` t
  ON p.game_id = t.game_id
WHERE p.usage_rate > 50
ORDER BY p.usage_rate DESC
```

#### Question #5: Why Didn't Phase 4 Run Automatically After Phase 3?
**Facts**:
- Phase 3 completed successfully (212 records created)
- Phase 4 did NOT trigger automatically
- Pipeline appears to require manual intervention

**Root Cause Unknown**:
- Is Phase 4 scheduled independently (Cloud Scheduler)?
- Does Phase 3 publish a Pub/Sub event that Phase 4 should consume?
- Is there a dependency check that failed?
- Was Phase 4 service down or scaled to zero?

**Investigation Required**:
```bash
# Check Cloud Run services
gcloud run services list --platform=managed --region=us-west2 | grep -i phase

# Check Cloud Scheduler jobs
gcloud scheduler jobs list --location=us-west2 | grep -i phase

# Check Pub/Sub topics for phase transitions
gcloud pubsub topics list | grep -E 'phase|analytics|precompute'

# Check processor run history for Phase 4
SELECT processor_name, data_date, status, started_at, errors
FROM `nba-props-platform.nba_reference.processor_run_history`
WHERE data_date = '2026-01-27'
  AND processor_name LIKE '%feature%'
ORDER BY started_at DESC
```

#### Question #6: What Is the Expected End-to-End Data Flow?
**Unknown**:
- What triggers each phase?
- How do phases communicate (Pub/Sub, Scheduler, webhooks)?
- What are the expected SLAs for each phase?
- Where are the monitoring/alerting gaps?

**Investigation Required**:
- Map the complete data pipeline architecture
- Document trigger mechanisms for each phase
- Identify failure points and error handling
- Create dependency graph (which phases depend on what)

---

### ğŸ“‹ Systematic Validation Framework Needed

Instead of ad-hoc validation, we need a comprehensive framework:

#### 1. Pipeline Health Validation
- [ ] Check each phase (1-5) completion for recent dates
- [ ] Identify which phase is the bottleneck
- [ ] Validate phase dependencies are met
- [ ] Check for silent failures (200 OK but no data)

#### 2. Data Completeness Validation
- [ ] Raw â†’ Analytics join analysis (what's dropped?)
- [ ] Analytics â†’ Predictions join analysis (what's filtered?)
- [ ] Temporal patterns (are Mondays worse than Fridays?)
- [ ] Team patterns (are specific teams missing more data?)

#### 3. Data Quality Validation
- [ ] Statistical anomaly detection (usage_rate > 100%)
- [ ] Cross-source validation (BDL vs NBAC vs ESPN)
- [ ] Historical consistency (did averages suddenly change?)
- [ ] Referential integrity (orphaned records, foreign key violations)

#### 4. Process Validation
- [ ] Execution log analysis (failures, warnings, skip reasons)
- [ ] Performance metrics (processing time trends)
- [ ] Resource utilization (are services running out of memory?)
- [ ] Error pattern analysis (same errors recurring?)

---

## ğŸ”´ Critical Blockers

### BLOCKER #1: Jan 27 Predictions Still Failing
**Status**: Phase 4 precompute (ml_feature_store_v2) has NOT run for Jan 27

**Issue Chain**:
```
Phase 1: Raw boxscores         âœ… Complete (BDL scraped 6/7 games)
Phase 2: Enrichment            âœ… Complete
Phase 3: Analytics             âœ… Complete (212 player_game_summary records)
Phase 4: Precompute            âŒ BLOCKED (ml_feature_store_v2 missing)
Phase 5: Predictions           âŒ BLOCKED (workers fail with no_features)
```

**Current Prediction Batch**:
- `batch_2026-01-27_1769572961`
- 122 requests published
- 0 completed (all failing with `no_features`)

**Immediate Action Required**:
```bash
# Trigger Phase 4 precompute for Jan 27
# Find Phase 4 trigger endpoint (similar to Phase 3)
curl -X POST "https://[phase4-service-url]/process-date-range" \
  -H "Authorization: Bearer $(gcloud auth print-identity-token)" \
  -H "Content-Type: application/json" \
  -d '{"start_date": "2026-01-27", "end_date": "2026-01-27"}'

# After Phase 4 completes, re-trigger predictions
curl -X POST "https://prediction-coordinator-756957797294.us-west2.run.app/start" \
  -H "Authorization: Bearer $(gcloud auth print-identity-token)" \
  -H "Content-Type: application/json" \
  -d '{"game_date": "2026-01-27"}'
```

---

### BLOCKER #2: December Analytics Gap (P1 CRITICAL)
**Status**: 15 days in December have incomplete analytics (51-82% completion)

**Affected Dates**: Dec 16-31, 2025
**Impact**:
- ~2,000 missing player-game records
- Rolling averages corrupted for Dec 16 - Jan 20 window
- ~2,000+ predictions potentially degraded

**Cascade Effect**:
- L5 averages: Dec 16 - Jan 5 (corrupted)
- L10 averages: Dec 16 - Jan 10 (corrupted)
- ML features: Dec 16 - Jan 20 (degraded)

**Remediation** (URGENT):
```bash
# Step 1: Backfill Phase 3 analytics for December
python scripts/backfill_player_game_summary.py \
  --start-date 2025-12-16 \
  --end-date 2025-12-31

# Step 2: Regenerate cache for cascade window
python scripts/regenerate_player_daily_cache.py \
  --start-date 2025-12-16 \
  --end-date 2026-01-20

# Step 3: Verify completion rates improved
bq query --use_legacy_sql=false --location=us-west2 "
SELECT game_date,
  COUNT(*) as analytics_count,
  ROUND(100.0 * COUNT(CASE WHEN minutes_played IS NOT NULL THEN 1 END) / COUNT(*), 1) as pct_with_minutes
FROM \`nba-props-platform.nba_analytics.player_game_summary\`
WHERE game_date BETWEEN '2025-12-16' AND '2025-12-31'
GROUP BY game_date
ORDER BY game_date"
```

---

## ğŸŸ¡ High Priority Issues

### ISSUE #1: November Duplicates (123 records)
**Dates**: Nov 10, Nov 13, 2025
**Impact**: Corrupted averaging calculations

```bash
# Deduplicate November data
python scripts/deduplicate_player_game_summary.py \
  --start-date 2025-11-10 \
  --end-date 2025-11-13
```

### ISSUE #2: January Incomplete Days
**Dates**: Jan 8 (84%), Jan 13 (71%), Jan 24 (88%)

**Note**: Jan 8 backfill FAILED with code bug:
```
'PlayerGameSummaryProcessor' object has no attribute 'track_source_coverage_event'
```

**Fix Required**:
1. Add missing `track_source_coverage_event` method to `PlayerGameSummaryProcessor`
2. Re-run backfill for Jan 8

```bash
# After code fix
python scripts/backfill_player_game_summary.py \
  --start-date 2026-01-08 --end-date 2026-01-08
python scripts/backfill_player_game_summary.py \
  --start-date 2026-01-13 --end-date 2026-01-13
python scripts/backfill_player_game_summary.py \
  --start-date 2026-01-24 --end-date 2026-01-24
```

### ISSUE #3: Usage Rate Anomalies
**Issue**: 27 players with usage_rate > 50% (some > 100%)

**Examples**:
- `deandreayton` (Jan 24): 264.9% usage rate (IMPOSSIBLE)
- `jeremiahrobinsonearl` (Jan 24): 121.4%
- `brandinpodziemski` (Jan 25): 99.4%

**Root Cause**: Team stats missing or incorrect
**Action**: Investigate team_offense_game_summary for affected games

---

## ğŸ“Š Validation Summary

### Recent Data (Jan 20-27, 2026)
| Metric | Status |
|--------|--------|
| Duplicates | âœ… 0 across all dates |
| usage_rate coverage | âœ… 93-99% for active players |
| Analytics completeness | âœ… 100% (6/6 completed dates) |
| Predictions | âš ï¸ Jan 26: 0 predictions (investigate) |

**Overall**: **HEALTHY with minor warnings**

### Last 2 Months (Dec 1, 2025 - Jan 27, 2026)
| Metric | Value | Assessment |
|--------|-------|------------|
| Analytics coverage | 57/58 days (98.3%) | HEALTHY |
| Predictions coverage | 53/57 game days (93.0%) | WARNING |
| Duplicates | 0 | HEALTHY |
| usage_rate coverage | 34.4% | WARNING (improved to 60% in Jan) |
| INCOMPLETE dates | 18 dates | WARNING |

**Problem Dates**:
- **SEVERE**: Dec 30 (41% completion)
- **MODERATE**: Dec 16-29 (15 dates, 51-82% completion)
- **MINOR**: Jan 8, 13, 24 (70-88% completion)

**Overall**: **WARNING** - December analytics gap requires remediation

### Full Season (Oct 22, 2025 - Jan 28, 2026)
| Metric | Value |
|--------|-------|
| Total game days | 95 |
| Days with analytics | 96 (96.9%) |
| Days with predictions | 78 (78.8%) |
| Total analytics records | 21,703 |
| Total predictions | 37,747 |
| Total duplicates | 123 (all in November) |

**Critical Issues**:
1. **December analytics gap** (Dec 16-31): 15 days incomplete
2. **November duplicates** (Nov 10, 13): 123 duplicate records
3. **Usage rate anomalies**: 27 players > 50% usage

**Overall**: **DEGRADED** - December analytics gap requires immediate remediation

---

## ğŸ› Code Bugs Fixed This Session

### Bug #1: Coordinator Import Path
**File**: `predictions/coordinator/coordinator.py:846`
**Fix**: Changed `from data_loaders import` â†’ `from predictions.worker.data_loaders import`
**Commit**: b02a2b04

### Bug #2: Coordinator Syntax Error
**File**: `predictions/coordinator/coverage_monitor.py:326`
**Fix**: Added missing comma in `notify_warning()` call
**Commit**: e3fe2a67

### Bug #3: 20.0 Placeholder Lines (v3.11)
**File**: `predictions/coordinator/player_loader.py:507-525`
**Issue**: When generating line spreads (e.g., 19.0, 20.0, 21.0), the value 20.0 was included
**Fix**: Skip 20.0 in spread generation, adjust single lines that are exactly 20.0
**Commit**: e7203314

**Before**:
```python
while current <= base_line + line_range:
    lines.append(round(current, 1))  # Would include 20.0
    current += line_increment
```

**After**:
```python
while current <= base_line + line_range:
    rounded = round(current, 1)
    if rounded != 20.0:  # Skip 20.0
        lines.append(rounded)
    current += line_increment
```

### Bug #4: Pub/Sub IAM Permissions
**Service Account**: `prediction-worker@nba-props-platform.iam.gserviceaccount.com`
**Missing Permission**: `roles/iam.serviceAccountTokenCreator`
**Fix**: Granted to `service-756957797294@gcp-sa-pubsub.iam.gserviceaccount.com`

---

## ğŸ” Root Cause: 20.0 Placeholder Issue

**Question**: "How did 20.0 values appear if we disabled default lines?"

**Answer**: The 20.0 values were NOT from the old `use_default_line` mechanism (disabled in v3.10). They came from a different source:

### Multiple Line Generation
When `use_multiple_lines=True` (default in production):
```python
# Config
line_range_points = 2.0  # Â±2.0 from base line
line_increment = 1.0     # 1.0 point increments

# Example: Player has prop line 21.0
base_line = 21.0
# Generates: [19.0, 20.0, 21.0, 22.0, 23.0]
#                   ^^^^
#            This 20.0 gets flagged as placeholder!
```

**Timeline of Default Line Fixes**:
1. âœ… v3.10 (Jan 23): Disabled `use_default_line` (15.5 hardcoded default)
2. âœ… v3.10 (Jan 23): Disabled `ESTIMATED_AVG` for players without props
3. âœ… v3.9 (Jan 23): Added adjustment for single estimated lines (20.0 â†’ 20.5/19.5)
4. âŒ **MISSED**: Spread generation still included 20.0
5. âœ… v3.11 (Jan 28 - THIS SESSION): Skip 20.0 in spread generation

---

## ğŸ“ Key Files Modified

### Prediction System
- `predictions/coordinator/coordinator.py` - Fixed import path
- `predictions/coordinator/coverage_monitor.py` - Fixed syntax error
- `predictions/coordinator/player_loader.py` - Fixed 20.0 generation (v3.11)

### Configuration
- IAM: `prediction-worker` service account

### Documentation
- This handoff document

---

## ğŸš€ Revised Next Steps: Investigation-First Approach

**CRITICAL MINDSET SHIFT**: Stop patching symptoms. Understand WHY issues occur, THEN fix systematically.

### Phase 1: Root Cause Investigation (PRIORITY)

#### 1A. Understand the Data Pipeline Architecture (DAY 1)
**Goal**: Map complete end-to-end flow from raw data â†’ predictions

Tasks:
- [ ] Document all 5 phases and their trigger mechanisms
- [ ] Identify Cloud Run services, Schedulers, and Pub/Sub topics for each phase
- [ ] Create dependency graph (what triggers what)
- [ ] Find where automatic phase transitions should happen but don't
- [ ] Document expected SLAs for each phase

**Output**: Architecture diagram + documented triggers

#### 1B. Investigate December Analytics Gap (DAY 1)
**Goal**: Understand WHY 15 days are incomplete (51-82%)

Tasks:
- [ ] Check processor_run_history for December failures/warnings
- [ ] Compare raw vs analytics to find patterns (which players/teams/games drop?)
- [ ] Check if there was a code deployment during Dec 16-31 that caused issues
- [ ] Investigate if game status was wrong during December
- [ ] Check if Phase 3 failed silently or never ran

**Output**: Root cause document explaining the gap

#### 1C. Investigate November Duplicates (DAY 1)
**Goal**: Understand WHY only Nov 10/13 have duplicates

Tasks:
- [ ] Check processor_run_history for double-runs on those dates
- [ ] Check deployment history around Nov 10/13
- [ ] Identify if manual backfill overlapped with scheduled run
- [ ] Look for race conditions in analytics processor code

**Output**: Root cause + prevention strategy

#### 1D. Investigate usage_rate Coverage (DAY 2)
**Goal**: Understand if 60% coverage is expected or a bug

Tasks:
- [ ] Validate team_offense_game_summary completeness
- [ ] Check what changed around Dec 29 (0% â†’ 60% jump)
- [ ] Determine expected coverage for DNPs and garbage-time players
- [ ] Investigate the 40% without usage_rate (are they low-minute players?)

**Output**: Expected vs actual coverage analysis

#### 1E. Investigate usage_rate Anomalies >100% (DAY 2)
**Goal**: Find bug in calculation or data corruption

Tasks:
- [ ] Get source data (player stats + team stats) for anomalous cases
- [ ] Reproduce calculation manually to find formula bug
- [ ] Check for division by zero, null handling, or data type issues
- [ ] Review usage_rate calculation code in analytics processor

**Output**: Bug fix or data correction

### Phase 2: Systematic Validation Framework (DAY 3)

#### 2A. Build Pipeline Health Dashboard
```sql
-- Create view that shows phase completion by date
CREATE OR REPLACE VIEW `nba-props-platform.nba_reference.pipeline_health_by_date` AS
SELECT
  game_date,
  -- Phase 1: Raw scraping
  (SELECT COUNT(*) FROM `nba_raw.nbac_gamebook` WHERE game_date = d.game_date) as phase1_records,
  -- Phase 2: Enrichment
  (SELECT COUNT(*) FROM `nba_enriched.some_table` WHERE game_date = d.game_date) as phase2_records,
  -- Phase 3: Analytics
  (SELECT COUNT(*) FROM `nba_analytics.player_game_summary` WHERE game_date = d.game_date) as phase3_records,
  -- Phase 4: Precompute
  (SELECT COUNT(*) FROM `nba_precompute.ml_feature_store_v2` WHERE game_date = d.game_date) as phase4_records,
  -- Phase 5: Predictions
  (SELECT COUNT(*) FROM `nba_predictions.player_prop_predictions` WHERE game_date = d.game_date AND is_active = TRUE) as phase5_records
FROM (SELECT DISTINCT game_date FROM `nba_raw.nbac_schedule` WHERE game_date >= '2025-10-01') d
ORDER BY game_date DESC
```

#### 2B. Build Data Quality Monitoring
- [ ] Automated duplicate detection query (run daily)
- [ ] Automated completeness check (raw vs analytics vs predictions)
- [ ] Automated anomaly detection (usage_rate >100%, negative values)
- [ ] Statistical consistency checks (averages don't jump >50% day-to-day)

#### 2C. Build Process Health Monitoring
- [ ] Alert on processor failures (check processor_run_history)
- [ ] Alert on missing phase transitions (Phase 3 done but Phase 4 not started)
- [ ] Alert on data gaps (completeness <90%)
- [ ] Alert on stale data (no updates in 24 hours)

### Phase 3: Fix Root Causes (Not Symptoms) (DAY 4-5)

**ONLY after understanding root causes**, implement fixes:

#### 3A. Fix Automatic Phase Transitions
- If Phase 4 doesn't auto-trigger after Phase 3, fix the trigger mechanism
- Add monitoring to alert when phase transitions fail

#### 3B. Fix December Analytics Gap
- If root cause was a bug, fix the bug THEN backfill
- If root cause was wrong game status, fix status validation THEN backfill
- Don't backfill without understanding why it happened

#### 3C. Prevent Duplicates
- Add idempotency checks to analytics processor
- Add unique constraint to prevent duplicate inserts
- Add monitoring to detect duplicates immediately

#### 3D. Fix usage_rate Calculation
- Fix formula bugs if found
- Add validation to reject impossible values (>100%)
- Backfill corrected values

### Phase 4: Validate Fixes (DAY 5)

- [ ] Run full season validation again
- [ ] Confirm December gap is fixed (>90% completion)
- [ ] Confirm no new duplicates
- [ ] Confirm usage_rate values are reasonable
- [ ] Confirm automatic phase transitions work for new dates

---

## âš ï¸ OLD APPROACH (Patching Symptoms) - DO NOT USE

~~### 1. Generate Jan 27 Predictions~~
~~### 2. Backfill December~~
~~### 3. Deduplicate November~~

**Why this is wrong**: These are band-aids. We'll keep hitting the same issues until we understand and fix root causes.

---

## ğŸ“Š Monitoring Dashboard

### Quick Health Check Query
```bash
bq query --use_legacy_sql=false --location=us-west2 "
SELECT
  game_date,
  COUNT(*) as analytics_records,
  COUNT(DISTINCT player_lookup) as unique_players,
  ROUND(100.0 * COUNT(CASE WHEN usage_rate IS NOT NULL THEN 1 END) /
    NULLIF(COUNT(CASE WHEN minutes_played > 0 THEN 1 END), 0), 1) as usage_pct,
  (SELECT COUNT(*) FROM \`nba-props-platform.nba_predictions.player_prop_predictions\` p
   WHERE p.game_date = s.game_date AND p.is_active = TRUE) as predictions
FROM \`nba-props-platform.nba_analytics.player_game_summary\` s
WHERE game_date >= CURRENT_DATE() - 7
GROUP BY game_date
ORDER BY game_date DESC"
```

### Check for Duplicates
```bash
bq query --use_legacy_sql=false --location=us-west2 "
SELECT game_date, COUNT(*) - COUNT(DISTINCT CONCAT(player_lookup, '_', game_id)) as dupes
FROM \`nba-props-platform.nba_analytics.player_game_summary\`
WHERE game_date >= '2025-10-01'
GROUP BY game_date
HAVING dupes > 0
ORDER BY dupes DESC"
```

---

## ğŸ¯ Success Metrics

### Definition of Done for Data Quality
- [ ] Jan 27 predictions generated (>80 predictions)
- [ ] December analytics gap fixed (all dates >90% complete)
- [ ] November duplicates removed (0 duplicates)
- [ ] January gaps backfilled (Jan 8, 13, 24 all >90%)
- [ ] usage_rate anomalies investigated and documented
- [ ] Full validation run shows HEALTHY status

### Target Metrics
| Metric | Target | Current |
|--------|--------|---------|
| Analytics completeness | >90% | 78% (December gap) |
| Duplicate records | 0 | 123 (November) |
| usage_rate coverage | >90% for active | 60% (January avg) |
| Predictions per game day | >80 | 0 (Jan 27 blocked) |

---

## ğŸ“š Reference Documentation

### Investigation Docs
```
docs/08-projects/current/2026-01-27-data-quality-investigation/
â”œâ”€â”€ findings.md                    # Original findings
â”œâ”€â”€ ROOT-CAUSE-ANALYSIS.md         # Deep root cause analysis
â”œâ”€â”€ ARCHITECTURE-IMPROVEMENTS.md   # Phase 3 sub-phases design
â”œâ”€â”€ MONITORING-PLAN.md             # Alert system design
â”œâ”€â”€ LOGGING-IMPROVEMENTS.md        # Structured logging
â”œâ”€â”€ VALIDATION-REPORT.md           # Session 1 validation
â”œâ”€â”€ VALIDATION-SESSION-SUMMARY.md  # Session 1 summary
â”œâ”€â”€ COORDINATOR-FIX.md             # Stuck coordinator investigation
â”œâ”€â”€ QUICK-START-MONITORING.md      # Quick reference
â”œâ”€â”€ HANDOFF-CONTINUATION.md        # Session 1â†’2 handoff
â””â”€â”€ HANDOFF-2026-01-28.md          # This document
```

### Operational Docs
```
docs/02-operations/
â”œâ”€â”€ DEPLOYMENT.md                  # Full deployment runbook
â”œâ”€â”€ DEPLOYMENT-QUICK-REFERENCE.md  # One-page cheat sheet
â””â”€â”€ DEPLOYMENT-TROUBLESHOOTING.md  # Common issues
```

### Key Tools
```
bin/predictions/
â”œâ”€â”€ fix_stuck_coordinator.py       # Diagnose/fix stuck batches
â””â”€â”€ clear_and_restart_predictions.py

scripts/
â”œâ”€â”€ backfill_player_game_summary.py
â””â”€â”€ regenerate_player_daily_cache.py

monitoring/queries/
â”œâ”€â”€ zero_predictions.sql
â”œâ”€â”€ low_usage_coverage.sql
â”œâ”€â”€ duplicate_detection.sql
â””â”€â”€ prop_lines_missing.sql
```

---

## ğŸ’¾ Session Artifacts

### Commits Pushed (34 total)
Latest commits:
- `e7203314` - fix: Skip 20.0 when generating multiple line values (v3.11)
- `e3fe2a67` - fix: Add missing comma in coverage_monitor notify_warning call
- `b02a2b04` - fix: Correct data_loaders import path in prediction coordinator

### Deployments
- **Coordinator**: revision 00092-ch2 (deployed with all fixes)
- **Analytics**: revision 00127-ppr (from previous session)
- **Monitoring**: data-quality-alerts (from previous session)

### Agent Work
- **Phase 3 Analytics Trigger** (Opus): Created 212 player_game_summary records for Jan 27
- **Recent Validation** (Opus): Validated Jan 20-27, found healthy data
- **Historical Backfills** (Opus): Backfilled Jan 13 (62.9%), Jan 24 (59.1%), Jan 8 failed
- **2-Month Validation** (Opus): Found December analytics gap (P1 CRITICAL)
- **Full Season Validation** (Opus): Comprehensive report on Oct-Jan

---

## ğŸ”— Service URLs

### Production Services
- **Prediction Coordinator**: https://prediction-coordinator-756957797294.us-west2.run.app
- **Prediction Worker**: https://prediction-worker-f7p3g7f6ya-wl.a.run.app
- **Phase 3 Analytics**: https://nba-phase3-analytics-processors-f7p3g7f6ya-wl.a.run.app
- **Data Quality Alerts**: https://data-quality-alerts-f7p3g7f6ya-wl.a.run.app

### Monitoring
```bash
# View coordinator logs
gcloud run services logs read prediction-coordinator --region us-west2 --limit 50

# View worker logs
gcloud run services logs read prediction-worker --region us-west2 --limit 50

# Check batch status
python3 bin/predictions/fix_stuck_coordinator.py --list-stuck --hours 24
```

---

## ğŸ¤ Questions for Next Session

1. What is the Phase 4 precompute trigger mechanism?
2. Should we prioritize December backfill or Jan 27 predictions?
3. Is usage_rate at 60% acceptable, or do we need to investigate the 40% gap?
4. Are Jan 16 and Jan 18 missing predictions expected (post-game deactivation)?
5. Should we add linting/unit tests to catch syntax errors earlier?

---

## ğŸ“ Contact / Escalation

**Repository**: /home/naji/code/nba-stats-scraper
**GCP Project**: nba-props-platform
**Region**: us-west2

**Key Decision**: 57.8% usage_rate on Jan 26 was CORRECT (not a bug). Players with 0 possessions should have NULL usage_rate.

---

**Session End**: Jan 28, 2026, 04:15 UTC
**Token Usage**: ~130k/200k (65%)
**Next Agent**: Resume with Phase 4 precompute investigation
