# Phase 5 Predictions - Getting Started Guide

**File:** `docs/predictions/tutorials/01-getting-started.md`
**Created:** 2025-11-15
**Purpose:** Complete onboarding guide for Phase 5 prediction system
**Audience:** Engineers new to Phase 5 who need to understand what exists and how to use it

---

## üéØ TL;DR - What You Need to Know

**Phase 5 Status: ‚úÖ FULLY IMPLEMENTED**

- **5 prediction models:** All implemented and tested
- **Coordinator + Worker services:** Complete with data loaders
- **Cache loading pattern:** Implemented and optimized
- **Confidence scoring:** Built into each system
- **Edge calculation:** Integrated with recommendation logic
- **Code location:** `predictions/` (22 Python files, ~3,500 lines)
- **Documentation:** `docs/predictions/` (6 comprehensive docs)

**What's Ready:** Code, tests, documentation
**What's Needed:** Model training (XGBoost), infrastructure deployment, monitoring setup

---

## üìã Quick Answers to Common Questions

Based on the most frequently asked questions about Phase 5:

### Q1: What prediction models should we prioritize?

**Answer: All 5 models are already implemented. Start with this order:**

1. **Moving Average Baseline** ‚úÖ - Simple, reliable baseline (code complete)
2. **XGBoost V1** ‚ö†Ô∏è - Primary ML model (code complete, needs trained model)
3. **Zone Matchup V1** ‚úÖ - Shot zone analysis (code complete)
4. **Similarity Balanced V1** ‚úÖ - Pattern matching (code complete)
5. **Ensemble V1** ‚úÖ - Weighted combination of above 4 (code complete)

**Implementation status:**
- Moving Average, Zone Matchup, Similarity, Ensemble: **100% ready**
- XGBoost: **Code ready, using mock model** (train real model next)

**Code locations:**
```
predictions/worker/prediction_systems/
‚îú‚îÄ‚îÄ moving_average_baseline.py      # 350 lines ‚úÖ
‚îú‚îÄ‚îÄ xgboost_v1.py                   # 427 lines ‚úÖ (needs trained model)
‚îú‚îÄ‚îÄ zone_matchup_v1.py              # 380 lines ‚úÖ
‚îú‚îÄ‚îÄ similarity_balanced_v1.py       # 450 lines ‚úÖ
‚îî‚îÄ‚îÄ ensemble_v1.py                  # 487 lines ‚úÖ
```

---

### Q2: What should the ensemble weights be?

**Answer: Confidence-weighted average (already implemented)**

**Implementation:** `predictions/worker/prediction_systems/ensemble_v1.py:253-266`

```python
def _calculate_weighted_prediction(predictions: List[Dict]) -> float:
    """
    Calculate confidence-weighted average prediction

    Weight = each system's confidence score
    Prediction = Œ£(pred_i √ó conf_i) / Œ£(conf_i)
    """
    total_weight = sum(p['confidence'] for p in predictions)
    weighted_sum = sum(p['prediction'] * p['confidence'] for p in predictions)

    return weighted_sum / total_weight
```

**Why confidence-weighted?**
- Systems with higher confidence get more weight
- Automatically adapts to each player/game context
- XGBoost gets higher weight when features are complete
- Moving Average gets higher weight when player is consistent

**Example weights for a typical prediction:**
```
XGBoost:     35% (confidence: 80/100)
Moving Avg:  30% (confidence: 70/100)
Zone Match:  20% (confidence: 50/100)
Similarity:  15% (confidence: 40/100)
```

**Feature quality adjustments:**
- High quality (95+): XGBoost confidence +10 points ‚Üí more weight
- Low quality (<70): XGBoost confidence +0 points ‚Üí less weight
- Moving Average and Zone Matchup maintain stable weights

**Agreement bonuses:** `ensemble_v1.py:295-306`
- High agreement (variance < 2.0): +10 confidence points
- Good agreement (variance < 3.0): +5 confidence points
- Low agreement (variance > 6.0): -10 confidence points

---

### Q3: How do we handle low-confidence predictions?

**Answer: Multi-level thresholds with PASS recommendation (already implemented)**

**Ensemble thresholds:** `ensemble_v1.py:85-86`
```python
self.edge_threshold = 1.5          # Must beat line by 1.5+ points
self.confidence_threshold = 65.0   # Must have 65%+ confidence
```

**Recommendation logic:** `ensemble_v1.py:315-368`

```python
def _determine_ensemble_recommendation(ensemble_pred, prop_line, ensemble_conf, predictions):
    # Step 1: Check minimum confidence
    if ensemble_conf < 65.0:
        return 'PASS'

    # Step 2: Check minimum edge
    edge = abs(ensemble_pred - prop_line)
    if edge < 1.5:
        return 'PASS'

    # Step 3: Check system agreement
    if rec_counts['OVER'] > len(predictions) / 2:
        return 'OVER'
    elif rec_counts['UNDER'] > len(predictions) / 2:
        return 'UNDER'

    # Step 4: Use ensemble direction
    return 'OVER' if ensemble_pred > prop_line else 'UNDER'
```

**Confidence calculation factors:**

1. **Base confidence:** Average of component systems (40-80)
2. **Agreement bonus:** +5 to +10 (when systems agree)
3. **All systems bonus:** +5 (when all 4 predict)
4. **Agreement penalty:** -5 to -10 (when systems disagree)
5. **Final range:** Clamped to 20-95

**Low-confidence scenarios that return PASS:**

| Scenario | Confidence | Edge | Result |
|----------|------------|------|--------|
| Early season | 45 | 3.0 | PASS (confidence < 65) |
| High disagreement | 55 | 2.5 | PASS (confidence < 65) |
| Close line | 75 | 1.0 | PASS (edge < 1.5) |
| Low quality features | 60 | 2.0 | PASS (confidence < 65) |

**Quality score impact:** `xgboost_v1.py:281-291`
```python
# Data quality adjustment (¬±10 points)
quality = features.get('feature_quality_score', 80)
if quality >= 90:
    confidence += 10
elif quality >= 80:
    confidence += 7
elif quality >= 70:
    confidence += 5
else:
    confidence += 0  # Low quality ‚Üí no bonus
```

---

### Q4: Should we have different models for different player types?

**Answer: Single models with context-aware features (current approach)**

**Current implementation:**
- **One model handles all player types** (stars, role players, rookies)
- **Differentiation comes from features**, not separate models
- **Graceful degradation** for edge cases (early season, injuries)

**How the system adapts to player types:**

**Star Players (LeBron, Giannis):**
```python
# Features automatically capture star characteristics:
points_avg_season: 27.5      # High baseline
points_std_last_10: 3.2      # Consistent
usage_spike_score: 0.5       # Stable role
feature_quality_score: 98    # Excellent data

# Result: High confidence (80-90), tight predictions
```

**Role Players (3-and-D wings):**
```python
# Features capture role player volatility:
points_avg_season: 8.2       # Low baseline
points_std_last_10: 4.5      # More volatile
usage_spike_score: 2.0       # Role varies
feature_quality_score: 92    # Good data

# Result: Medium confidence (60-75), wider range
```

**Rookies (first 10 games):**
```python
# Early season handling kicks in:
early_season_flag: True
feature_quality_score: 55    # Limited data
points_std_last_10: 7.8      # High variance

# Result: Low confidence (40-60), often PASS
```

**Why this works better than separate models:**
1. **Data efficiency:** 450 players/night, not enough for player-type stratification
2. **Automatic adaptation:** Features encode player context
3. **Consistent framework:** One pipeline, easier to maintain
4. **Graceful degradation:** System naturally becomes conservative when uncertain

**Future enhancement (Phase 5.2):**
- Add `player_tier` feature (star/starter/role/bench)
- Add `career_games_played` for rookie detection
- XGBoost will learn tier-specific patterns during training

---

### Q5: What's our training data strategy?

**Answer: 3+ seasons, seasonal adjustments, weekly retraining (architecture ready)**

**Training data requirements (for XGBoost model):**

**Historical depth:**
```sql
-- Training data query structure
SELECT
    player_lookup,
    game_date,
    features,              -- 25 features (from ml_feature_store_v2)
    actual_points,         -- Ground truth (from player_game_summary)
    season,
    games_into_season
FROM training_data
WHERE season IN ('2022-23', '2023-24', '2024-25')  -- 3 seasons
  AND games_into_season >= 10  -- Skip early season (unreliable)
  AND feature_quality_score >= 70  -- Only good quality data
```

**Expected training set size:**
- **3 seasons √ó 450 players √ó 70 games** = ~94,500 games
- **After quality filtering:** ~75,000 games (80% usable)
- **Train/validation split:** 80/20 = 60K train, 15K validation

**Seasonal adjustments:** `ml_feature_store_v2.py` (already implemented)

```python
# Features include seasonal context:
features[4] = games_into_season     # 1-82 (accounts for early vs late season)
features[5] = fatigue_score         # Season fatigue (decreases over time)
features[22] = team_pace            # Adjusts to league-wide pace changes

# XGBoost learns seasonal patterns during training:
# - Early season (games 1-15): Higher uncertainty, rely on priors
# - Mid season (games 16-50): Stable patterns, high confidence
# - Late season (games 51-82): Fatigue effects, rotation changes
```

**Retraining strategy:**

**Week 1-4 (November):**
- Use **mock model** (placeholder)
- Collect production predictions + actual results
- Build evaluation dataset

**Week 5+ (December onwards):**
- Train **first real model** on 3 seasons of data
- Deploy to production
- Begin weekly retraining

**Weekly retraining flow:**
```bash
# Every Monday 2 AM (offseason window)
1. Extract last 7 days of predictions + actuals
2. Add to training dataset
3. Retrain XGBoost model on full dataset
4. Validate on holdout set (last 2 weeks)
5. If MAE < 3.5 points: deploy new model
6. If MAE >= 3.5 points: keep current model, alert team
```

**Model versioning (GCS structure):**
```
gs://nba-models-production/
‚îú‚îÄ‚îÄ xgboost/
‚îÇ   ‚îú‚îÄ‚îÄ v1.0_2024-11-15/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.json           # XGBoost model file
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metadata.json        # Training stats, feature importance
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation.json      # Validation metrics
‚îÇ   ‚îú‚îÄ‚îÄ v1.1_2024-11-22/         # Week 2 retrain
‚îÇ   ‚îú‚îÄ‚îÄ v1.2_2024-11-29/         # Week 3 retrain
‚îÇ   ‚îî‚îÄ‚îÄ current -> v1.2_2024-11-29/  # Symlink to active model
```

**Code location for model loading:** `xgboost_v1.py:204-249`

```python
def _load_model_from_gcs(model_path: str):
    """Load trained XGBoost model from GCS"""
    # Parse GCS path: gs://bucket/path/model.json
    # Download to /tmp/xgboost_model.json
    # Load with xgboost.Booster()
    # Falls back to mock model if loading fails
```

**Training script location (to be created):**
```
predictions/training/
‚îú‚îÄ‚îÄ train_xgboost.py           # Main training script
‚îú‚îÄ‚îÄ feature_engineering.py     # Feature extraction
‚îú‚îÄ‚îÄ model_evaluation.py        # Validation metrics
‚îî‚îÄ‚îÄ deploy_model.py            # Upload to GCS
```

---

## üèóÔ∏è Architecture Overview

**Phase 5 uses a coordinator-worker pattern with event-driven processing:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Cloud Scheduler (6:15 AM daily)                             ‚îÇ
‚îÇ   ‚îÇ                                                          ‚îÇ
‚îÇ   ‚ñº                                                          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ ‚îÇ COORDINATOR (Cloud Run Job)                         ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - Query 450 players with games today                ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - Publish 450 messages to Pub/Sub                   ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - Track completion (450/450)                        ‚îÇ    ‚îÇ
‚îÇ ‚îÇ                                                      ‚îÇ    ‚îÇ
‚îÇ ‚îÇ Code: predictions/coordinator/coordinator.py        ‚îÇ    ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                          ‚îÇ                                   ‚îÇ
‚îÇ                          ‚ñº                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ ‚îÇ Pub/Sub Topic: prediction-request                   ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - Fan-out pattern (1 ‚Üí 450 messages)                ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - Each message = one player to predict              ‚îÇ    ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                          ‚îÇ                                   ‚îÇ
‚îÇ                          ‚ñº                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ ‚îÇ WORKER (Cloud Run Service, 0-20 instances)          ‚îÇ    ‚îÇ
‚îÇ ‚îÇ                                                      ‚îÇ    ‚îÇ
‚îÇ ‚îÇ For each player:                                    ‚îÇ    ‚îÇ
‚îÇ ‚îÇ 1. Load features from BigQuery (~20ms)              ‚îÇ    ‚îÇ
‚îÇ ‚îÇ 2. Load historical games (~50ms)                    ‚îÇ    ‚îÇ
‚îÇ ‚îÇ 3. Run 5 prediction systems (~30ms)                 ‚îÇ    ‚îÇ
‚îÇ ‚îÇ    - Moving Average                                 ‚îÇ    ‚îÇ
‚îÇ ‚îÇ    - XGBoost                                        ‚îÇ    ‚îÇ
‚îÇ ‚îÇ    - Zone Matchup                                   ‚îÇ    ‚îÇ
‚îÇ ‚îÇ    - Similarity                                     ‚îÇ    ‚îÇ
‚îÇ ‚îÇ    - Ensemble                                       ‚îÇ    ‚îÇ
‚îÇ ‚îÇ 4. Store predictions to BigQuery (~50ms)            ‚îÇ    ‚îÇ
‚îÇ ‚îÇ 5. Publish completion event                         ‚îÇ    ‚îÇ
‚îÇ ‚îÇ                                                      ‚îÇ    ‚îÇ
‚îÇ ‚îÇ Code: predictions/worker/worker.py                  ‚îÇ    ‚îÇ
‚îÇ ‚îÇ Systems: predictions/worker/prediction_systems/     ‚îÇ    ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                          ‚îÇ                                   ‚îÇ
‚îÇ                          ‚ñº                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ ‚îÇ BigQuery: nba_predictions.player_prop_predictions   ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - 450 players √ó 5 systems = 2,250 predictions       ‚îÇ    ‚îÇ
‚îÇ ‚îÇ - Includes confidence, recommendation, metadata     ‚îÇ    ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Performance targets:**
- **Coordinator startup:** 5-10 seconds (query + publish)
- **Per-player processing:** 150-200ms (parallel across 20 workers)
- **Total time:** 2-5 minutes for 450 players
- **Cost:** ~$60/day (~$1,800/month)

---

## üìÅ Code Structure

**Everything is in the `predictions/` directory:**

```
predictions/
‚îú‚îÄ‚îÄ coordinator/                    # Orchestration service
‚îÇ   ‚îú‚îÄ‚îÄ coordinator.py              # Main Flask app (150 lines)
‚îÇ   ‚îú‚îÄ‚îÄ player_loader.py            # Query players with games today (120 lines)
‚îÇ   ‚îú‚îÄ‚îÄ progress_tracker.py         # Track 450/450 completion (90 lines)
‚îÇ   ‚îî‚îÄ‚îÄ tests/                      # 3 test files (200+ tests)
‚îÇ
‚îú‚îÄ‚îÄ worker/                         # Prediction service
‚îÇ   ‚îú‚îÄ‚îÄ worker.py                   # Main Flask app (300 lines)
‚îÇ   ‚îú‚îÄ‚îÄ data_loaders.py             # BigQuery data loading (400 lines)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ prediction_systems/         # 5 prediction models
‚îÇ       ‚îú‚îÄ‚îÄ base_predictor.py       # Base class (80 lines)
‚îÇ       ‚îú‚îÄ‚îÄ moving_average_baseline.py  # 350 lines ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ xgboost_v1.py           # 427 lines ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ zone_matchup_v1.py      # 380 lines ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ similarity_balanced_v1.py   # 450 lines ‚úÖ
‚îÇ       ‚îî‚îÄ‚îÄ ensemble_v1.py          # 487 lines ‚úÖ
‚îÇ
‚îî‚îÄ‚îÄ shared/                         # Shared utilities
    ‚îú‚îÄ‚îÄ mock_xgboost_model.py       # Mock model for testing (200 lines)
    ‚îî‚îÄ‚îÄ mock_data_generator.py      # Test data generation (250 lines)
```

**Total: 22 Python files, ~3,500 lines of code**

---

## üîß What's Already Built

### 1. ‚úÖ Cache Loading Pattern

**Implementation:** `worker.py:68-79` + `data_loaders.py:50-130`

The cache loading pattern from the processor cards is **fully implemented**:

```python
# In worker.py (initialization, runs once at startup)
data_loader = PredictionDataLoader(PROJECT_ID)

# For each prediction request
features = data_loader.load_features(
    player_lookup='lebron-james',
    game_date=date(2025, 11, 15)
)
# Returns: 25 features in ~20ms (indexed BigQuery query)

historical_games = data_loader.load_historical_games(
    player_lookup='lebron-james',
    game_date=date(2025, 11, 15),
    lookback_days=90,
    max_games=30
)
# Returns: 30 recent games in ~50ms
```

**Performance characteristics:**
- Features query: O(1) with player_lookup + game_date index
- Historical query: O(log n) with player_lookup + game_date index
- Total data loading: 70-100ms per player
- **No caching needed** - BigQuery is fast enough with proper indexes

**vs. Original Design:**

The processor card described loading cache once at 6 AM and reusing it. Current implementation queries per-player instead because:

1. **BigQuery is fast:** 20ms indexed query is acceptable
2. **Simpler architecture:** No cache invalidation logic
3. **Always fresh:** No stale data concerns
4. **Stateless workers:** Can scale up/down freely

If we need further optimization:
```python
# Add Redis cache (future enhancement)
cache_key = f"features:{player_lookup}:{game_date}"
features = redis.get(cache_key)
if not features:
    features = data_loader.load_features(...)
    redis.setex(cache_key, 3600, features)  # Cache 1 hour
```

### 2. ‚úÖ Confidence Scoring

**Per-system confidence:** Each system calculates its own confidence

**Moving Average:** `moving_average_baseline.py:235-271`
```python
def calculate_confidence(volatility, recent_games, data_quality):
    confidence = 0.5  # Base

    # Volatility penalty
    if volatility > 6.0:
        confidence -= 0.15

    # Recent games bonus
    if recent_games >= 3:
        confidence += 0.10

    # Data quality adjustment
    confidence *= data_quality

    return max(0.2, min(0.8, confidence))  # Clamp to 20-80%
```

**XGBoost:** `xgboost_v1.py:255-309`
```python
def _calculate_confidence(features, feature_vector):
    confidence = 70.0  # ML starts higher than rules

    # Data quality (¬±10 points)
    quality = features.get('feature_quality_score', 80)
    if quality >= 90:
        confidence += 10

    # Consistency (¬±10 points)
    std_dev = features.get('points_std_last_10', 5)
    if std_dev < 4:
        confidence += 10

    return max(0, min(100, confidence))
```

**Ensemble:** `ensemble_v1.py:268-313`
```python
def _calculate_ensemble_confidence(predictions):
    # Average component confidences
    avg_confidence = mean([p['confidence'] for p in predictions])

    # Agreement bonus
    variance = std([p['prediction'] for p in predictions])
    if variance < 2.0:
        avg_confidence += 10  # High agreement
    elif variance > 6.0:
        avg_confidence -= 10  # Low agreement

    # All systems bonus
    if len(predictions) == 4:
        avg_confidence += 5

    return max(20, min(95, avg_confidence))
```

### 3. ‚úÖ Edge Calculation

**Implementation:** `ensemble_v1.py:315-368`

```python
def _determine_ensemble_recommendation(ensemble_pred, prop_line, ensemble_conf, predictions):
    # Check confidence threshold
    if ensemble_conf < 65.0:
        return 'PASS'

    # Calculate edge
    edge = abs(ensemble_pred - prop_line)

    # Check edge threshold
    if edge < 1.5:  # Must beat line by 1.5+ points
        return 'PASS'

    # Determine direction
    if ensemble_pred > prop_line:
        return 'OVER'
    else:
        return 'UNDER'
```

**Edge thresholds by system:**

| System | Edge Threshold | Confidence Threshold | Rationale |
|--------|---------------|----------------------|-----------|
| Moving Average | 2.0 points | 45% | Conservative (rule-based) |
| XGBoost | 1.5 points | 60% | ML learns optimal threshold |
| Zone Matchup | 2.0 points | 50% | Matchup-specific edge |
| Similarity | 2.5 points | 40% | Pattern matching, more uncertain |
| Ensemble | 1.5 points | 65% | Most aggressive (combines signals) |

### 4. ‚úÖ Prediction Result Schema

**BigQuery schema:** `schemas/bigquery/predictions/05_player_prop_predictions.sql`

```sql
CREATE TABLE nba_predictions.player_prop_predictions (
    -- Identifiers
    prediction_id STRING,
    player_lookup STRING,
    universal_player_id STRING,
    game_date DATE,
    game_id STRING,

    -- Betting context
    prop_type STRING,              -- 'points', 'rebounds', 'assists'
    prop_line FLOAT64,             -- Current betting line
    bookmaker STRING,              -- 'fanduel', 'draftkings', etc.

    -- Individual system predictions
    moving_avg_prediction FLOAT64,
    moving_avg_confidence FLOAT64,
    moving_avg_recommendation STRING,

    xgboost_prediction FLOAT64,
    xgboost_confidence FLOAT64,
    xgboost_recommendation STRING,

    zone_matchup_prediction FLOAT64,
    zone_matchup_confidence FLOAT64,
    zone_matchup_recommendation STRING,

    similarity_prediction FLOAT64,
    similarity_confidence FLOAT64,
    similarity_recommendation STRING,

    -- Ensemble (final prediction)
    ensemble_prediction FLOAT64,
    ensemble_confidence FLOAT64,
    ensemble_recommendation STRING,  -- 'OVER', 'UNDER', 'PASS'

    -- Edge analysis
    edge_points FLOAT64,           -- ensemble_prediction - prop_line
    edge_percent FLOAT64,          -- (edge / prop_line) * 100

    -- Metadata
    systems_agreement_type STRING, -- 'high', 'good', 'moderate', 'low'
    systems_variance FLOAT64,      -- Variance across 4 base systems
    feature_quality_score FLOAT64, -- From ml_feature_store_v2

    -- Timestamps
    prediction_timestamp TIMESTAMP,
    created_at TIMESTAMP
)
PARTITION BY game_date
CLUSTER BY player_lookup, ensemble_recommendation;
```

**Output from worker:** `worker.py:250-350` (writes to this table)

---

## üöÄ What's Needed Next

### 1. ‚ö†Ô∏è Train XGBoost Model

**Current state:** Using mock model for testing
**Priority:** HIGH
**Effort:** 2-3 days

**Steps:**

```bash
# 1. Create training dataset
python predictions/training/create_training_data.py \
    --start-date 2022-10-01 \
    --end-date 2025-11-01 \
    --output gs://nba-training-data/xgboost/training_v1.parquet

# 2. Train model
python predictions/training/train_xgboost.py \
    --training-data gs://nba-training-data/xgboost/training_v1.parquet \
    --output-model gs://nba-models-production/xgboost/v1.0/model.json \
    --max-depth 6 \
    --learning-rate 0.1 \
    --n-estimators 100

# 3. Validate model
python predictions/training/evaluate_model.py \
    --model gs://nba-models-production/xgboost/v1.0/model.json \
    --validation-data gs://nba-training-data/xgboost/validation_v1.parquet

# 4. Deploy to production
# Update worker.py environment variable:
# XGBOOST_MODEL_PATH=gs://nba-models-production/xgboost/v1.0/model.json
```

**Expected performance:**
- MAE (Mean Absolute Error): 3.0-3.5 points
- R¬≤: 0.65-0.75
- Calibration: 80% of predictions within ¬±4 points

### 2. ‚ùå Deploy Infrastructure

**Current state:** Code ready, infrastructure not deployed
**Priority:** HIGH
**Effort:** 1 day

**Follow:** `docs/predictions/operations/01-deployment-guide.md`

**Quick deployment:**

```bash
# 1. Deploy Pub/Sub topics
gcloud pubsub topics create prediction-request
gcloud pubsub topics create prediction-ready
gcloud pubsub topics create prediction-worker-dlq

# 2. Deploy Worker service
cd predictions/worker
gcloud run deploy prediction-worker \
    --source . \
    --platform managed \
    --region us-central1 \
    --memory 2Gi \
    --cpu 2 \
    --min-instances 0 \
    --max-instances 20 \
    --concurrency 5 \
    --set-env-vars GCP_PROJECT_ID=nba-props-platform,XGBOOST_MODEL_PATH=gs://...

# 3. Create Pub/Sub push subscription
gcloud pubsub subscriptions create prediction-request-sub \
    --topic prediction-request \
    --push-endpoint https://prediction-worker-xxx.run.app/predict \
    --ack-deadline 60

# 4. Deploy Coordinator service
cd predictions/coordinator
gcloud run jobs create prediction-coordinator \
    --source . \
    --region us-central1 \
    --memory 1Gi \
    --cpu 1 \
    --set-env-vars GCP_PROJECT_ID=nba-props-platform

# 5. Set up Cloud Scheduler
gcloud scheduler jobs create http prediction-daily-trigger \
    --schedule "15 6 * * *" \
    --http-method POST \
    --uri https://prediction-coordinator-xxx.run.app/start \
    --oidc-service-account-email scheduler@nba-props-platform.iam.gserviceaccount.com
```

### 3. ‚ùå Set Up Monitoring

**Current state:** No dashboards or alerts
**Priority:** MEDIUM
**Effort:** 4 hours

**Follow:** `docs/monitoring/01-grafana-monitoring-guide.md`

**Key metrics to monitor:**

```yaml
Alerts:
  - name: predictions_daily_count
    threshold: < 400 players  # Should be ~450
    severity: P1

  - name: ensemble_confidence_avg
    threshold: < 70
    severity: P2

  - name: worker_error_rate
    threshold: > 5%
    severity: P1

  - name: prediction_latency_p95
    threshold: > 500ms
    severity: P2
```

---

## üìö Where to Learn More

### Essential Reading (in order):

1. **Start here:** `docs/predictions/README.md` - Overview and reading guide
2. **Deployment:** `docs/predictions/operations/01-deployment-guide.md` - Deploy to production
3. **Understand data:** `docs/predictions/data-sources/01-data-categorization.md` - What data flows where
4. **Deep dive:** `docs/predictions/operations/04-worker-deepdive.md` - Worker internals

### Code Deep Dives:

1. **Coordinator:** `predictions/coordinator/coordinator.py` - Read this to understand orchestration
2. **Worker:** `predictions/worker/worker.py` - Read this to understand prediction flow
3. **Ensemble:** `predictions/worker/prediction_systems/ensemble_v1.py` - How systems combine
4. **XGBoost:** `predictions/worker/prediction_systems/xgboost_v1.py` - ML model interface

### Related Documentation:

- **Phase 4 Features:** `docs/processor-cards/phase4-ml-feature-store-v2.md` - Your input data
- **Workflow:** `docs/processor-cards/workflow-realtime-prediction-flow.md` - End-to-end flow
- **Architecture:** `docs/architecture/04-event-driven-pipeline-architecture.md` - System design

---

## üéØ Quick Start Checklist

**For developers new to Phase 5:**

- [ ] Read this document (you're here!)
- [ ] Read `docs/predictions/README.md`
- [ ] Browse code structure in `predictions/`
- [ ] Run local tests: `pytest predictions/worker/prediction_systems/`
- [ ] Read ensemble code to understand system combination
- [ ] Review BigQuery schemas in `schemas/bigquery/predictions/`

**To deploy Phase 5:**

- [ ] Train XGBoost model (or use mock model for testing)
- [ ] Deploy Pub/Sub topics
- [ ] Deploy Worker service
- [ ] Deploy Coordinator service
- [ ] Set up Cloud Scheduler trigger
- [ ] Configure monitoring and alerts
- [ ] Run end-to-end test
- [ ] Monitor first week of production predictions

**To improve Phase 5:**

- [ ] Analyze prediction accuracy (MAE, calibration)
- [ ] Review feature importance from XGBoost
- [ ] Add new features to ml_feature_store_v2
- [ ] Tune ensemble weights based on performance
- [ ] Implement weekly model retraining
- [ ] Add player tier segmentation

---

## üí° Common Gotchas

1. **Mock model in production**
   - XGBoost defaults to mock model if GCS path not set
   - Set `XGBOOST_MODEL_PATH` environment variable
   - Verify with: Check `xgboost_prediction.model_type` in results

2. **Missing features**
   - Worker returns PASS if features not found
   - Check `ml_feature_store_v2` has data for game_date
   - Verify Phase 4 ran successfully before 6:15 AM

3. **Low confidence across all players**
   - Check `feature_quality_score` in ml_feature_store_v2
   - Likely Phase 4 fell back to Phase 3 (lower quality)
   - Verify Phase 4 processors completed

4. **Ensemble disagrees with XGBoost**
   - This is normal! Ensemble weighs all systems
   - Check `systems_variance` - high variance = disagreement
   - Review individual system predictions in output

5. **Slow worker processing**
   - Check BigQuery query performance
   - Verify indexes on `player_lookup` + `game_date`
   - Consider Redis caching for features

---

## üîó Quick Links

- **Code:** `predictions/` directory (22 files)
- **Docs:** `docs/predictions/` (6 comprehensive guides)
- **Tests:** `predictions/coordinator/tests/` + system tests
- **Schemas:** `schemas/bigquery/predictions/`
- **Deployment Guide:** `docs/predictions/operations/01-deployment-guide.md`
- **Troubleshooting:** `docs/predictions/operations/03-troubleshooting.md`

---

**Document Status:** ‚úÖ Complete
**Last Updated:** 2025-11-15
**Next Review:** After Phase 5 production deployment

---

**Questions or feedback?** Update this document or create an issue in the repository.
