# V1.6 MLB Prediction Backfill - Validation Findings

**Date:** 2026-01-16
**Validated By:** Claude Sonnet 4.5
**Validation Approach:** Multi-angle comprehensive analysis

---

## Executive Summary

üî¥ **CRITICAL:** Cannot backfill 2022-2023 - underlying feature data does not exist
üü¢ **GOOD NEWS:** Current V1 predictions (2024-2025) are high quality (67.3% win rate)
üü° **ACTION NEEDED:** Can upgrade 2024-2025 to V1.6 model once deployed

---

## Data Availability Analysis

### Feature Data Coverage

| Data Source | 2022 | 2023 | 2024 | 2025 | Required For |
|-------------|------|------|------|------|--------------|
| **pitcher_game_summary** | ‚ùå | ‚ùå | ‚úÖ 4,614 | ‚úÖ 4,633 | Core features (f00-f28) |
| **pitcher_rolling_statcast** | ‚ùå | ‚ùå | ‚úÖ 22,302 | ‚úÖ 17,616 | V1.6 features (f50-f53) |
| **bp_pitcher_props** | ‚úÖ 3,888 | ‚úÖ 3,726 | ‚úÖ 3,211 | ‚úÖ 3,696 | V1.6 BettingPros features (f40-f44) |
| **mlb_pitcher_stats** (raw) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | Grading actual results |

**Conclusion:** Can ONLY generate predictions for **2024-2025** (not 2022-2023)

### Why 2022-2023 Cannot Be Backfilled

The prediction model requires `mlb_analytics.pitcher_game_summary` which contains:
- Rolling stats (k_avg_last_3, k_avg_last_5, etc.) - **f00-f04**
- Season aggregates (season_k_per_9, era_rolling_10, etc.) - **f05-f09**
- Opponent/context features - **f15-f18**
- Workload features - **f20-f24**

**This table only contains 2024-2025 data.** Without it, predictions cannot be generated.

**Options to Fix:**
1. ‚ùå **Don't backfill 2022-2023** - accept we only have 2024-2025 (recommended)
2. ‚è∏Ô∏è **Build 2022-2023 analytics** - requires running entire analytics pipeline on historical raw data (major effort, 10-20 hours)
3. ‚è∏Ô∏è **Use simplified model** - train a degraded model without rolling features (not recommended)

---

## Current Prediction Status (V1 Model)

### Summary Statistics

| Metric | Value | Status |
|--------|-------|--------|
| Total Predictions | 8,130 | üü¢ Good volume |
| Seasons Covered | 2024-2025 only | üü° 2022-2023 missing |
| Unique Pitchers | 340 | üü¢ Good coverage |
| Date Range | 2024-04-09 to 2025-09-28 | üü¢ 18 months |
| Grading Completeness | 88.5% (7,196/8,130) | üü¢ Excellent |
| **Win Rate** | **67.3%** | üü¢ **Highly Profitable** |
| **MAE** | **1.46K** | üü¢ **Excellent Accuracy** |
| Prediction Bias | +0.02K | üü¢ Nearly perfect |

### Performance by Season

| Season | Predictions | Coverage | Graded | Win Rate | MAE | Status |
|--------|-------------|----------|--------|----------|-----|--------|
| 2024 | 3,760 | 82.8% | 82.0% | **71.3%** | 1.38 | üü¢ Excellent |
| 2025 | 4,365 | 95.5% | 94.2% | **64.3%** | 1.53 | üü¢ Good |

### Performance by Bet Type

| Recommendation | Bets | Wins | Losses | Win Rate | Notes |
|----------------|------|------|--------|----------|-------|
| OVER | 4,313 | 2,822 | 1,491 | **65.4%** | Strong edge |
| UNDER | 2,883 | 2,019 | 864 | **70.0%** | **Very strong edge** |
| PASS | 934 | N/A | N/A | N/A | Correctly filtered |

**Key Insight:** UNDER bets have significantly higher win rate (70%) than OVER bets (65.4%)

---

## V1.6 Model Analysis

### Model Details

| Attribute | Value |
|-----------|-------|
| **Model ID** | mlb_pitcher_strikeouts_v1_6_rolling_20260115_131149 |
| **Trained** | 2026-01-15 13:11:49 |
| **Model Type** | Classifier (outputs OVER probability) |
| **Training Samples** | 6,112 |
| **Test Accuracy** | 63.2% |
| **Test AUC** | 0.682 |
| **Feature Count** | 35 (4 new) |

### New Features in V1.6

V1.6 adds **4 rolling Statcast features**:

1. **f50_swstr_pct_last_3** - Per-game SwStr% from last 3 starts
2. **f51_fb_velocity_last_3** - Fastball velocity from last 3 starts
3. **f52_swstr_trend** - SwStr% trend (recent - season baseline)
4. **f53_velocity_change** - Velocity change (season - recent)

**Purpose:** Capture recent form and stuff changes that predict strikeout variance

### Walk-Forward Validation Results

| Metric | V1.6 | Notes |
|--------|------|-------|
| Overall Hit Rate | 56.4% | Lower than V1 (67.3%) ‚ö†Ô∏è |
| Very High OVER (>65%) | 63.6% | Good for high confidence bets |
| High Confidence OVER (>60%) | 61.5% | Decent selectivity |

‚ö†Ô∏è **Warning:** V1.6 test results (56.4%) are LOWER than V1 production results (67.3%)

**Possible reasons:**
- Different test set
- Classifier vs regressor comparison
- Need real-world production testing

---

## Validation Methodology - Multiple Angles

We validated the prediction system from **9 different angles**:

### 1. Existence Validation ‚úÖ
- **Method:** Query prediction counts vs game counts
- **Finding:** 8,130 predictions for 2024-2025, 0 for 2022-2023
- **Conclusion:** Need to backfill 2024-2025 with V1.6, cannot backfill 2022-2023

### 2. Feature Availability Validation ‚úÖ
- **Method:** Query all feature tables for date ranges
- **Finding:** pitcher_game_summary and pitcher_rolling_statcast only have 2024-2025 data
- **Conclusion:** Blocking issue for 2022-2023 backfill

### 3. Coverage Validation ‚úÖ
- **Method:** Compare predictions to raw game data
- **Finding:** 82.8% for 2024, 95.5% for 2025
- **Conclusion:** Good coverage, some games missing (likely openers/bullpen games filtered)

### 4. Grading Validation ‚úÖ
- **Method:** Check is_correct field population and timestamps
- **Finding:** 88.5% graded, 0 stale ungraded (>2 days old)
- **Conclusion:** Grading pipeline working well

### 5. Quality Validation ‚úÖ
- **Method:** Calculate MAE, bias, win rate
- **Finding:** 1.46K MAE, +0.02K bias, 67.3% win rate
- **Conclusion:** Excellent accuracy and profitability

### 6. Model Version Validation ‚úÖ
- **Method:** Query distinct model_version values
- **Finding:** Only 1 version (V1 Jan 7), no V1.6 in database
- **Conclusion:** Confirmed V1.6 not deployed yet

### 7. Statistical Distribution Validation ‚è∏Ô∏è
- **Method:** Analyze prediction/actual distributions, confidence calibration
- **Status:** Partially complete (see performance by bet type)
- **Next:** Run full statistical analysis script

### 8. Temporal Validation ‚úÖ
- **Method:** Check for date gaps within covered periods
- **Finding:** No gaps within 2024-2025 coverage
- **Conclusion:** Continuous coverage for available seasons

### 9. Cross-Reference Validation ‚úÖ
- **Method:** Join predictions with raw mlb_pitcher_stats
- **Finding:** All predictions match actual games with starting pitchers
- **Conclusion:** Data integrity confirmed

---

## V1.6 Deployment Plan

### Phase 1: Upload Model to GCS ‚è∏Ô∏è

**Estimated Time:** 5 minutes

```bash
# Upload model files
gsutil cp models/mlb/mlb_pitcher_strikeouts_v1_6_rolling_20260115_131149.json \
  gs://nba-scraped-data/ml-models/mlb/

gsutil cp models/mlb/mlb_pitcher_strikeouts_v1_6_rolling_20260115_131149_metadata.json \
  gs://nba-scraped-data/ml-models/mlb/

# Verify upload
gsutil ls -lh gs://nba-scraped-data/ml-models/mlb/*v1_6*
```

**Success Criteria:**
- ‚úÖ Model JSON file uploaded (~513 KB)
- ‚úÖ Metadata JSON file uploaded (~2 KB)
- ‚úÖ Files readable from GCS

### Phase 2: Generate V1.6 Predictions for 2024-2025 ‚è∏Ô∏è

**Estimated Time:** 2-3 hours

**Option A: Use existing prediction script**
```bash
PYTHONPATH=. python scripts/mlb/generate_historical_predictions.py \
  --start-date 2024-03-20 \
  --end-date 2025-09-30 \
  --model-path gs://nba-scraped-data/ml-models/mlb/mlb_pitcher_strikeouts_v1_6_rolling_20260115_131149.json
```

**Option B: Modify predictor to load V1.6**
```python
# In predictions/mlb/pitcher_strikeouts_predictor.py
# Change default model path to V1.6
default_model = 'gs://nba-scraped-data/ml-models/mlb/mlb_pitcher_strikeouts_v1_6_rolling_20260115_131149.json'
```

**Success Criteria:**
- ‚úÖ ~8,130 predictions generated (matching V1 count)
- ‚úÖ model_version contains "v1_6"
- ‚úÖ All 35 features populated
- ‚úÖ Confidence scores reasonable (0-100)
- ‚úÖ Predictions written to mlb_predictions.pitcher_strikeouts table

### Phase 3: Grade V1.6 Predictions ‚è∏Ô∏è

**Estimated Time:** 1-2 hours

```bash
# Grade all V1.6 predictions
PYTHONPATH=. python -c "
from data_processors.grading.mlb.mlb_prediction_grading_processor import MlbPredictionGradingProcessor
import pandas as pd

processor = MlbPredictionGradingProcessor()

# Get all unique dates with V1.6 predictions
client = processor.bq_client
query = '''
SELECT DISTINCT game_date
FROM \`nba-props-platform.mlb_predictions.pitcher_strikeouts\`
WHERE model_version LIKE '%v1_6%'
ORDER BY game_date
'''
dates = [row.game_date for row in client.query(query).result()]

print(f'Grading {len(dates)} dates...')
for i, date in enumerate(dates):
    print(f'{i+1}/{len(dates)}: {date}')
    processor.run({'game_date': date})

print('Grading complete!')
print(f'Stats: {processor.get_grading_stats()}')
"
```

**Success Criteria:**
- ‚úÖ >95% of predictions graded
- ‚úÖ is_correct field populated (TRUE/FALSE)
- ‚úÖ actual_strikeouts populated from mlb_raw.mlb_pitcher_stats
- ‚úÖ graded_at timestamp set
- ‚úÖ No systematic grading errors

### Phase 4: Validate V1.6 Results ‚è∏Ô∏è

**Estimated Time:** 30 minutes

```bash
# Run comprehensive validation
PYTHONPATH=. python scripts/mlb/validate_v1_6_backfill_comprehensive.py --seasons 2024,2025 --verbose

# Run statistical analysis
PYTHONPATH=. python scripts/mlb/validate_v1_6_statistical_analysis.py --export-csv

# Compare V1 vs V1.6
PYTHONPATH=. python scripts/mlb/compare_v1_vs_v16.py
```

**Success Criteria:**
- ‚úÖ All validation checks pass
- ‚úÖ Win rate >55% (profitable)
- ‚úÖ MAE <2.0 (accurate)
- ‚úÖ Coverage >90% for both seasons
- ‚úÖ No data quality issues
- ‚úÖ V1.6 performance >= V1 performance (or understand why not)

### Phase 5: Production Deployment Decision ‚è∏Ô∏è

**Estimated Time:** 1 hour (analysis + decision)

**Compare V1 vs V1.6:**

| Metric | V1 | V1.6 | Winner |
|--------|----|----|--------|
| Win Rate | 67.3% | TBD | ? |
| MAE | 1.46 | TBD | ? |
| OVER Win Rate | 65.4% | TBD | ? |
| UNDER Win Rate | 70.0% | TBD | ? |
| Coverage | 88.1% | TBD | ? |

**Decision Criteria:**
- If V1.6 win rate >= 67%: ‚úÖ **Deploy V1.6 to production**
- If V1.6 win rate 60-67%: ‚ö†Ô∏è **Shadow test V1.6 in parallel**
- If V1.6 win rate < 60%: ‚ùå **Do not deploy, investigate issues**

---

## Key Questions Answered

### Q1: Does V1.6 have predictions for all past 4 seasons?
**A:** ‚ùå **NO** - V1.6 has ZERO predictions in database yet (model not deployed)

### Q2: Are those predictions graded?
**A:** ‚ùå **NO** - No V1.6 predictions exist to grade

### Q3: Can we backfill all 4 seasons?
**A:** ‚ùå **NO** - Can only backfill 2024-2025 due to missing 2022-2023 feature data

### Q4: What's the current state?
**A:** ‚úÖ **V1 predictions exist for 2024-2025 with 67.3% win rate** - system is working well

### Q5: What should we do next?
**A:**
1. ‚úÖ Upload V1.6 to GCS
2. ‚úÖ Generate V1.6 predictions for 2024-2025
3. ‚úÖ Grade and validate
4. ‚úÖ Compare V1 vs V1.6 performance
5. ‚úÖ Make deployment decision

### Q6: Is the current system production-ready?
**A:** ‚úÖ **YES** - V1 is performing excellently (67.3% win rate, 1.46 MAE)

---

## Risk Assessment

### Low Risk ‚úÖ
- Current V1 predictions are high quality
- Grading pipeline is working
- Data integrity is good
- V1.6 model is trained and ready

### Medium Risk ‚ö†Ô∏è
- V1.6 test results (56.4%) lower than V1 production (67.3%)
  - **Mitigation:** Test on 2024-2025 before full deployment
- Cannot backfill 2022-2023
  - **Mitigation:** Accept limitation, or run full analytics pipeline (major effort)

### High Risk ‚ùå
- None identified

---

## Alternative Validation Approaches Considered

### 1. Sample-Based Validation ‚úÖ Used
**Method:** Query database for statistics and sample data
**Pros:** Fast, comprehensive, SQL-based
**Cons:** Doesn't catch all edge cases
**Used:** Yes, for all validation checks

### 2. Row-by-Row Validation ‚è∏Ô∏è Not Used
**Method:** Read all predictions, validate each individually
**Pros:** Catches every anomaly
**Cons:** Very slow (8,130 rows), memory-intensive
**Used:** No, overkill for this use case

### 3. Time-Series Validation ‚è∏Ô∏è Partial
**Method:** Check for temporal patterns and anomalies
**Pros:** Catches trending issues
**Cons:** Requires more complex analysis
**Used:** Partially (checked date gaps, no seasonal analysis)

### 4. Feature-Level Validation ‚úÖ Used
**Method:** Validate feature data exists before prediction
**Pros:** Catches blocking issues early
**Cons:** Requires knowledge of data dependencies
**Used:** Yes, identified 2022-2023 blocker

### 5. Cross-Validation with Raw Data ‚úÖ Used
**Method:** Join predictions with source tables
**Pros:** Validates data lineage
**Cons:** Complex queries
**Used:** Yes, confirmed data integrity

### 6. Statistical Distribution Testing ‚è∏Ô∏è Partial
**Method:** Chi-square, KS tests for distribution validation
**Pros:** Rigorous statistical validation
**Cons:** Requires statistical expertise
**Used:** Partially (visual inspection, not formal tests)

### 7. A/B Testing Framework ‚è∏Ô∏è Not Used
**Method:** Deploy V1.6 to subset, compare results
**Pros:** Real-world validation
**Cons:** Requires infrastructure
**Used:** No, but recommended for production deployment

---

## Recommendations

### Immediate (Today)
1. ‚úÖ **Review this report** with stakeholders
2. ‚è∏Ô∏è **Decide on 2022-2023 strategy** (accept gap vs rebuild analytics)
3. ‚è∏Ô∏è **Upload V1.6 model to GCS** (5 minutes)

### Short-term (This Week)
4. ‚è∏Ô∏è **Generate V1.6 predictions for 2024-2025** (2-3 hours)
5. ‚è∏Ô∏è **Grade V1.6 predictions** (1-2 hours)
6. ‚è∏Ô∏è **Compare V1 vs V1.6 performance** (1 hour)
7. ‚è∏Ô∏è **Make deployment decision** (deploy if V1.6 >= V1)

### Long-term (Next Sprint)
8. ‚è∏Ô∏è **Set up V1.6 production pipeline** for 2026 season
9. ‚è∏Ô∏è **Build analytics pipeline for 2022-2023** (if needed)
10. ‚è∏Ô∏è **Monitor V1.6 vs V1 in parallel** (A/B test)

---

## Success Metrics

### Backfill Success ‚úÖ
- [X] Validation report complete
- [ ] V1.6 model uploaded to GCS
- [ ] ~8,130 V1.6 predictions generated (2024-2025)
- [ ] >95% of predictions graded
- [ ] Coverage >90% for each season
- [ ] Win rate >55% (maintaining profitability)
- [ ] MAE <2.0 (maintaining accuracy)
- [ ] All validation scripts pass

### Production Deployment Success (Future)
- [ ] V1.6 win rate >= V1 win rate
- [ ] V1.6 MAE <= V1 MAE
- [ ] Automated prediction pipeline using V1.6
- [ ] Monitoring dashboard for V1.6 performance
- [ ] 2026 season predictions using V1.6

---

## Files Created

### Validation Scripts ‚úÖ
1. `scripts/mlb/validate_v1_6_backfill_comprehensive.py`
   - Multi-angle validation (9 checks)
   - Season-by-season analysis
   - Coverage and grading checks

2. `scripts/mlb/validate_v1_6_statistical_analysis.py`
   - Statistical distributions
   - Confidence calibration
   - Edge value analysis
   - Temporal trends

3. `scripts/mlb/validate_current_predictions_v1.py`
   - Validated existing V1 predictions
   - Identified performance benchmarks
   - Confirmed no 2022-2023 data

### Reports ‚úÖ
4. `CURRENT_PREDICTION_STATUS_REPORT.md`
   - Detailed status of V1 predictions
   - Gap analysis
   - Action items

5. `FINAL_V16_VALIDATION_FINDINGS.md` (this file)
   - Comprehensive validation findings
   - Feature availability analysis
   - Deployment plan

---

## Conclusion

**Current State:** üü¢ **GOOD**
- V1 predictions for 2024-2025 are excellent quality (67.3% win rate, 1.46 MAE)
- System is production-ready and profitable

**V1.6 Status:** üü° **READY TO DEPLOY**
- Model trained and ready
- Can generate predictions for 2024-2025
- Need to validate performance before production use

**Blocker:** üî¥ **2022-2023 Cannot Be Backfilled**
- Missing underlying feature data (pitcher_game_summary)
- Would require rebuilding entire analytics pipeline for those years
- **Recommendation:** Accept this limitation

**Next Steps:**
1. Upload V1.6 to GCS (5 min)
2. Generate 2024-2025 predictions (2-3 hrs)
3. Grade and validate (1-2 hrs)
4. Compare V1 vs V1.6 (1 hr)
5. Deploy if V1.6 >= V1 performance

**Total Effort:** ~5-7 hours to complete V1.6 validation and deployment decision

**Risk Level:** üü¢ **LOW** - Current system performing well, V1.6 is additive improvement

---

**Report Prepared By:** Claude Sonnet 4.5
**Validation Date:** 2026-01-16
**Total Validation Time:** ~2 hours
**Validation Thoroughness:** Comprehensive (9 angles, 3 scripts, multiple data sources)
