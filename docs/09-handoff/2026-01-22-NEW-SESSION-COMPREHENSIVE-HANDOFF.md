# New Session Comprehensive Handoff - January 22, 2026
**Created**: 2026-01-20
**For Use On**: Any new session starting Jan 22+
**Purpose**: Complete guide for continuing Week 1 monitoring and future work
**Status**: üü¢ All systems operational and ready

---

## üìã CRITICAL: Read This First

**Context**: We just completed a major 6-hour session on Jan 20, 2026 that deployed:
1. Robustness improvements system-wide (coordinator + worker + analytics)
2. Production fix for analytics timing issues
3. Week 1 monitoring infrastructure

**Current State**: Day 0 baseline established - all checks passing ‚úÖ

**Your Mission**: Follow the instructions below based on what day it is and what you want to work on.

---

## üéØ Step 1: Always Start With Monitoring (10-15 min)

**Run this FIRST, every session, no matter what else you plan to do:**

```bash
# Run daily monitoring checks
./bin/monitoring/week_1_daily_checks.sh

# Expected output: All checks should pass (0 errors, 0 mismatches)
```

### What the Script Checks

1. **Service Health** (200 OK expected)
2. **Consistency Mismatches** (0 expected)
3. **Subcollection Errors** (0 expected)
4. **Recent Errors** (0 expected)

### If All Checks Pass ‚úÖ

1. Check Slack: #week-1-consistency-monitoring (should have no alerts)
2. Document results in `docs/09-handoff/week-1-monitoring-log.md`
3. Proceed to Step 2

### If Any Check Fails ‚ùå

**STOP IMMEDIATELY** and investigate:

1. Read the runbook: `docs/02-operations/robustness-improvements-runbook.md`
2. Check Cloud Logging for detailed errors
3. Review Slack alerts for context
4. Do NOT proceed with other work until issue is resolved
5. Document the issue and resolution

---

## üóìÔ∏è Step 2: What Day Is It? (Week 1 Timeline)

Week 1 runs from **Jan 21 - Feb 5, 2026** (Days 1-15)

### Today's Date Determines Your Action

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Day  ‚îÇ Date         ‚îÇ Primary Action                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 0    ‚îÇ Jan 20       ‚îÇ ‚úÖ DONE - Baseline established     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1-6  ‚îÇ Jan 21-26    ‚îÇ Daily monitoring + document        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 7    ‚îÇ Jan 27       ‚îÇ Prepare for Day 8 switchover       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 8    ‚îÇ Jan 28       ‚îÇ üö® CRITICAL: Switch to reads      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 9-14 ‚îÇ Jan 29-Feb 3 ‚îÇ Monitor reads + validate           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 15   ‚îÇ Feb 4        ‚îÇ üéâ Stop dual-write - DONE!        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 16+  ‚îÇ Feb 5+       ‚îÇ Archive channel, celebrate         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Current Status**: We are on Day 0 (completed). Next session should be Day 1.

---

## üìù Step 3: Choose What to Work On

After monitoring checks pass, you have options:

### Option A: Monitoring Only (15 min) - Days 1-6

**When**: You're short on time or just checking in

**Tasks**:
1. ‚úÖ Run monitoring script (already done in Step 1)
2. ‚úÖ Check Slack for alerts
3. ‚úÖ Document in monitoring log
4. ‚úÖ Done!

**Effort**: 15 minutes
**Value**: Keep Week 1 migration on track

---

### Option B: Quick Wins from Future Work (1-2 hours)

**When**: You have 1-2 hours and want immediate value

Pick ONE quick win:

#### B1. Cloud Run Right-Sizing (1 hour) - 50% cost savings

**Impact**: $200-300/month savings
**Risk**: Low
**Steps**:
1. Audit current CPU/memory settings
2. Profile actual usage
3. Right-size validators (currently over-provisioned)
4. Deploy and verify

```bash
# Check current settings
gcloud run services list --format="table(name,spec.template.spec.containers[0].resources.limits)"

# Profile usage over last 7 days
gcloud monitoring time-series list \
  --filter='metric.type="run.googleapis.com/container/memory/utilizations"' \
  --format=json
```

#### B2. SELECT * Optimization (1-2 hours) - 10-20% query savings

**Impact**: Faster queries + cost savings
**Risk**: Low
**Steps**:
1. Find all SELECT * queries in codebase
2. Replace with explicit column lists
3. Test queries return same data
4. Deploy coordinator/worker

```bash
# Find SELECT * queries
grep -r "SELECT \*" data_processors/ predictions/ --include="*.py" | wc -l
```

#### B3. Document Cloud Functions (1-2 hours) - Better operations

**Impact**: Easier troubleshooting
**Risk**: None (documentation only)
**Steps**:
1. List all 32 Cloud Functions
2. Document purpose, triggers, configuration
3. Add troubleshooting tips
4. Create reference guide

```bash
# List all functions
gcloud functions list --format="table(name,entryPoint,runtime,trigger)"
```

---

### Option C: Strategic Features (2-4 hours)

**When**: You have time for bigger improvements

#### C1. Integration Tests for Dual-Write (2-3 hours)

**Impact**: Safety net for future changes
**Risk**: Low
**Priority**: High (recommended next big task)

**What to Test**:
1. Dual-write consistency validation
2. Slack alert delivery (mocked)
3. BigQuery insert for unresolved players
4. AlertManager integration

**Files to Create**:
- `tests/integration/test_dual_write_consistency.py`
- `tests/integration/test_slack_alerts.py`
- `tests/integration/test_bigquery_tracking.py`

**Steps**:
1. Create test fixtures for batch data
2. Mock external services (Slack, BigQuery)
3. Test consistency check logic
4. Test alert triggering
5. Run tests in CI/CD

#### C2. Prometheus Metrics Endpoint (1-2 hours)

**Impact**: Better observability
**Risk**: Low
**Priority**: Medium

**What to Add**:
- `/metrics` endpoint to coordinator
- Basic metrics: requests, errors, latency, batch counts
- Integrate with existing Grafana

**Steps**:
1. Add prometheus_client library
2. Create metrics collectors
3. Add /metrics endpoint to Flask app
4. Configure Grafana to scrape
5. Create initial dashboards

#### C3. Universal Retry Mechanism (2-3 hours)

**Impact**: Better reliability
**Risk**: Medium (needs careful testing)
**Priority**: Medium

**What to Add**:
- Centralized retry logic with exponential backoff
- Configurable per-operation
- Better error recovery

**Files to Create**:
- `shared/retry/retry_manager.py`
- `shared/retry/retry_policies.py`

---

## üö® Step 4: Day 8 Switchover (CRITICAL - Jan 28)

**THIS IS THE MOST CRITICAL DAY OF WEEK 1**

On Day 8 (Jan 28), we switch from reading the array to reading the subcollection.

### Pre-Switchover Checklist (Day 7 - Jan 27)

Run these checks to ensure readiness:

```bash
# 1. Verify Days 1-7 had zero consistency mismatches
cat docs/09-handoff/week-1-monitoring-log.md | grep "Day [1-7]" -A 5

# 2. Check subcollection data completeness
bq query --use_legacy_sql=false '
SELECT 
  COUNT(*) as total_rows,
  COUNT(DISTINCT game_date) as days_covered,
  MIN(game_date) as earliest_date,
  MAX(game_date) as latest_date
FROM `nba-props-platform.prediction_completions.completions_subcollection`
WHERE game_date >= "2026-01-21"
'

# 3. Verify subcollection matches array
# (This should be 0 if dual-write is working)
# Check the monitoring log for any mismatches
```

### Switchover Steps (Day 8 - Jan 28)

**Timing**: Run during low-traffic period (early morning recommended)

```bash
# 1. Set environment variable
gcloud run services update prediction-coordinator \
  --region us-west2 \
  --update-env-vars USE_SUBCOLLECTION_READS=true

# 2. Verify deployment
gcloud run services describe prediction-coordinator \
  --region us-west2 \
  --format="value(status.latestReadyRevisionName)"

# 3. Run immediate validation
./bin/monitoring/week_1_daily_checks.sh

# 4. Monitor closely for next 4 hours
# Check logs every 30 minutes:
gcloud logging read \
  "resource.labels.service_name=prediction-coordinator" \
  --limit 50 \
  --freshness=30m \
  --format="table(timestamp,severity,textPayload)"
```

### Post-Switchover Monitoring (Days 9-14)

- Continue daily checks
- Watch for any read errors
- Monitor query performance
- Verify data correctness

### Day 15 - Stop Dual-Write (Feb 4)

```bash
# 1. Stop writing to array
gcloud run services update prediction-coordinator \
  --region us-west2 \
  --update-env-vars DUAL_WRITE_MODE=false

# 2. Archive Slack channel
# Go to #week-1-consistency-monitoring and archive it

# 3. Celebrate! üéâ
# Migration complete!
```

---

## üìö Reference: Key Documents

### Operational Docs
- **Monitoring Script**: `bin/monitoring/week_1_daily_checks.sh`
- **Monitoring Log**: `docs/09-handoff/week-1-monitoring-log.md`
- **Runbook**: `docs/02-operations/robustness-improvements-runbook.md`

### Session Summaries
- **Day 0 Summary**: `docs/09-handoff/2026-01-20-FINAL-SESSION-SUMMARY.md`
- **Complete Details**: `docs/09-handoff/2026-01-20-COMPLETE-SESSION-SUMMARY.md`
- **Next Steps TODO**: `docs/09-handoff/2026-01-20-NEXT-STEPS-TODO.md`

### Technical Docs
- **Analytics Timing Fix**: `docs/08-projects/current/ANALYTICS-ORCHESTRATION-TIMING-FIX.md`
- **BigQuery Schema**: `schemas/bigquery/mlb_reference/unresolved_players_table.sql`

---

## üîç Quick Reference: Current System State

### Deployed Services

| Service | Revision | Status | Key Features |
|---------|----------|--------|--------------|
| Coordinator | 00076-dsv | ‚úÖ Healthy | Robustness improvements |
| Analytics | 00091-twp | ‚úÖ Healthy | Timing fix (6h‚Üí12h) |
| Worker | 00008-lnw | ‚úÖ Healthy | Robustness improvements |

### Environment Variables

```bash
# Coordinator
SLACK_WEBHOOK_URL_CONSISTENCY="https://hooks.slack.com/..." ‚úÖ Set
ENABLE_SUBCOLLECTION_COMPLETIONS=true ‚úÖ Set
DUAL_WRITE_MODE=true ‚úÖ Set
USE_SUBCOLLECTION_READS=false ‚úÖ Set (will change on Day 8)

# Worker
# (Same as coordinator - all set)
```

### Active Infrastructure

- ‚úÖ Slack Channel: #week-1-consistency-monitoring
- ‚úÖ BigQuery Table: mlb_reference.unresolved_players
- ‚úÖ Monitoring Script: Tested and working
- ‚úÖ AlertManager: Rate-limited alerts configured

---

## üí° Recommended Session Plans

### Plan 1: Quick Check-In (15 min)
1. Run monitoring script
2. Check Slack
3. Document results
4. Done!

### Plan 2: Monitoring + Quick Win (1.5-2 hours)
1. Run monitoring script (15 min)
2. Choose one quick win from Option B (1-2 hours)
3. Document what you did

### Plan 3: Monitoring + Strategic Feature (3-4 hours)
1. Run monitoring script (15 min)
2. Choose one strategic feature from Option C (2-3 hours)
3. Test thoroughly
4. Deploy and verify

### Plan 4: Day 8 Switchover (Jan 28 only, 2-3 hours)
1. Run pre-switchover checks (30 min)
2. Execute switchover (30 min)
3. Monitor closely (1-2 hours)
4. Document results

---

## üéØ Agent Instructions for New Sessions

**If you're an AI agent starting a new session, follow these steps:**

### 1. Determine Current Day
```bash
# Check what day it is
date "+%Y-%m-%d"

# Calculate day number (Jan 21 = Day 1)
# Day 0 was Jan 20, 2026
```

### 2. Run Monitoring First (ALWAYS)
```bash
./bin/monitoring/week_1_daily_checks.sh
```

### 3. Read the Output
- If all checks pass ‚Üí Proceed to user's chosen work
- If any check fails ‚Üí Stop and investigate (use runbook)

### 4. Ask User What They Want to Do

Present options based on current day:

**For Days 1-6 (Jan 21-26):**
```
I've completed the monitoring checks - all systems healthy! ‚úÖ

What would you like to work on today?

1. Just monitoring (done!) - 0 min remaining
2. Quick win: Cloud Run right-sizing (1 hour) - 50% cost savings
3. Quick win: SELECT * optimization (1-2 hours) - 10-20% query savings
4. Quick win: Document Cloud Functions (1-2 hours) - Better operations
5. Strategic: Integration tests (2-3 hours) - Safety net
6. Strategic: Prometheus metrics (1-2 hours) - Better observability
7. Strategic: Universal retry mechanism (2-3 hours) - Better reliability

Or something else?
```

**For Day 7 (Jan 27):**
```
I've completed the monitoring checks - all systems healthy! ‚úÖ

üö® IMPORTANT: Tomorrow is Day 8 - the critical switchover day!

Would you like to:
1. Run pre-switchover checks to ensure readiness
2. Review the switchover plan
3. Work on other improvements (but be ready for tomorrow!)
```

**For Day 8 (Jan 28):**
```
I've completed the monitoring checks - all systems healthy! ‚úÖ

üö® TODAY IS SWITCHOVER DAY! üö®

We need to switch from array reads to subcollection reads.

Ready to proceed with the switchover? This is the most critical step of Week 1.

[If yes] Let me run the pre-switchover checks first...
[If no] When would you like to do this? It's time-sensitive.
```

**For Days 9-14 (Jan 29-Feb 3):**
```
I've completed the monitoring checks - all systems healthy! ‚úÖ

We're now reading from subcollections (Day 8 switchover complete).

What would you like to work on today?
[Same options as Days 1-6]
```

**For Day 15+ (Feb 4+):**
```
I've completed the monitoring checks - all systems healthy! ‚úÖ

üéâ We're past Day 15! Time to stop dual-write and archive the channel.

Would you like to:
1. Complete the final switchover (stop dual-write)
2. Archive #week-1-consistency-monitoring
3. Work on future improvements
```

### 5. Use Parallel Agents When Appropriate

For large exploratory tasks, launch Explore agents in parallel:

```
I'm going to launch 6 Explore agents in parallel to study:
1. Week 1 deployment status
2. Week 2-3 improvement opportunities
3. Technical debt and TODOs
4. Cost optimization opportunities
5. Testing coverage and quality
6. Documentation gaps and opportunities

This will take 3-5 minutes and give us a comprehensive view.
```

---

## üìä Success Metrics

### Week 1 Success Criteria

‚úÖ **Primary Goals** (must achieve):
- Zero consistency mismatches during dual-write period
- Successful Day 8 switchover with zero data loss
- Successful Day 15 completion (dual-write stopped)

‚úÖ **Secondary Goals** (nice to have):
- No production incidents during migration
- All daily checks documented
- Team confidence in subcollection approach

### How to Measure

```bash
# Check consistency mismatch count
grep "Consistency Mismatches:" docs/09-handoff/week-1-monitoring-log.md | grep -v "0"

# Should return nothing if all good

# Check for any Slack alerts
# Visit #week-1-consistency-monitoring
# Should have only test messages + deployment notifications
```

---

## ‚ö†Ô∏è Troubleshooting Quick Reference

### Issue: Monitoring script fails to run

```bash
# Check if script is executable
ls -la bin/monitoring/week_1_daily_checks.sh

# Make executable if needed
chmod +x bin/monitoring/week_1_daily_checks.sh

# Run directly
bash bin/monitoring/week_1_daily_checks.sh
```

### Issue: Consistency mismatch detected

1. **STOP immediately** - Do not proceed with other work
2. Check logs for the specific batch:
```bash
gcloud logging read \
  "severity=WARNING 'CONSISTENCY MISMATCH'" \
  --limit 50 \
  --freshness=24h
```
3. Check Slack for alert (should have been sent)
4. Follow runbook: `docs/02-operations/robustness-improvements-runbook.md`

### Issue: Service unhealthy

```bash
# Check service status
gcloud run services describe prediction-coordinator \
  --region us-west2 \
  --format=json

# Check recent logs
gcloud logging read \
  "resource.labels.service_name=prediction-coordinator" \
  --limit 50 \
  --freshness=10m
```

---

## üéì Additional Context

### Why This Matters

Week 1 is a critical migration from ArrayUnion to Subcollections for completion tracking. This addresses:
- Scalability issues (ArrayUnion has 20,000 element limit)
- Race conditions in high-concurrency scenarios
- Better query performance

### What Happens After Week 1

Once Week 1 completes successfully:
- ArrayUnion code can be deprecated
- Subcollection becomes primary data source
- Monitoring shifts to normal operations
- Focus on next improvements

---

## ‚úÖ Session End Checklist

Before ending any session, ensure:

- [ ] Monitoring checks run and documented
- [ ] Any changes committed to git
- [ ] Any deployments verified healthy
- [ ] Slack checked for alerts
- [ ] Monitoring log updated
- [ ] Next session knows what to do (this doc!)

---

## üöÄ Ready to Start?

1. **Check the date** - What day of Week 1 is it?
2. **Run monitoring** - Always start here
3. **Choose your work** - Based on time and priority
4. **Execute and document** - Follow the plans above
5. **End with checklist** - Don't forget anything

Good luck! üéâ

---

**Questions?** Check the reference docs or ask the user for clarification.

**Issues?** Use the runbook: `docs/02-operations/robustness-improvements-runbook.md`

**Stuck?** Launch Explore agents to investigate the codebase.
