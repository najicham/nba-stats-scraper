# Session 167 Handoff: Model Loading Fix + Feb 2-7 Backfill (Partial)

**Date:** 2026-02-09
**Focus:** Fix model loading bugs, complete Feb 2-7 prediction backfill with correct model

## Summary

Continuing Session 166's work to fix the wrong-model bug (Feb 2-7 predictions generated by deprecated/untested models). This session discovered and fixed **three root causes** of the wrong-model bug, but the backfill is only partially complete (Feb 2-4 done, Feb 5-7 still need backfill).

## What Was Done

### 1. Fixed Model Loading Priority (`catboost_v9.py`)

**Problem:** `_load_model_from_default_location()` checked local files FIRST, then the `CATBOOST_V9_MODEL_PATH` env var. Any model baked into the Docker image silently overrode the env var.

**Fix:** Reversed priority order:
1. **Priority 1:** `CATBOOST_V9_MODEL_PATH` env var (authoritative when set)
2. **Priority 2:** Local model files (sorted alphabetically)
3. **Priority 3:** Default GCS path

### 2. Made `cloudbuild.yaml` Read Production Model from Manifest

**Problem:** Production model filename was hardcoded in `cloudbuild.yaml`. Required manual updates on every model promotion.

**Fix:** Step 0 now:
1. Downloads `manifest.json` from GCS
2. Parses it to find the model with `status: "production"`
3. Downloads that model dynamically

**Note:** Cloud Build requires `$$` for shell variable escaping (not `$`). First build failed because `$MODEL_GCS_PATH` was interpreted as a substitution variable.

### 3. Removed 44 Git-Tracked Model Files

**Critical discovery:** `models/` was in `.gitignore` but 44 model files were STILL tracked in git (committed before the gitignore was added). When Cloud Build checked out the repo, it got the wrong model (`catboost_v9_36features`) alongside the correct one. Since `sorted(model_files)[-1]` picks alphabetically, `36features` > `33features` won.

**Fix:**
- `git rm --cached` all 44 tracked model files
- Added `rm -f models/catboost_v9*.cbm` in `cloudbuild.yaml` Step 0 before downloading the correct model

### 4. Set `CATBOOST_V9_MODEL_PATH` Env Var on Worker

Even after the build fixes, old Cloud Run instances were still processing Pub/Sub messages with the wrong model. Setting the env var directly on the Cloud Run service created a new revision that forces all instances to load from GCS.

```bash
gcloud run services update prediction-worker --region=us-west2 \
  --update-env-vars="CATBOOST_V9_MODEL_PATH=gs://nba-props-platform-models/catboost/v9/catboost_v9_33features_20260201_011018.cbm"
```

**Confirmed working:** Worker logs show `Loading CatBoost V9 from: gs://...33features...` with SHA `5b3a187b1b6dfac6`.

### 5. Partial Backfill Status

| Date | Status | Active Predictions | Model | avg_pvl |
|------|--------|-------------------|-------|---------|
| Feb 2 | **DONE** | 62 | 33features (correct) | -0.26 |
| Feb 3 | **DONE** | 154 | 33features (correct) | -0.31 |
| Feb 4 | **DONE** | 99 | 33features (correct) | -3.44 |
| Feb 5 | **NEEDS BACKFILL** | 0 | All deactivated | — |
| Feb 6 | **NEEDS BACKFILL** | 0 | All deactivated | — |
| Feb 7 | **NEEDS BACKFILL** | 0 | All deactivated | — |

**Why Feb 5-7 are incomplete:** Multiple backfill attempts were thwarted by:
1. Old Cloud Run instances still processing Pub/Sub with wrong model
2. BQ DML race conditions (deactivation UPDATE running concurrently with worker writes)
3. Coordinator timing out on `/start` requests

All wrong-model predictions for Feb 5-7 have been deactivated (`is_active=FALSE, superseded=TRUE`).

### 6. Bug Found: Regeneration Supersede Doesn't Deactivate

**Discovery:** The `/regenerate-with-supersede` endpoint sets `superseded=TRUE` but does NOT set `is_active=FALSE`. The quality gate checks `is_active=TRUE` for existing predictions, so superseded-but-still-active predictions block new predictions.

**Impact:** The regeneration endpoint is partially broken — it marks old predictions as superseded but the quality gate still sees them as "existing" and skips regeneration.

**Recommended fix:** In `_mark_predictions_superseded()` (coordinator.py ~line 2009), also set `is_active = FALSE`:
```sql
UPDATE ... SET
    superseded = TRUE,
    superseded_at = CURRENT_TIMESTAMP(),
    superseded_reason = @reason,
    is_active = FALSE  -- ADD THIS
WHERE ...
```

## What Needs To Be Done (Next Session)

### Step 1: Complete Feb 5-7 Backfill

The worker now loads the correct model via the env var. Trigger backfill:

```bash
TOKEN=$(gcloud auth print-identity-token)
for DATE in 2026-02-05 2026-02-06 2026-02-07; do
  echo "=== Triggering $DATE ==="
  curl -X POST "https://prediction-coordinator-f7p3g7f6ya-wl.a.run.app/start" \
    -H "Authorization: Bearer $TOKEN" \
    -H "Content-Type: application/json" \
    -d "{\"game_date\": \"$DATE\", \"prediction_run_mode\": \"BACKFILL\"}"
  echo ""
  # Wait for batch to complete (check /status, ~2-3 min per date)
  sleep 180
  # Reset if stuck (some players always timeout)
  curl -X POST "https://prediction-coordinator-f7p3g7f6ya-wl.a.run.app/reset" \
    -H "Authorization: Bearer $TOKEN" \
    -H "Content-Type: application/json" \
    -d "{\"game_date\": \"$DATE\"}"
  sleep 5
done
```

**Expected:** ~70-100 active predictions per date with `model_file_name = 'catboost_v9_33features_20260201_011018.cbm'`.

**Note:** The coordinator may time out on `/start` — if so, the batch is still running. Check `/status` separately.

### Step 2: Verify Correct Model for All Dates

```sql
SELECT game_date,
  ARRAY_AGG(DISTINCT model_file_name IGNORE NULLS) as models,
  COUNT(*) as active,
  ROUND(AVG(predicted_points - current_points_line), 2) as avg_pvl
FROM nba_predictions.player_prop_predictions
WHERE game_date BETWEEN '2026-02-02' AND '2026-02-07'
  AND system_id = 'catboost_v9' AND is_active = TRUE
  AND current_points_line IS NOT NULL
GROUP BY 1 ORDER BY 1;
```

All dates should show ONLY `catboost_v9_33features_20260201_011018.cbm` with avg_pvl near 0 (not -4 to -6).

### Step 3: Trigger Re-grading

```bash
for DATE in 2026-02-02 2026-02-03 2026-02-04 2026-02-05 2026-02-06 2026-02-07; do
  gcloud pubsub topics publish nba-grading-trigger \
    --project=nba-props-platform \
    --message="{\"target_date\":\"$DATE\",\"trigger_source\":\"backfill\"}"
  sleep 2
done
```

### Step 4: Re-materialize Subsets

Subsets read from `player_prop_predictions` with `is_active = TRUE`. After prediction backfill and grading, subsets MUST be re-materialized:

```bash
PYTHONPATH=. python backfill_jobs/publishing/daily_export.py \
  --start-date 2026-02-02 --end-date 2026-02-07 \
  --only subset-picks
```

**Why:** Subsets don't auto-regenerate after prediction backfill. They read `is_active = TRUE` predictions and create versioned picks in `current_subset_picks` table, then export to GCS JSON. Without re-materialization, API consumers see stale picks.

### Step 5: Re-run Experiment

Once grading is corrected:
```bash
PYTHONPATH=. python ml/experiments/quick_retrain.py \
    --name "V9_JAN31_REEVAL" \
    --train-start 2025-11-02 --train-end 2026-01-31 \
    --eval-start 2026-02-01 --eval-end 2026-02-07 --force
```

### Step 6: Fix Regeneration Supersede Bug (Recommended)

In `predictions/coordinator/coordinator.py`, function `_mark_predictions_superseded()` (~line 2009), add `is_active = FALSE` to the UPDATE statement. Currently superseded predictions remain active, blocking the quality gate from allowing regeneration.

## Files Modified

| File | Change |
|------|--------|
| `predictions/worker/prediction_systems/catboost_v9.py` | Env var checked first, before local files |
| `cloudbuild.yaml` | Reads model from manifest.json dynamically, cleans old models |
| `models/*` (44 files) | Removed from git tracking (still in .gitignore) |

## Commits

```
34670a0c fix: Env var takes priority over local models, cloudbuild reads manifest
40398e28 fix: Escape shell variables in cloudbuild.yaml for Cloud Build
dbe597cc fix: Remove git-tracked model files and clean stale models in build
```

## Architectural Lessons

1. **Git-tracked files override .gitignore** — Files committed before `.gitignore` was added remain tracked. `git rm --cached` is needed to stop tracking them. This was the root cause of the wrong model being baked into Docker images.

2. **Cloud Build `$$` escaping** — Shell variables in Cloud Build YAML must use `$$VAR` (double dollar) because `$VAR` is interpreted as a Cloud Build substitution variable.

3. **Old Cloud Run instances persist** — Even with 100% traffic to the latest revision, old instances can still process in-flight Pub/Sub messages. Setting an env var creates a new revision and forces all instances to restart.

4. **BQ DML race conditions** — When workers write predictions concurrently with UPDATE statements, some writes may land after the UPDATE and not be caught. Multiple cleanup passes may be needed.

5. **Regeneration supersede is incomplete** — Setting `superseded=TRUE` without `is_active=FALSE` creates a broken state where the quality gate still sees old predictions as "existing" and blocks regeneration.

6. **Coordinator `/start` can timeout** — Long-running `/start` requests (loading features, running quality gate) may timeout the HTTP connection. The batch still runs server-side. Check `/status` separately.

## Current Worker State

- **Revision:** `prediction-worker-00170-857` (commit `dbe597c`)
- **Env var:** `CATBOOST_V9_MODEL_PATH=gs://nba-props-platform-models/catboost/v9/catboost_v9_33features_20260201_011018.cbm`
- **Model loaded:** `catboost_v9_33features_20260201_011018.cbm` (SHA: `5b3a187b1b6dfac6`)
- **Loading method:** GCS via env var (Priority 1)
