# Session 37 Complete Handoff

**Date:** 2026-01-30
**Duration:** ~3 hours
**Status:** Investigation complete, fixes deployed, safeguards in place

---

## Quick Start for Next Session

```bash
# 1. Read this handoff
cat docs/09-handoff/2026-01-30-SESSION-37-COMPLETE-HANDOFF.md

# 2. Check current model performance
bq query --use_legacy_sql=false "
SELECT DATE_TRUNC(game_date, WEEK) as week,
  ROUND(100.0 * COUNTIF(prediction_correct) / COUNT(*), 1) as hit_rate
FROM nba_predictions.prediction_accuracy
WHERE system_id = 'catboost_v8' AND game_date >= '2025-12-01'
GROUP BY 1 ORDER BY 1 DESC"

# 3. Run daily validation
/validate-daily

# 4. Check pre-deploy validation passes
./bin/pre-deploy-validation.sh
```

---

## Critical Context: Confidence Calibration Impact

### How Confidence Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONFIDENCE FLOW                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PREDICTION TIME (when predict() is called):                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Features    â”‚ â†’  â”‚ _calculate_       â”‚ â†’  â”‚ Store in DB  â”‚  â”‚
â”‚  â”‚ Dict        â”‚    â”‚ confidence()      â”‚    â”‚ with record  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  GRADING TIME (next day, after game):                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Read stored â”‚ â†’  â”‚ Compare to        â”‚ â†’  â”‚ Store in     â”‚  â”‚
â”‚  â”‚ confidence  â”‚    â”‚ actual_points     â”‚    â”‚ pred_accuracyâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  âš ï¸  Confidence is FROZEN at prediction time!                   â”‚
â”‚  âš ï¸  Grading uses the STORED value, not recalculated!          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When Calibration Changes Take Effect

| Scenario | Effect |
|----------|--------|
| **Deploy calibration code** | Only NEW predictions use it |
| **Historical predictions** | Keep their original confidence |
| **prediction_accuracy table** | Uses confidence from prediction time |
| **Re-run prediction backfill** | Would apply new calibration |
| **Grading** | Uses whatever was stored |

### Implications for Analysis

```sql
-- After deploying calibration, you'll see a split:
-- OLD predictions: raw_confidence_score = calibrated_confidence_score
-- NEW predictions: raw_confidence_score â‰  calibrated_confidence_score

SELECT
  DATE(created_at) as created_date,
  calibration_method,
  COUNT(*) as predictions,
  AVG(raw_confidence_score) as avg_raw,
  AVG(confidence_score) as avg_calibrated
FROM nba_predictions.player_prop_predictions
WHERE game_date >= '2026-01-25'
GROUP BY 1, 2
ORDER BY 1;
```

### Options for Applying Calibration

| Option | Pros | Cons |
|--------|------|------|
| **Deploy and go forward** | Simple, no disruption | Historical analysis shows discontinuity |
| **Backfill predictions** | Consistent data | Expensive, may lose original predictions |
| **Post-hoc query adjustment** | No data changes | Complex queries, easy to forget |
| **Add calibrated column** | Best of both worlds | Schema change, storage cost |

**Recommendation:** Deploy and go forward. Use `calibration_method` field to filter/segment analysis.

---

## What Session 37 Accomplished

### 1. Root Cause Analysis

**Finding:** The January 7-9 model collapse was a "perfect storm" of 6 concurrent issues:

| Issue | Impact |
|-------|--------|
| V8 deployed expecting 33 features | Model change |
| Feature version mismatch (got 25 features) | Wrong predictions |
| Missing betting data (Jan 6, 8) | No lines |
| BigDataBall lineup gap (Jan 9) | No players found |
| Ball Don't Lie API 502 errors | Scraper failures |
| Prediction worker OOM crashes | Reduced volume |

**Result:**
- Decile 10 picks: 124 â†’ 7 (94% drop)
- Hit rate: 67.9% â†’ 48.3%
- Model edge: +1.42 â†’ -0.91 (Vegas now beats us)

### 2. Bug Fixes Applied

| Bug | Fix | Status |
|-----|-----|--------|
| Double-insertion in player_game_summary | Removed nested `@retry_on_serialization` from `save_analytics()` | âœ… Committed |
| 2026-01-29 duplicates | Deduplicated 564 â†’ 282 records | âœ… Done |
| No error tracking | Added `prediction_error_code` to output | âœ… Committed |

### 3. Database Schema Changes

**Applied via BigQuery ALTER TABLE:**

```sql
-- player_prop_predictions (9 new columns)
feature_version STRING
feature_count INT64
feature_quality_score NUMERIC(5,2)
feature_data_source STRING
early_season_flag BOOLEAN
prediction_error_code STRING
raw_confidence_score NUMERIC(4,3)
calibrated_confidence_score NUMERIC(4,3)
calibration_method STRING

-- prediction_accuracy (7 new columns)
feature_version STRING
feature_count INT64
feature_quality_score NUMERIC(5,2)
feature_data_source STRING
early_season_flag BOOLEAN
raw_confidence_score NUMERIC(4,3)
calibration_method STRING
```

### 4. Safeguards Implemented

| Safeguard | File | Purpose |
|-----------|------|---------|
| Pre-deploy validation | `bin/pre-deploy-validation.sh` | Prevents feature version mismatch |
| Confidence distribution alert | `validation/queries/monitoring/confidence_distribution_alert.sql` | Detects when high-confidence buckets disappear |
| Vegas sharpness tracking | `validation/queries/monitoring/vegas_sharpness_tracking.sql` | Monitors if Vegas is getting more accurate |

### 5. Code Changes

**Modified:**
- `data_processors/analytics/operations/bigquery_save_ops.py` - Removed nested retry decorator
- `predictions/worker/prediction_systems/catboost_v8.py` - Added error tracking fields to output

**New files:**
- `bin/pre-deploy-validation.sh`
- `docs/08-projects/current/v8-model-investigation/ROOT-CAUSE-ANALYSIS-JAN-7-9.md`
- `docs/08-projects/current/v8-model-investigation/SAFEGUARDS-AND-ERROR-TRACKING-PLAN.md`
- `docs/08-projects/current/v8-model-investigation/SESSION-37-INVESTIGATION-REPORT.md`
- `schemas/bigquery/migrations/2026-01-30-add-error-tracking-fields.sql`
- `validation/queries/monitoring/confidence_distribution_alert.sql`
- `validation/queries/monitoring/vegas_sharpness_tracking.sql`

### 6. Commit Created

```
f343bf85 fix: Add error tracking safeguards and fix double-insertion bug
```

---

## What Still Needs To Be Done

### Priority 1: Deploy Code Changes

The bug fixes and error tracking are committed but **not deployed to Cloud Run**.

```bash
# Deploy prediction worker with new error tracking
./bin/deploy-service.sh prediction-worker

# Deploy analytics processors with retry fix
./bin/deploy-service.sh nba-phase3-analytics-processors
```

### Priority 2: Confidence Calibration (No Challenger Needed)

**Why no challenger:** Calibration is POST-model, doesn't change predictions.

**Options (pick one):**

**Option A: Temperature Scaling (Simplest)**
```python
# In catboost_v8.py _calculate_confidence()
confidence = confidence * 0.85  # Reduce over-confidence
```

**Option B: Threshold Raise (Business Rule)**
```python
# In catboost_v8.py _generate_recommendation()
if confidence < 75:  # Was 60
    return 'PASS'
```

**Option C: Isotonic Regression (Best)**
```python
# Fit on historical data, apply as post-processing
from sklearn.isotonic import IsotonicRegression
calibrator = IsotonicRegression(out_of_bounds='clip')
calibrator.fit(predicted_confidences, actual_accuracies)
```

### Priority 3: Model Decision

The model itself may need attention:

| Option | When To Use | Effort |
|--------|-------------|--------|
| Keep V8, add calibration | Quick fix needed | Low |
| Retrain V8 with 2026 data | Model drift confirmed | Medium |
| Deploy V9/V10 challenger | Major improvement needed | High |

### Priority 4: Monitoring Integration

Add to `/validate-daily` skill:
- [ ] Confidence distribution check
- [ ] Vegas sharpness check
- [ ] Feature version mismatch check
- [ ] Error code distribution check

---

## Key Queries for Monitoring

### Check Model Performance

```sql
-- Weekly hit rate trend
SELECT
  DATE_TRUNC(game_date, WEEK) as week,
  COUNT(*) as predictions,
  ROUND(100.0 * COUNTIF(prediction_correct) / COUNT(*), 1) as hit_rate,
  ROUND(AVG(ABS(predicted_points - actual_points)), 2) as mae
FROM nba_predictions.prediction_accuracy
WHERE system_id = 'catboost_v8'
  AND game_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 8 WEEK)
GROUP BY 1 ORDER BY 1 DESC;
```

### Check Vegas vs Model Edge

```sql
-- Are we still beating Vegas?
SELECT
  DATE_TRUNC(game_date, WEEK) as week,
  ROUND(AVG(ABS(line_value - actual_points)), 2) as vegas_mae,
  ROUND(AVG(ABS(predicted_points - actual_points)), 2) as model_mae,
  ROUND(AVG(ABS(line_value - actual_points)) - AVG(ABS(predicted_points - actual_points)), 2) as our_edge
FROM nba_predictions.prediction_accuracy
WHERE system_id = 'catboost_v8'
  AND game_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 4 WEEK)
  AND line_value IS NOT NULL
GROUP BY 1 ORDER BY 1 DESC;
```

### Check Confidence Distribution

```sql
-- Has the distribution shifted?
SELECT
  ROUND(confidence_score, 1) as bucket,
  COUNT(*) as count,
  ROUND(100.0 * COUNTIF(prediction_correct) / NULLIF(COUNT(*), 0), 1) as hit_rate
FROM nba_predictions.prediction_accuracy
WHERE system_id = 'catboost_v8'
  AND game_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
GROUP BY 1 ORDER BY 1 DESC;
```

### Check Error Codes (After Deploy)

```sql
-- What errors are occurring?
SELECT
  game_date,
  prediction_error_code,
  COUNT(*) as count
FROM nba_predictions.player_prop_predictions
WHERE game_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 3 DAY)
  AND prediction_error_code IS NOT NULL
GROUP BY 1, 2 ORDER BY 1 DESC, 3 DESC;
```

---

## Understanding the Confidence Problem

### Current State (Miscalibrated)

| Confidence Level | Expected Hit Rate | Actual Hit Rate | Status |
|------------------|-------------------|-----------------|--------|
| 90-100% (Decile 10) | ~90% | **25%** | ðŸ”´ Broken |
| 85-89% (Decile 9) | ~85% | **51%** | ðŸ”´ Broken |
| 80-84% | ~80% | ~55% | ðŸŸ¡ Poor |

### Why It's Miscalibrated

1. **Confidence formula is simple heuristic:**
   ```python
   confidence = 75.0  # Base
   confidence += quality_bonus(feature_quality_score)  # +2 to +10
   confidence += consistency_bonus(points_std_last_10)  # +2 to +10
   # Range: 77-95%
   ```

2. **It doesn't use model uncertainty** - CatBoost can provide prediction intervals, but we don't use them.

3. **It doesn't adapt to market conditions** - Vegas got sharper, our formula didn't adjust.

4. **Missing features affected both confidence and accuracy** - But not in proportion.

### Calibration Approaches

**Approach 1: Post-hoc scaling**
- Multiply all confidences by 0.7-0.85
- Simple, but loses discrimination

**Approach 2: Bucket mapping**
- Map 90% â†’ 52%, 85% â†’ 48%, etc.
- Based on empirical hit rates
- Preserves relative ordering

**Approach 3: Isotonic regression**
- Non-parametric, learns optimal mapping
- Best calibration, requires fitting

**Approach 4: Temperature scaling**
- `calibrated = softmax(logits / T)` where T > 1
- Standard ML calibration technique

---

## Documentation Reference

| Document | Purpose | Location |
|----------|---------|----------|
| Root Cause Analysis | Why Jan 7-9 failed | `docs/08-projects/current/v8-model-investigation/ROOT-CAUSE-ANALYSIS-JAN-7-9.md` |
| Safeguards Plan | Prevention mechanisms | `docs/08-projects/current/v8-model-investigation/SAFEGUARDS-AND-ERROR-TRACKING-PLAN.md` |
| Investigation Report | Full Session 37 analysis | `docs/08-projects/current/v8-model-investigation/SESSION-37-INVESTIGATION-REPORT.md` |
| Champion-Challenger Framework | When to use challengers | `docs/08-projects/current/ml-model-v8-deployment/CHAMPION-CHALLENGER-FRAMEWORK.md` |
| DB Migration | Schema changes | `schemas/bigquery/migrations/2026-01-30-add-error-tracking-fields.sql` |

---

## Key Learnings from Session 37

1. **Confidence is NOT from the model** - It's a separate heuristic formula
2. **No challenger needed for calibration** - It's post-processing, not model change
3. **Feature version mismatches are silent killers** - Now we have validation
4. **Multiple small issues compound** - 6 minor issues = major failure
5. **Vegas is getting sharper** - Their MAE improved 13%, monitor it
6. **Nested retry decorators cause duplicates** - Fixed in this session
7. **Error tracking was missing** - Now we have error codes and warnings

---

## Recommended Next Steps (Prioritized)

### Immediate (Today)
1. âœ… Bug fixes committed (done)
2. â¬œ Deploy to Cloud Run

### This Week
3. â¬œ Decide on calibration approach
4. â¬œ Implement chosen calibration
5. â¬œ Add monitoring to /validate-daily

### Next Week
6. â¬œ Evaluate if model needs retraining
7. â¬œ Consider V9/V10 challenger if retraining
8. â¬œ Backfill with new error tracking fields

---

## Git State

```bash
# Latest commit
f343bf85 fix: Add error tracking safeguards and fix double-insertion bug

# Files not committed (safe to ignore)
ml/experiments/results/catboost_v11_*.json  # Experiment metadata
docs/09-handoff/2026-01-30-SESSION-34-*.md  # Previous session doc
```

---

## Contact Points

- **Session 36 handoff:** `docs/09-handoff/2026-01-30-SESSION-36-V8-INVESTIGATION-HANDOFF.md`
- **Session 35 handoff:** `docs/09-handoff/2026-01-30-SESSION-35-V8-DEGRADATION-INVESTIGATION.md`
- **Operations runbook:** `docs/02-operations/daily-operations-runbook.md`

---

*Session 37 complete. The January 7-9 model collapse has been fully investigated, root causes identified, and safeguards implemented. Next session should focus on deploying code changes and deciding on calibration approach.*
