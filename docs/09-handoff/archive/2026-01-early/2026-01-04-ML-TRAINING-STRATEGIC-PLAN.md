# ML Training Strategic Plan - Ready to Execute
**Created**: January 4, 2026
**Status**: üéØ READY FOR EXECUTION
**Priority**: P0 - High Impact Opportunity

---

## EXECUTIVE SUMMARY

**Situation**: All data quality issues fixed, backfills complete, but no new model trained on clean data

**Opportunity**: Train XGBoost v5 with clean dataset ‚Üí Expected 15-20% improvement over baseline

**Current State**:
- Production baseline: 4.27 MAE (mock model)
- Latest v4 model: 4.56 MAE (trained on corrupt data)
- Data quality: NOW FIXED (minutes: 0.64% NULL, usage_rate: 95%+ coverage)

**Expected Outcome**: v5 model achieving 3.40-3.80 MAE (beats baseline by 15-20%)

**Timeline**: 3-5 hours total (validation + training + post-validation)

**Risk Level**: LOW (data validated, pipeline proven, deployment path tested)

---

## BACKGROUND: WHAT HAPPENED

### The Data Quality Journey (Jan 3-4, 2026)

**Critical Bugs Discovered & Fixed**:

1. **minutes_played Bug** (commit 83d91e2)
   - Problem: Field incorrectly included in `pd.to_numeric()` conversion
   - Impact: 99.5% NULL rate (coerced "45:58" ‚Üí NaN)
   - Fix: Removed from numeric_columns list
   - Result: 0.64% NULL rate ‚úÖ
   - Backfill: Complete (21 minutes with 15 parallel workers)

2. **usage_rate Implementation** (commit 390caba)
   - Problem: Code literally had `'usage_rate': None # Requires team stats`
   - Impact: 100% NULL across ALL historical data
   - Fix: Added team_offense dependency + Basketball-Reference formula
   - Result: 95-99% coverage ‚úÖ

3. **Shot Distribution Regression** (commit 390caba)
   - Problem: BigDataBall format change (added player_id prefix)
   - Impact: 0% coverage for 2025/2026 season (JOIN broke)
   - Fix: REGEXP_REPLACE to strip numeric prefix
   - Result: 40-50% coverage for current season ‚úÖ

**Why v4 Model Failed**:
- Trained on dataset with 55% fake/default data
- XGBoost learned NULL‚Üídefault patterns, not real NBA gameplay
- More features = more NULLs = worse performance (4.56 MAE vs 4.27 baseline)

**What Changed**:
- Full historical backfill (2021-2026): 127k+ complete records
- All critical features now have >95% coverage
- Phase 4 precompute: 88.1% coverage (maximum possible)
- Data quality validated with comprehensive checks

---

## STRATEGIC ANALYSIS

### Why This Is High Priority üéØ

**Perfect Storm of Readiness**:
- ‚úÖ Data quality fixed (3 critical bugs)
- ‚úÖ Full historical backfill complete
- ‚úÖ 21 well-engineered features
- ‚úÖ Proven training pipeline (v1-v4)
- ‚úÖ Validation infrastructure in place
- ‚úÖ Production deployment path ready
- ‚ùå **But no model trained on clean data!**

**Expected Impact**:
- Current production: 4.27 MAE (mock model)
- Expected v5: 3.40-3.80 MAE
- Improvement: 15-20% better predictions
- Business value: More accurate prop bets ‚Üí higher win rate

**Risk Assessment**: LOW
- Data quality independently validated
- Training pipeline tested multiple times
- Hyperparameters already optimized
- Deployment path proven
- Rollback plan: Keep mock model running

---

## THE 21-FEATURE MODEL

### Feature Architecture

**Performance Features (5)**:
```
points_avg_last_5      # Recent form
points_avg_last_10     # Medium-term trend
points_avg_season      # Season baseline
points_std_last_10     # Consistency/volatility
minutes_avg_last_10    # Playing time (WAS 95% NULL, NOW 0.64%)
```

**Composite Factors from Phase 4 (4)**:
```
fatigue_score              # 0-100 (100=fresh)
shot_zone_mismatch_score   # -10 to +10 (player zones vs opponent D)
pace_score                 # -3 to +3 (game pace impact)
usage_spike_score          # -3 to +3 (recent usage changes)
```

**Opponent Defense (2)**:
```
opponent_def_rating_last_15  # Points allowed per 100 possessions
opponent_pace_last_15        # Opponent pace
```

**Game Context (3)**:
```
is_home          # Home/away advantage
days_rest        # Recovery time
back_to_back     # B2B fatigue flag
```

**Shot Distribution (4)**:
```
paint_rate_last_10      # % shots from paint
mid_range_rate_last_10  # % shots from mid-range
three_pt_rate_last_10   # % shots from three
assisted_rate_last_10   # % makes assisted
```

**Team Metrics (2)**:
```
team_pace_last_10        # Team pace
team_off_rating_last_10  # Team offensive efficiency
```

**Usage Features (1)**:
```
usage_rate_last_10  # Player usage (WAS 0% NULL, NOW 95%+ coverage)
```

**Critical Dependencies**:
- Phase 3 (Analytics): player_game_summary, team_offense_game_summary
- Phase 4 (Precompute): player_composite_factors, team_defense_zone_analysis, player_daily_cache

---

## EXECUTION PLAN

### PHASE 1: Pre-Flight Validation (30-45 minutes) ‚úàÔ∏è

**Objective**: Validate data quality before investing in training

**Steps**:
1. Check minutes_played NULL rate (target: <1%)
2. Validate usage_rate coverage (target: >95%)
3. Check shot distribution coverage (target: >70%)
4. Verify Phase 4 precompute coverage (target: >85%)
5. Validate date range (2021-2026)
6. Run comprehensive feature validation

**Success Criteria**:
- All critical features >95% coverage
- No regressions vs historical baseline
- Date range complete
- Phase 4 dependency met

**Scripts to Run**:
```bash
# Feature validation
PYTHONPATH=. .venv/bin/python scripts/validation/validate_backfill_features.py \
  --start-date 2021-10-01 \
  --end-date 2026-01-03 \
  --with-regression-check

# Quick spot check
bq query --use_legacy_sql=false "
SELECT
  COUNT(*) as total_records,
  COUNTIF(minutes_played IS NULL) as minutes_null,
  COUNTIF(usage_rate IS NULL) as usage_null,
  COUNTIF(paint_rate IS NULL) as paint_null
FROM nba_analytics.player_game_summary
WHERE game_date >= '2021-10-01'
"
```

---

### PHASE 2: Train v5 Model (1-2 hours) üöÇ

**Objective**: Train XGBoost v5 with complete, clean dataset

**Pre-Training Checklist**:
- [ ] Phase 1 validation passed
- [ ] GCP credentials set: `export GCP_PROJECT_ID=nba-props-platform`
- [ ] Python environment active
- [ ] Script reviewed: `ml/train_real_xgboost.py`

**Training Command**:
```bash
cd /home/naji/code/nba-stats-scraper

export PYTHONPATH=.
export GCP_PROJECT_ID=nba-props-platform

# Execute training
.venv/bin/python ml/train_real_xgboost.py
```

**What Will Happen**:
1. Extracts data from BigQuery (127k+ records)
2. Engineers 21 features
3. Chronological split: 70% train / 15% val / 15% test
4. Trains XGBoost (up to 500 trees with early stopping)
5. Evaluates on test set
6. Compares against 4.27 baseline
7. Saves model: `models/xgboost_real_v5_21features_YYYYMMDD.json`
8. Saves metadata with metrics

**Expected Duration**: 5-10 minutes actual training

**Monitoring**:
- Watch for early stopping (validation MAE plateaus)
- Typical: 150-300 trees before stopping
- Progress printed every 20 iterations

**Expected Output**:
```
Training MAE:    3.8-4.0 points
Validation MAE:  4.0-4.2 points
Test MAE:        3.8-4.0 points
Baseline:        4.27 points
Improvement:     +12-15% ‚úÖ
```

---

### PHASE 3: Post-Training Validation (30-45 minutes) ‚úÖ

**Objective**: Rigorous validation before production deployment

**Validation Checklist**:

**1. Overfitting Check**:
```
Gap = (Test MAE - Train MAE) / Train MAE
‚úÖ GOOD:  Gap < 10%
‚ö†Ô∏è  OK:    Gap 10-15%
‚ùå BAD:   Gap > 15% (overfitting)
```

**2. Feature Importance Analysis**:
- Top features should make basketball sense
- Expected top 10:
  - points_avg_last_5/10
  - usage_rate_last_10 (NEW - should be important!)
  - minutes_avg_last_10
  - fatigue_score
  - opponent_def_rating_last_15
  - shot_zone_mismatch_score

**3. Baseline Comparison**:
```
Target: Test MAE < 4.27
‚úÖ EXCELLENT: < 4.0 (6%+ improvement)
‚úÖ GOOD:      4.0-4.2 (2-6% improvement)
‚ö†Ô∏è  OK:       4.2-4.27 (marginal)
‚ùå FAIL:      > 4.27 (worse than baseline)
```

**4. Spot Check Predictions**:
- Select 5-10 recent high-profile games
- Compare v5 predictions vs actuals
- Look for systematic bias (over/under predicting)
- Check edge cases (injuries, rest, blowouts)

**5. Prediction Distribution**:
- Check prediction range (should be 5-45 points)
- No extreme outliers (>50 or <0)
- Reasonable variance (not all 20-25 points)

**Query for Spot Checks**:
```sql
SELECT
  p.player_name,
  p.game_date,
  p.points_actual,
  m.points_predicted as mock_predicted,
  ABS(p.points_actual - m.points_predicted) as mock_error
FROM nba_analytics.player_game_summary p
JOIN nba_predictions.prediction_accuracy m
  ON p.player_name = m.player_name
  AND p.game_date = m.game_date
WHERE p.game_date >= '2025-12-01'
  AND m.system_id = 'xgboost_v1'
ORDER BY mock_error DESC
LIMIT 10
```

**Documentation**:
- Record all metrics in `models/xgboost_real_v5_*_metadata.json`
- Create handoff doc: `docs/09-handoff/2026-01-XX-V5-MODEL-TRAINING-SUCCESS.md`
- Document feature importance rankings
- Note any concerns or limitations

---

### PHASE 4: Production Deployment (1-2 hours) - CONDITIONAL ‚öôÔ∏è

**ONLY PROCEED IF**: Test MAE < 4.2 (meaningfully beats baseline)

**Deployment Steps**:

**1. Upload Model to GCS**:
```bash
gsutil cp models/xgboost_real_v5_21features_*.json \
  gs://nba-scraped-data/ml-models/production/

gsutil cp models/xgboost_real_v5_21features_*_metadata.json \
  gs://nba-scraped-data/ml-models/production/
```

**2. Update Prediction Worker Config**:
- Edit `predictions/worker/prediction_systems/xgboost_v1.py`
- Update model path to v5
- Set `USE_MOCK_MODEL = False`
- Test locally first

**3. Deploy to Cloud Run**:
```bash
./bin/predictions/deploy/deploy_prediction_worker.sh
```

**4. Smoke Test**:
```bash
# Get auth token
TOKEN=$(gcloud auth print-identity-token)

# Test prediction endpoint
curl -X POST https://prediction-worker-f7p3g7f6ya-wl.a.run.app/predict \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "player_name": "Luka Doncic",
    "game_date": "2026-01-05",
    "opponent": "LAL",
    "is_home": true
  }'
```

**5. Monitor Production Performance**:
- Check Cloud Run logs for errors
- Validate predictions look reasonable
- Monitor latency (<500ms target)
- Track daily MAE vs baseline

**Rollback Plan** (if issues):
```bash
# Revert to mock model
gsutil cp gs://nba-scraped-data/ml-models/production/mock_xgboost_v4.json \
  gs://nba-scraped-data/ml-models/production/active_model.json

# Redeploy
./bin/predictions/deploy/deploy_prediction_worker.sh
```

---

## SUCCESS CRITERIA

### Training Success ‚úÖ
- [ ] Training completes without errors
- [ ] Train/val/test MAE within 10% of each other
- [ ] Test MAE < 4.2 (beats 4.27 baseline)
- [ ] Feature importance makes basketball sense
- [ ] usage_rate in top 10 features
- [ ] No extreme predictions (<0 or >50)
- [ ] Spot checks look reasonable

### Validation Success ‚úÖ
- [ ] No overfitting detected
- [ ] Predictions normally distributed
- [ ] No systematic bias
- [ ] Comparable or better than v4 on all metrics
- [ ] Model artifact saved correctly
- [ ] Metadata complete and accurate

### Deployment Success ‚úÖ (if deployed)
- [ ] Model uploaded to GCS
- [ ] Cloud Run deployment successful
- [ ] Smoke test passes
- [ ] Production logs show no errors
- [ ] Predictions match expected format
- [ ] Latency acceptable (<500ms)

---

## FAILURE MODES & TROUBLESHOOTING

### If Training Fails

**Error: "Unable to connect to BigQuery"**
```bash
# Check GCP auth
gcloud auth application-default login

# Verify project
gcloud config get-value project
# Should be: nba-props-platform
```

**Error: "Table not found"**
```bash
# Verify tables exist
bq ls nba-props-platform:nba_analytics
bq ls nba-props-platform:nba_precompute

# Check specific table
bq show nba-props-platform:nba_analytics.player_game_summary
```

**Error: "Insufficient data for training"**
- Check date range in script (should be 2021-10-01 to latest)
- Verify backfill completion
- Run Phase 1 validation again

### If Model Underperforms (MAE > 4.2)

**Diagnostic Steps**:
1. Check feature NULL rates (might have new gaps)
2. Analyze feature importance (are critical features low?)
3. Check train/val/test split (might be imbalanced)
4. Review recent data quality (Phase 4 might have stopped)
5. Compare distribution vs v4 training data

**Potential Causes**:
- New data quality regression
- Feature engineering bug
- Hyperparameter mismatch
- Recent source data changes

**Actions**:
1. Re-run Phase 1 validation
2. Check last 7 days of data separately
3. Review BigQuery processor logs
4. Consider training on 2021-2023 only (known good data)

### If Overfitting Detected (Gap > 15%)

**Solutions**:
1. Increase regularization:
   - `min_child_weight: 3 ‚Üí 5`
   - `reg_lambda: 1 ‚Üí 2`
2. Reduce model complexity:
   - `max_depth: 8 ‚Üí 6`
   - `n_estimators: 500 ‚Üí 300`
3. More aggressive early stopping:
   - `early_stopping_rounds: 20 ‚Üí 10`

### If Feature Importance Unexpected

**Red Flags**:
- usage_rate NOT in top 10 (should be critical)
- minutes_avg_last_10 NOT in top 10 (should be critical)
- Placeholder features high (shouldn't exist in v5)
- Random features dominating

**Investigation**:
1. Check feature NULL rates in training data
2. Verify feature engineering logic
3. Review train/val/test distributions
4. Check for data leakage

---

## MONITORING PLAN

### Phase 5: Ongoing Monitoring (Continuous)

**Daily Metrics** (automated):
```sql
-- Daily MAE tracking
SELECT
  DATE(p.game_date) as date,
  COUNT(*) as predictions,
  AVG(ABS(p.points_actual - m.points_predicted)) as mae,
  STDDEV(ABS(p.points_actual - m.points_predicted)) as mae_std
FROM nba_analytics.player_game_summary p
JOIN nba_predictions.prediction_accuracy m
  ON p.player_name = m.player_name
  AND p.game_date = m.game_date
WHERE m.system_id = 'xgboost_v5'
  AND p.game_date >= CURRENT_DATE() - 7
GROUP BY date
ORDER BY date DESC
```

**Weekly Analysis**:
- MAE trend (improving/degrading?)
- Feature drift detection
- Comparison vs mock model
- Outlier analysis

**Monthly Review**:
- Retrain consideration (if data quality improves)
- Hyperparameter tuning
- Feature engineering improvements
- A/B test results

---

## KEY FILES REFERENCE

### Training & Model Files
```
ml/train_real_xgboost.py                    # Main training script
models/xgboost_real_v4_21features_*.json    # Latest model (v4)
models/xgboost_real_v4_*_metadata.json      # v4 metadata
predictions/worker/prediction_systems/      # Production prediction code
predictions/shared/mock_xgboost_model.py    # Mock model (current prod)
```

### Validation Scripts
```
scripts/validation/validate_backfill_features.py    # Feature validation
scripts/validation/validate_player_summary.sh       # Player summary checks
shared/validation/feature_thresholds.py             # Threshold definitions
shared/validation/validators/feature_validator.py   # Feature validator
shared/validation/validators/regression_detector.py # Regression detection
```

### BigQuery Tables
```
nba_analytics.player_game_summary           # Phase 3 (main features)
nba_analytics.team_offense_game_summary     # Team context
nba_precompute.player_composite_factors     # Composite scores
nba_precompute.team_defense_zone_analysis   # Opponent defense
nba_precompute.player_daily_cache           # Cached team metrics
nba_predictions.prediction_accuracy         # Production predictions
```

### Documentation
```
docs/09-handoff/2026-01-04-ML-TRAINING-READY-HANDOFF.md    # Latest state
docs/09-handoff/2026-01-03-DATA-QUALITY-BREAKTHROUGH.md    # Data issues
docs/08-projects/current/ml-model-development/             # Project history
docs/03-phases/phase5-predictions/ml-training/             # Training docs
```

---

## DECISION TREE

```
START: Should we train v5?
‚îÇ
‚îú‚îÄ Is data quality validated?
‚îÇ  ‚îú‚îÄ NO ‚Üí Run Phase 1 validation first
‚îÇ  ‚îî‚îÄ YES ‚Üí Continue
‚îÇ
‚îú‚îÄ Did Phase 1 pass all checks?
‚îÇ  ‚îú‚îÄ NO ‚Üí Investigate issues, fix, re-run
‚îÇ  ‚îî‚îÄ YES ‚Üí Continue
‚îÇ
‚îú‚îÄ Execute Phase 2 (training)
‚îÇ  ‚îú‚îÄ Training failed? ‚Üí Troubleshoot, check logs
‚îÇ  ‚îî‚îÄ Training succeeded ‚Üí Continue
‚îÇ
‚îú‚îÄ Check Test MAE:
‚îÇ  ‚îú‚îÄ MAE > 4.27 ‚Üí STOP, investigate why worse than baseline
‚îÇ  ‚îú‚îÄ MAE 4.2-4.27 ‚Üí Phase 3 validation, document, DON'T deploy
‚îÇ  ‚îî‚îÄ MAE < 4.2 ‚Üí Continue
‚îÇ
‚îú‚îÄ Execute Phase 3 (validation)
‚îÇ  ‚îú‚îÄ Overfitting? ‚Üí Adjust hyperparameters, retrain
‚îÇ  ‚îú‚îÄ Bad feature importance? ‚Üí Investigate data quality
‚îÇ  ‚îî‚îÄ All checks pass ‚Üí Continue
‚îÇ
‚îú‚îÄ Should we deploy?
‚îÇ  ‚îú‚îÄ MAE < 4.0 ‚Üí YES, high confidence
‚îÇ  ‚îú‚îÄ MAE 4.0-4.2 ‚Üí MAYBE, discuss with team
‚îÇ  ‚îî‚îÄ MAE > 4.2 ‚Üí NO, not worth risk
‚îÇ
‚îî‚îÄ If deploying:
   ‚îú‚îÄ Execute Phase 4 (deployment)
   ‚îú‚îÄ Smoke test passes?
   ‚îÇ  ‚îú‚îÄ NO ‚Üí Rollback immediately
   ‚îÇ  ‚îî‚îÄ YES ‚Üí Monitor closely
   ‚îî‚îÄ Begin Phase 5 (ongoing monitoring)
```

---

## TIMELINE ESTIMATE

**Conservative (thorough)**:
- Phase 1 (validation): 45 minutes
- Phase 2 (training): 1.5 hours (includes review)
- Phase 3 (post-validation): 45 minutes
- Phase 4 (deployment): 1.5 hours
- **Total**: ~4.5 hours

**Optimistic (if smooth)**:
- Phase 1: 30 minutes
- Phase 2: 1 hour
- Phase 3: 30 minutes
- Phase 4: 1 hour
- **Total**: ~3 hours

**Realistic**: Plan for 4 hours, hope for 3

---

## COMMUNICATION PLAN

### Before Training
- [ ] Review this plan with team
- [ ] Confirm no ongoing backfills
- [ ] Verify Phase 4 processors running normally
- [ ] Set expectations: 3-5 hour session

### During Training
- [ ] Share training progress updates
- [ ] Document any unexpected findings
- [ ] Alert if issues discovered

### After Training
- [ ] Share results immediately (success or failure)
- [ ] Document learnings in handoff
- [ ] Update team on next steps
- [ ] If successful, schedule deployment

### After Deployment (if applicable)
- [ ] Daily MAE reports for first week
- [ ] Weekly summary for first month
- [ ] Monthly performance review

---

## CONCLUSION

**Current Status**: üéØ **READY TO EXECUTE**

**Confidence Level**: HIGH (85%)
- Data quality fixes validated
- Training pipeline proven
- Infrastructure ready
- Low-risk approach

**Expected Outcome**: 15-20% improvement over baseline (4.27 ‚Üí 3.8-4.0 MAE)

**Next Action**: Begin Phase 1 validation

**Estimated Value**:
- Better predictions = higher betting accuracy
- 15-20% improvement = significant edge
- Low execution risk
- Fast feedback cycle (3-5 hours total)

**Go/No-Go Decision**: ‚úÖ **GO** - All prerequisites met, high probability of success

---

**Created by**: Strategic Analysis (3 specialized agents)
**Date**: January 4, 2026
**Status**: Ready for execution
**Priority**: P0 - High impact, low risk
