# ü§ñ ML Training Status & Phase 4 Gap Explained

**Date**: 2026-01-03
**Status**: Comprehensive analysis complete
**Objective**: Answer 3 critical questions about ML training and pipeline

---

## üéØ YOUR THREE QUESTIONS ANSWERED

### 1Ô∏è‚É£ Why don't we have Phase 4 backfill for 2024-25 season?

**Answer**: Phase 4 orchestrator only runs for **live data**, NOT backfill.

**Current Status**:
- Phase 4 last processed: **Dec 28, 2025** (5 days ago)
- Coverage for 2024-25: **13.6%** (275 games out of 2,027)
- Missing: **Oct 22 - Nov 3, 2024** + **Dec 29 - Jan 2, 2026**

**How Phase 3‚Üí4 Works**:
```
Phase 3 completes ‚Üí Publishes to "nba-phase3-analytics-complete"
                   ‚Üì
Phase3‚Üí4 Orchestrator (Cloud Function)
  - Tracks completion in Firestore
  - Waits for all 5 Phase 3 processors
  - When complete ‚Üí Publishes to "nba-phase4-trigger"
                   ‚Üì
Phase 4 Processors run
```

**Why the gap exists**:
- ‚úÖ Orchestrator works for **daily live games**
- ‚ùå Orchestrator does **NOT** trigger for backfill dates
- Phase 3 backfill completed but never triggered Phase 4
- **Result**: Phase 4 only has data from daily scheduled runs (Dec 3-28)

**Solution**: Manual Phase 4 backfill needed (see Action Plan below)

---

### 2Ô∏è‚É£ How do we train ML models?

**Answer**: Training script exists and was **already run on Jan 2, 2026!**

**Training Script**: `/home/naji/code/nba-stats-scraper/ml/train_real_xgboost.py`

**Last Training Run (v3)**:
- **Date**: Jan 2, 2026
- **Model**: XGBoost with 25 features
- **Data**: 64,285 games (2021-11-06 to 2024-04-14)
- **Result**: ‚ùå **FAILED to beat mock baseline**
  - Mock MAE: **4.27 points**
  - v3 MAE: **4.63 points** (-8.4% worse)

**Training Data Source**:
The script uses **Phase 3 analytics**, NOT Phase 4 features:
```sql
FROM `nba-props-platform.nba_analytics.player_game_summary`
LEFT JOIN `nba-props-platform.nba_precompute.player_composite_factors`
LEFT JOIN `nba-props-platform.nba_precompute.team_defense_zone_analysis`
LEFT JOIN `nba-props-platform.nba_precompute.player_daily_cache`
```

**Good news**: Phase 3 has **100% coverage** for historical seasons!
- 2023-24: 1,318 games ‚úÖ
- 2022-23: 1,320 games ‚úÖ
- 2021-22: 1,292 games ‚úÖ

**You can train RIGHT NOW** - Phase 4 gap doesn't block ML training!

---

### 3Ô∏è‚É£ What are the next steps?

**Answer**: You have **3 strategic options** depending on your goal.

---

## üéØ OPTION 1: Re-train ML Model (QUICK WIN)

**Goal**: Try to beat the mock baseline (4.27 MAE)

**Steps**:
```bash
cd /home/naji/code/nba-stats-scraper

# Run training script (uses existing Phase 3 data)
PYTHONPATH=. python3 ml/train_real_xgboost.py
```

**Expected time**: 10-15 minutes

**What it does**:
1. Loads 64K+ games from BigQuery (Phase 3 analytics)
2. Trains XGBoost model with 25 features
3. Evaluates on test set (Feb-Apr 2024)
4. Saves model to `models/` directory
5. Prints MAE comparison to mock baseline

**Known issues from last run (Jan 2)**:
- ‚ö†Ô∏è 95% missing values for `minutes_avg_last_10` (filled with 0)
- ‚ö†Ô∏è Placeholders (4 features) filled with 0 (waste model capacity)
- ‚ö†Ô∏è Model couldn't learn complex non-linear rules from mock

**Recommended improvements** (if retrying):
1. Remove 4 placeholder features ‚Üí train with 21 real features
2. Fix `minutes_avg_last_10` missing data (use player avg, not 0)
3. Tune hyperparameters (increase depth, add early stopping)

**Expected outcome**: **4.40-4.55 MAE** (better, but likely still worse than mock)

---

## üéØ OPTION 2: Backfill Phase 4 for 2024-25 Season (OPTIONAL)

**Goal**: Get complete Phase 4 precompute features for current season

**Why you might want this**:
- Test predictions on recent games (validation)
- Get full feature set for 2024-25 season
- Completeness (Phase 4 = ML-ready features)

**Why you might NOT need this**:
- ‚úÖ Phase 3 has 100% historical coverage (sufficient for training)
- Training script already works with Phase 3 data
- Phase 4 gap is for recent dates, not training period

**How to backfill Phase 4**:

### Method A: Trigger orchestrator manually (UNTESTED)
```bash
# Publish message to Phase 4 trigger topic for each missing date
for date in 2024-10-22 2024-10-23 ... 2025-01-02; do
  gcloud pubsub topics publish nba-phase4-trigger \
    --message='{"game_date": "'$date'", "source": "manual_backfill"}' \
    --project=nba-props-platform
done
```

### Method B: Direct HTTP call to Phase 4 service (RECOMMENDED)
```bash
# Get auth token
TOKEN=$(gcloud auth print-identity-token)

# Process specific date
curl -X POST \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"game_date": "2024-11-01"}' \
  https://nba-phase4-precompute-processors-f7p3g7f6ya-wl.a.run.app/process
```

### Method C: Write a backfill script
```python
# backfill_phase4.py
import requests
import subprocess
from datetime import date, timedelta

# Get auth token
token = subprocess.check_output(['gcloud', 'auth', 'print-identity-token']).decode().strip()

# Date ranges to backfill
date_ranges = [
    (date(2024, 10, 22), date(2024, 11, 3)),  # Early season gap
    (date(2025, 12, 29), date(2026, 1, 2))    # Recent gap
]

url = "https://nba-phase4-precompute-processors-f7p3g7f6ya-wl.a.run.app/process"
headers = {
    "Authorization": f"Bearer {token}",
    "Content-Type": "application/json"
}

for start_date, end_date in date_ranges:
    current = start_date
    while current <= end_date:
        print(f"Processing {current}...")
        response = requests.post(url, json={"game_date": str(current)}, headers=headers)
        print(f"  Status: {response.status_code}")
        current += timedelta(days=1)
```

**Expected time**: 2-3 hours (depending on data volume)

**Impact**: Fill Phase 4 gap from 13.6% ‚Üí ~90% for 2024-25 season

---

## üéØ OPTION 3: Accept Mock Model & Focus Elsewhere (PRAGMATIC)

**Goal**: Stop trying to beat mock, focus on other improvements

**Rationale**:
- **3 training attempts** (v1, v2, v3) all failed to beat mock
- Mock baseline: **4.27 MAE** with hand-tuned rules
- Best ML model: **4.63 MAE** with 25 features (-8.4% worse)
- **Mock may be better** for this problem (domain expertise > ML)

**What this means**:
- ‚úÖ Keep using mock predictions in production
- ‚úÖ Focus effort on higher ROI improvements
- ‚è∏Ô∏è Revisit ML training later when conditions improve

**Better uses of time**:
1. **Data quality** - Fix missing values, improve feature engineering
2. **More data** - Collect more seasons (need 100K+ samples for ML)
3. **Better features** - Add referee data, travel data, etc.
4. **Pipeline reliability** - Monitor, alerts, self-healing
5. **Product features** - User interface, notifications, etc.

**When to revisit ML training**:
- [ ] More training data (>100K samples, currently 64K)
- [ ] Better features (referee, travel, injury severity)
- [ ] Advanced techniques (deep learning, ensembles)
- [ ] Fixed data quality issues (95% missing minutes_avg)

---

## üìä CURRENT DATA STATUS SUMMARY

### Phase 3 (Analytics) - ‚úÖ READY FOR ML TRAINING
| Season | Games | Coverage | Status |
|--------|-------|----------|--------|
| 2023-24 | 1,318 | 100% | ‚úÖ Complete |
| 2022-23 | 1,320 | 100% | ‚úÖ Complete |
| 2021-22 | 1,292 | 98.2% | ‚úÖ Complete |
| **Total** | **3,930** | **~100%** | **‚úÖ TRAIN NOW** |

### Phase 4 (Precompute) - ‚ö†Ô∏è HAS GAPS BUT NOT BLOCKING
| Season | Games | Coverage | Status |
|--------|-------|----------|--------|
| 2024-25 | 275 | 13.6% | ‚ö†Ô∏è Backfill needed (optional) |
| 2023-24 | 1,206 | 91.5% | ‚úÖ Complete |
| 2022-23 | 1,208 | 91.5% | ‚úÖ Complete |
| 2021-22 | 1,229 | 93.4% | ‚úÖ Complete |
| **Total** | **3,918** | **~92%** | **‚úÖ Training OK** |

**Key insight**: Phase 4 gaps are in 2024-25 (current season), NOT training period!

---

## üöÄ RECOMMENDED ACTION PLAN

### Immediate (TODAY)
Choose ONE:

**If goal = Beat mock baseline:**
1. ‚úÖ Review `ml/train_real_xgboost.py`
2. ‚úÖ Fix known issues (remove placeholders, fix missing data)
3. ‚úÖ Retrain and evaluate
4. ‚úÖ If MAE < 4.27, deploy to production

**If goal = Complete pipeline:**
1. ‚úÖ Write Phase 4 backfill script (Method C above)
2. ‚úÖ Run backfill for missing dates
3. ‚úÖ Validate coverage reaches 90%+

**If goal = Pragmatic progress:**
1. ‚úÖ Accept mock model is good enough (4.27 MAE)
2. ‚úÖ Focus on pipeline reliability
3. ‚úÖ Improve data quality
4. ‚úÖ Revisit ML later with more data

### Short-term (THIS WEEK)
- [ ] Document ML training process
- [ ] Add unit tests for training script
- [ ] Set up automated retraining pipeline
- [ ] Monitor prediction accuracy in production

### Long-term (THIS MONTH)
- [ ] Collect more historical data (2019-2021 seasons)
- [ ] Implement better features (referee, travel)
- [ ] Fix data quality issues (95% missing minutes)
- [ ] Explore advanced ML techniques (deep learning)

---

## üìÅ KEY FILES & RESOURCES

### ML Training
- **Training script**: `ml/train_real_xgboost.py`
- **Latest model**: `models/xgboost_real_v3_25features_20260102.json`
- **Training results**: `docs/09-handoff/2026-01-02-ML-V3-TRAINING-RESULTS.md`

### Phase 4 Orchestration
- **Orchestrator**: `orchestration/cloud_functions/phase3_to_phase4/main.py`
- **Deploy script**: `bin/orchestrators/deploy_phase3_to_phase4.sh`
- **Service URL**: `https://nba-phase4-precompute-processors-f7p3g7f6ya-wl.a.run.app`

### Data Quality
- **Investigation script**: `ml/run_data_quality_investigation.py`
- **Reports**: `ml/reports/`

---

## ‚úÖ BOTTOM LINE

### Your Questions Answered:

**Q1: Why no Phase 4 backfill for 2024-25?**
A: Orchestrator only runs for live data. Backfill completed Phase 3 but never triggered Phase 4.

**Q2: How do we train?**
A: `PYTHONPATH=. python3 ml/train_real_xgboost.py` (already exists, last run Jan 2)

**Q3: What are next steps?**
A: **Three options**:
1. **Re-train** to beat mock (fix issues, retrain, ~1 hour)
2. **Backfill Phase 4** for completeness (optional, ~2-3 hours)
3. **Accept mock** and focus elsewhere (pragmatic choice)

**Recommendation**: Option 3 (Accept mock for now)
- Mock is good (4.27 MAE)
- 3 ML attempts all failed to beat it
- Better to focus on data quality, more features, more data
- Revisit ML in 3-6 months with better conditions

**BUT** - if you want to try beating mock, data is ready! Just run the training script.

---

**Ready to proceed with any option - your choice!** üöÄ
