# Handoff Document: NBA Orchestration Fixes - Remaining Issues

**Date:** 2025-11-14
**Status:** Investigation Complete - 4 Fixes Needed
**Session:** Continuation of 2025-11-13 orchestration improvements
**Current State:** Scrapers service deployed, 4 failures identified

---

## Executive Summary

**What was accomplished:**
- âœ… Fixed 5 parameter resolution issues (event_ids, injury report, multi-team support)
- âœ… Fixed Pub/Sub schema mismatch (added 'name' field)
- âœ… Created enhanced error notification system
- âœ… Deployed scrapers service successfully
- âœ… Tested with live workflow (morning_operations)

**Current situation:**
- Deployment successful, multi-team support working (30 teams executed)
- Test workflow shows 30 successes, 4 failures
- Investigation identified 4 distinct root causes requiring fixes

**Time estimate to complete:** 30-45 minutes (fix + test + deploy)

---

## Investigation Results

### Test Workflow Execution (2025-11-14 04:05:06 UTC)

**Workflow:** morning_operations
**Execution ID:** b75262ce-0c56-49b9-a5e1-ce371ca4e62a
**Results:**
- 34 scrapers triggered (from 5 requested)
- 30 scrapers succeeded
- 4 scrapers failed

**Successful:**
- âœ… Multi-team support working (all 30 NBA teams executed for br_season_roster)
- âœ… nbac_schedule_api (no 'name' field errors)
- âœ… nbac_player_list
- âœ… 29 of 30 br_season_roster executions

**Failures identified via Cloud Run logs:**
1. bdl_standings - Missing season parameter
2. br_season_roster (PHX team) - Team abbreviation mismatch
3. nbac_schedule_api - Wrong season year (2026-27 instead of 2025-26)
4. Multiple scrapers - BigQuery opts field JSON conversion error

---

## Failure #1: bdl_standings - Missing Season Parameter

### Error Message:
```
ERROR: Missing required option [season].
DownloadDataException: Missing required option [season].
```

### Root Cause:
In `config/scraper_parameters.yaml`, we set `bdl_standings: {}` (empty dict) assuming it doesn't need parameters, but the scraper's `required_opts` includes `'season'`.

### Current Code:
**File:** `config/scraper_parameters.yaml:48`
```yaml
bdl_standings: {}  # No parameters needed
```

### Fix Required:
```yaml
bdl_standings:
  season: context.season_year  # Ball Don't Lie API uses 4-digit year
```

### Verification:
After fix, bdl_standings should receive `{"season": "2025"}` and succeed.

---

## Failure #2: br_season_roster - Team Abbreviation Mismatch

### Error Message:
```
ValueError: Invalid team abbreviation: PHX.
Must be one of: ['ATL', 'BOS', 'BRK', 'CHO', 'CHI', 'CLE', 'DAL', 'DEN', 'DET',
'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NOP', 'NYK',
'OKC', 'ORL', 'PHI', 'PHO', 'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS']
```

### Root Cause:
NBA uses "PHX" for Phoenix Suns, but Basketball Reference uses "PHO".
Similarly, NBA uses "BKN" for Brooklyn Nets, but Basketball Reference uses "BRK".

Our multi-team resolver uses `NBA_TEAMS` which has NBA abbreviations, but the scraper validates against Basketball Reference abbreviations.

### Current Code:
**File:** `orchestration/parameter_resolver.py:195-209`
```python
def _resolve_br_season_roster(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Returns list of parameter sets for all 30 NBA teams."""
    from shared.config.nba_teams import NBA_TEAMS

    season = context['season']
    ending_year = season.split('-')[1]
    full_ending_year = f"20{ending_year}"

    team_params = []
    for team in NBA_TEAMS:
        team_params.append({
            'teamAbbr': team['abbr'],  # Uses NBA abbreviation (PHX, BKN)
            'year': full_ending_year
        })

    return team_params
```

**File:** `scrapers/basketball_ref/br_season_roster.py:171` (validation logic)
```python
raise ValueError(error_msg)
```

### Fix Required:

Add team code mapping in `_resolve_br_season_roster()`:

```python
def _resolve_br_season_roster(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Returns list of parameter sets for all 30 NBA teams."""
    from shared.config.nba_teams import NBA_TEAMS

    # Basketball Reference uses different abbreviations for some teams
    NBA_TO_BR_TEAM_CODES = {
        'PHX': 'PHO',  # Phoenix Suns
        'BKN': 'BRK',  # Brooklyn Nets
        # All other teams use the same code
    }

    season = context['season']
    ending_year = season.split('-')[1]
    full_ending_year = f"20{ending_year}"

    team_params = []
    for team in NBA_TEAMS:
        nba_abbr = team['abbr']
        br_abbr = NBA_TO_BR_TEAM_CODES.get(nba_abbr, nba_abbr)

        team_params.append({
            'teamAbbr': br_abbr,  # Use Basketball Reference abbreviation
            'year': full_ending_year
        })

    return team_params
```

### Verification:
After fix, all 30 teams should succeed (PHXâ†’PHO, BKNâ†’BRK).

---

## Failure #3: Wrong Season Year (2026-27 Instead of 2025-26)

### Error Message:
```
WARNING: Season=2026-27
WARNING: ReadTimeoutError: stats.nba.com/stats/scheduleleaguev2int?Season=2026-27
```

### Root Cause:
Our `season_year` extraction logic uses the **ending year** of the NBA season instead of the **starting year**.

**Current date:** November 14, 2025
**Current NBA season:** 2025-26
**What we're requesting:** 2026-27 (doesn't exist yet!)

The issue is in how we extract `season_year` from the NBA season format.

### Current Code:
**File:** `orchestration/parameter_resolver.py:115-120`
```python
# Extract 4-digit ending year from season (e.g., "2025-26" -> "2026")
season_year = season.split('-')[1]  # "26"
full_season_year = f"20{season_year}"  # "2026"

context = {
    'workflow_name': workflow_name,
    'execution_date': execution_date,
    'season': season,  # NBA format: "2025-26"
    'season_year': full_season_year,  # 4-digit ending year: "2026"
```

**Problem:** Extracts "26" and converts to "2026", but some scrapers expect the **starting year** ("2025").

### Fix Required:

Change to extract **starting year** instead:

```python
# Extract 4-digit starting year from season (e.g., "2025-26" -> "2025")
season_start = season.split('-')[0]  # "2025"

context = {
    'workflow_name': workflow_name,
    'execution_date': execution_date,
    'season': season,  # NBA format: "2025-26"
    'season_year': season_start,  # 4-digit starting year: "2025"
```

**Alternative (if some scrapers need ending year):**
Provide both `season_start` and `season_end` in context:

```python
season_parts = season.split('-')
season_start = season_parts[0]  # "2025"
season_end = f"20{season_parts[1]}"  # "2026"

context = {
    'workflow_name': workflow_name,
    'execution_date': execution_date,
    'season': season,  # NBA format: "2025-26"
    'season_year': season_start,  # Default to starting year
    'season_start': season_start,  # Explicit starting year
    'season_end': season_end,  # Explicit ending year
```

### Files Using season_year:

1. **config/scraper_parameters.yaml:42**
   ```yaml
   nbac_schedule_api:
     season: context.season_year  # Currently gets "2026", needs "2025"
   ```

2. **orchestration/parameter_resolver.py:195-209** (br_season_roster)
   ```python
   full_ending_year = f"20{ending_year}"  # Should use season_end or context.season_year
   ```

### Verification:
After fix, nbac_schedule_api should request Season=2025-26 (not 2026-27).

---

## Failure #4: BigQuery opts Field JSON Conversion Error

### Error Message:
```
ERROR: Failed to insert rows into nba_orchestration.scraper_execution_log:
[{'index': 0, 'errors': [{'reason': 'invalid', 'location': 'opts',
'message': 'This field: opts is not a record.'}]}]
```

### Root Cause:
The BigQuery schema defines `opts` as a `JSON` field, but the scraper is sending it as a Python dict instead of a JSON string.

### Schema Definition:
**File:** `schemas/bigquery/nba_orchestration/scraper_execution_log.sql:215`
```sql
opts JSON,
  -- Scraper options used for this execution
```

### Current Code Location:
The error occurs when scrapers log to BigQuery. Need to find where `opts` is being inserted.

**Likely location:** `shared/utils/bigquery_utils.py` or `scrapers/scraper_base.py`

### Fix Required:

Find the BigQuery insert code and convert `opts` dict to JSON string:

```python
import json

# Before inserting into BigQuery
row = {
    'execution_id': execution_id,
    'scraper_name': scraper_name,
    # ... other fields ...
    'opts': json.dumps(opts) if isinstance(opts, dict) else opts,
    # ... other fields ...
}
```

### Investigation Steps:

1. Search for BigQuery insert code:
   ```bash
   grep -r "scraper_execution_log" scrapers/ shared/
   grep -r "insert_rows" shared/utils/bigquery_utils.py
   ```

2. Find where `opts` is being prepared for BigQuery

3. Add JSON conversion before insert

### Verification:
After fix, no more "This field: opts is not a record" errors in logs.

---

## Current Deployment State

### Services Deployed:
- âœ… **nba-scrapers** (revision: nba-scrapers-00075-mgr)
  - Includes orchestration code (bundled in scrapers service)
  - Deployed at: 2025-11-14 ~03:57 UTC
  - Duration: 3m 30s
  - Status: Running successfully

### Services NOT Deployed:
- âŒ **nba-processors** (enhanced error notifications not live yet)
  - Enhanced error notification system is implemented but not deployed
  - Current processors still using old error format
  - Optional: Can deploy after scraper fixes are complete

### Code Changes NOT Deployed Yet:
None - all code changes from previous session were deployed in nba-scrapers service.

### Code Changes Needed (Not Yet Implemented):
The 4 fixes listed above.

---

## Files Modified in Previous Session

### Successfully Deployed Changes:

1. **orchestration/parameter_resolver.py**
   - Added `season_year` to context (line 115-120) - NEEDS FIX (wrong year)
   - Added `_resolve_nbac_injury_report()` method - âœ… Working
   - Updated `_resolve_br_season_roster()` for multi-team - âœ… Working (needs team mapping fix)
   - Updated `_resolve_odds_props()` and `_resolve_odds_game_lines()` - âœ… Working

2. **orchestration/workflow_executor.py**
   - Added `data_summary` field to `ScraperExecution` dataclass - âœ… Working
   - Added multi-entity scraper support (list handling) - âœ… Working
   - Added event_id capture logic - âœ… Working
   - Added `_extract_event_ids_from_execution()` method - âœ… Working

3. **scrapers/utils/pubsub_utils.py**
   - Added 'name' field to Pub/Sub messages - âœ… Working (no more schema errors)

4. **scrapers/oddsapi/oddsa_events.py**
   - Updated `get_scraper_stats()` to include event_ids - âœ… Working

5. **config/scraper_parameters.yaml**
   - Updated nbac_schedule_api to use season_year - NEEDS FIX (wrong year)
   - Set bdl_standings to `{}` - NEEDS FIX (needs season parameter)

### Implemented But Not Deployed:

6. **shared/utils/enhanced_error_notifications.py** (NEW FILE)
   - Enhanced error notification system
   - Not live until processors service is deployed

7. **data_processors/raw/main_processor_service.py**
   - Integrated enhanced error notifications
   - Not live until processors service is deployed

---

## Next Steps (Prioritized)

### Step 1: Implement the 4 Fixes

**Priority: HIGH** - These prevent scrapers from working

1. **Fix bdl_standings parameter** (2 minutes)
   - File: `config/scraper_parameters.yaml:48`
   - Change: `bdl_standings: {}` â†’ `bdl_standings: {season: context.season_year}`

2. **Fix season_year extraction logic** (5 minutes)
   - File: `orchestration/parameter_resolver.py:115-120`
   - Change: Extract starting year instead of ending year
   - Option: Provide both season_start and season_end

3. **Add team code mapping for Basketball Reference** (5 minutes)
   - File: `orchestration/parameter_resolver.py:195-209`
   - Add: NBA_TO_BR_TEAM_CODES = {'PHX': 'PHO', 'BKN': 'BRK'}
   - Update: Use mapped abbreviation

4. **Fix BigQuery opts field JSON conversion** (10 minutes)
   - Find: BigQuery insert code in scrapers/scraper_base.py or shared/utils/bigquery_utils.py
   - Add: `json.dumps(opts)` conversion before insert

### Step 2: Test Locally (Optional)

Run verification script:
```bash
python bin/orchestration/verify_parameters.py
```

Expected results:
- âœ… PASS: 10+
- âš ï¸ WARNING: 8 (expected - benign)
- âŒ FAIL: 0
- ðŸ”¥ ERROR: 0

### Step 3: Deploy Scrapers Service

```bash
./bin/scrapers/deploy/deploy_scrapers_simple.sh
```

**Estimated time:** 10-15 minutes
**Service:** nba-scrapers (includes orchestration)

### Step 4: Test with Live Workflow

```bash
# Trigger morning_operations workflow
curl -X POST https://nba-scrapers-f7p3g7f6ya-wl.a.run.app/trigger-workflow \
  -H "Authorization: Bearer $(gcloud auth print-identity-token)" \
  -H "Content-Type: application/json" \
  -d '{"workflow_name": "morning_operations"}'
```

### Step 5: Verify Results

Query BigQuery to check results:
```bash
bq query --use_legacy_sql=false --format=json "
SELECT
  execution_id,
  workflow_name,
  status,
  scrapers_requested,
  scrapers_triggered,
  scrapers_succeeded,
  scrapers_failed
FROM \`nba-props-platform.nba_orchestration.workflow_executions\`
WHERE DATE(execution_time) = CURRENT_DATE()
ORDER BY execution_time DESC
LIMIT 1
"
```

**Expected results:**
- scrapers_failed: 0 (down from 4)
- scrapers_succeeded: 34 (up from 30)

### Step 6: Deploy Processors (Optional)

If you want enhanced error notifications:
```bash
./bin/raw/deploy/deploy_processors_simple.sh
```

**Estimated time:** 10-15 minutes
**Service:** nba-processors
**Benefit:** Enhanced error emails with stack traces and suggested fixes

---

## Quick Reference: File Locations

### Parameter Configuration:
- `config/scraper_parameters.yaml` - YAML parameter mappings

### Parameter Resolution:
- `orchestration/parameter_resolver.py` - Complex resolver functions
- `orchestration/workflow_executor.py` - Workflow execution logic

### Scrapers:
- `scrapers/scraper_base.py` - Base scraper class (likely has BigQuery insert)
- `scrapers/balldontlie/bdl_standings.py` - Ball Don't Lie standings scraper
- `scrapers/basketball_ref/br_season_roster.py` - Basketball Reference roster scraper
- `scrapers/nbacom/nbac_schedule_api.py` - NBA.com schedule scraper

### Utilities:
- `shared/utils/bigquery_utils.py` - BigQuery insert utilities
- `shared/config/nba_teams.py` - NBA team configurations
- `scrapers/utils/pubsub_utils.py` - Pub/Sub messaging

### Testing:
- `bin/orchestration/verify_parameters.py` - Parameter verification script

### Deployment:
- `bin/scrapers/deploy/deploy_scrapers_simple.sh` - Deploy scrapers service
- `bin/raw/deploy/deploy_processors_simple.sh` - Deploy processors service

### Documentation:
- `docs/orchestration/2025-11-13-parameter-fixes-summary.md` - Previous fixes
- `docs/orchestration/enhanced-error-notifications-summary.md` - Enhanced notifications
- `DEPLOYMENT_PLAN.md` - Deployment guide

---

## Context from Previous Session

### Original Issues Fixed:
1. âœ… Pub/Sub schema mismatch - Added 'name' field to messages
2. âœ… Event ID capture - oddsa_events includes event_ids in data_summary
3. âœ… Multi-team support - br_season_roster iterates all 30 teams
4. âœ… Injury report timing - Uses execution hour with 12-hour AM/PM format
5. âœ… Season format errors - Added season_year to context (but wrong year!)

### Enhanced Error Notification System:
- âœ… Implemented in shared/utils/enhanced_error_notifications.py
- âœ… Integrated in data_processors/raw/main_processor_service.py
- âœ… Tested with test_enhanced_notifications.py
- âŒ Not deployed yet (requires processors deployment)

**Features:**
- Stack traces
- Root cause analysis
- Suggested fixes for common errors
- 15-minute deduplication window
- Severity levels (CRITICAL, HIGH, MEDIUM, LOW)

---

## Known Issues and Warnings

### Expected Warnings (Not Errors):

1. **All-Star game team codes**
   - Teams: MEL, HAP, SEM, GUA
   - Status: Harmless warnings (All-Star exhibition teams)

2. **Empty event_ids warnings**
   - Scrapers: oddsa_player_props, oddsa_game_lines
   - Occurs when: No events available (off-season, no games today)
   - Status: Normal behavior

3. **Multi-entity warnings in verification script**
   - Shows "unexpected params" for game-specific scrapers
   - Status: Benign (verification script limitation)

### BigQuery Schema Notes:

**scraper_execution_log table fields:**
- `triggered_at` - Execution start time (NOT execution_time)
- `completed_at` - Execution end time
- `workflow` - Parent workflow name
- `status` - 'success', 'no_data', or 'failed'
- `opts` - JSON field (needs JSON string, not Python dict)
- `data_summary` - JSON field with scraper stats

**workflow_executions table fields:**
- `execution_id` - Workflow execution UUID
- `execution_time` - Workflow start time
- `status` - 'completed' or 'failed'
- `scrapers_requested` - Array of scraper names requested
- `scrapers_triggered` - Count of actual scraper executions
- `scrapers_succeeded` - Count of successes
- `scrapers_failed` - Count of failures

---

## Testing Queries

### Check latest workflow results:
```sql
SELECT
  execution_id,
  workflow_name,
  status,
  scrapers_requested,
  scrapers_triggered,
  scrapers_succeeded,
  scrapers_failed,
  execution_time
FROM `nba-props-platform.nba_orchestration.workflow_executions`
WHERE DATE(execution_time) = CURRENT_DATE()
ORDER BY execution_time DESC
LIMIT 5;
```

### Check scraper execution details:
```sql
SELECT
  scraper_name,
  workflow,
  status,
  error_type,
  error_message,
  JSON_VALUE(data_summary, '$.record_count') as record_count,
  triggered_at
FROM `nba-props-platform.nba_orchestration.scraper_execution_log`
WHERE triggered_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 MINUTE)
  AND status = 'failed'
ORDER BY triggered_at DESC;
```

### Check multi-team execution:
```sql
SELECT
  scraper_name,
  JSON_VALUE(opts, '$.teamAbbr') as team,
  status,
  triggered_at
FROM `nba-props-platform.nba_orchestration.scraper_execution_log`
WHERE scraper_name = 'basketball_ref_season_roster'
  AND DATE(triggered_at) = CURRENT_DATE()
ORDER BY team;
```

---

## Success Criteria

After implementing all 4 fixes and deploying:

âœ… **No scraper failures:**
- bdl_standings â†’ Success
- br_season_roster (all 30 teams) â†’ Success
- nbac_schedule_api â†’ Success (requesting correct season)
- All scrapers â†’ No BigQuery insert errors

âœ… **Correct season data:**
- nbac_schedule_api requests Season=2025-26 (not 2026-27)
- All scrapers use correct year for 2025-26 season

âœ… **All 30 NBA teams processed:**
- PHX â†’ Mapped to PHO (Phoenix)
- BKN â†’ Mapped to BRK (Brooklyn)
- All other teams â†’ Direct mapping

âœ… **Clean BigQuery logs:**
- No "This field: opts is not a record" errors
- All executions logged successfully

---

## Contact and Support

**Previous session summary:** DEPLOYMENT_PLAN.md
**Enhanced notifications docs:** docs/orchestration/enhanced-error-notifications-summary.md
**Parameter fixes summary:** docs/orchestration/2025-11-13-parameter-fixes-summary.md

**GCP Project:** nba-props-platform
**Region:** us-west2

**Services:**
- nba-scrapers: https://nba-scrapers-f7p3g7f6ya-wl.a.run.app
- nba-processors: https://nba-processors-[hash].run.app (not updated yet)
- nba-orchestration-service: (bundled in nba-scrapers)

---

## Estimated Timeline

**Total time to complete all fixes:** 30-45 minutes

- Implement 4 fixes: 15-20 minutes
- Deploy scrapers service: 10-15 minutes
- Test workflow: 2-5 minutes
- Verify results: 5 minutes
- Optional: Deploy processors: 10-15 minutes

**Current blockers:** None - all issues identified, fixes are straightforward

**Risk level:** Low - All fixes are well-understood and backwards compatible

---

**Last Updated:** 2025-11-14 04:30 UTC
**Status:** Ready for implementation
**Deployment:** Scrapers service (nba-scrapers-00075-mgr) running in production with known issues
**Next Action:** Implement the 4 fixes and redeploy

---

## Appendix: Cloud Run Log Excerpts

### bdl_standings Error:
```
ERROR:shared.utils.notification_system:[PROCESSING_ERROR] Scraper Configuration Error:
BdlStandingsScraper: Missing required option: season
```

### br_season_roster Error (PHX team):
```
ValueError: Invalid team abbreviation: PHX.
Must be one of: ['ATL', 'BOS', 'BRK', 'CHO', 'CHI', 'CLE', 'DAL', 'DEN', 'DET',
'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NOP', 'NYK',
'OKC', 'ORL', 'PHI', 'PHO', 'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS']
```

### Wrong Season Error:
```
WARNING:urllib3.connectionpool:Retrying after connection broken by
'ReadTimeoutError': /stats/scheduleleaguev2int?Season=2026-27
```

### BigQuery opts Error:
```
ERROR:shared.utils.bigquery_utils:Failed to insert rows into
nba_orchestration.scraper_execution_log:
[{'index': 0, 'errors': [{'reason': 'invalid', 'location': 'opts',
'message': 'This field: opts is not a record.'}]}]
```

---

**End of Handoff Document**
