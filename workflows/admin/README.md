# Administrative Workflows

**System maintenance, monitoring, and utility workflows that support the overall health and operation of the NBA data platform.**

## Purpose

Administrative workflows handle platform-wide concerns that span across operational and backfill activities:
- System health monitoring and alerting
- Data quality validation across all data sources
- Infrastructure maintenance and cleanup
- Performance optimization and resource management

## Planned Workflows

### System Health & Monitoring
- **`system-health-check.yaml`** ðŸ”„ **PLANNED**
  - Overall platform health validation
  - API connectivity checks (Ball Don't Lie, Odds API, NBA.com)
  - GCS storage health and accessibility
  - Cloud Run service status verification
  - **Schedule**: Hourly during active periods

- **`monitoring-dashboard-update.yaml`** ðŸ”„ **PLANNED**  
  - Update monitoring dashboards with latest metrics
  - Generate system performance reports
  - Update alerting thresholds based on historical patterns
  - **Schedule**: Daily during maintenance windows

### Data Quality & Validation
- **`data-quality-validation.yaml`** ðŸ”„ **PLANNED**
  - Cross-source data consistency checks
  - Detect anomalies in player statistics  
  - Validate prop betting data completeness
  - Generate data quality scorecards
  - **Schedule**: Daily after operational workflows complete

- **`cross-reference-validation.yaml`** ðŸ”„ **PLANNED**
  - Validate player names across all data sources
  - Check team assignments consistency  
  - Detect missing games or player data
  - **Triggers**: After major data collection events

### Maintenance & Cleanup
- **`cleanup-old-data.yaml`** ðŸ”„ **PLANNED**
  - Remove temporary files and test data
  - Archive old logs and debug files
  - Clean up failed workflow artifacts
  - **Schedule**: Weekly maintenance windows

- **`storage-optimization.yaml`** ðŸ”„ **PLANNED**
  - Optimize GCS storage organization
  - Compress old data files
  - Move infrequently accessed data to cheaper storage classes
  - **Schedule**: Monthly

### Infrastructure Management  
- **`api-usage-monitoring.yaml`** ðŸ”„ **PLANNED**
  - Track API usage against rate limits
  - Generate API cost reports
  - Alert on approaching usage thresholds
  - **Schedule**: Daily

- **`backup-critical-configs.yaml`** ðŸ”„ **PLANNED**
  - Backup Cloud Run configurations
  - Export workflow definitions
  - Archive deployment scripts and infrastructure code
  - **Schedule**: Weekly

## Execution Patterns

### Scheduled Maintenance
```bash
# Deploy admin workflows
./bin/deployment/deploy_workflows.sh workflows/admin/

# Schedule health checks  
gcloud scheduler jobs create http system-health-check \
  --schedule="0 */4 * * *" \
  --uri="https://workflowexecutions.googleapis.com/v1/projects/PROJECT/locations/REGION/workflows/system-health-check/executions"
```

### Manual Execution
```bash
# Run data quality validation on demand
gcloud workflows run data-quality-validation --location=us-west2

# Execute cleanup during maintenance windows
gcloud workflows run cleanup-old-data --location=us-west2
```

### Emergency Response
```bash
# Quick system health check during incidents
gcloud workflows run system-health-check --location=us-west2

# Validate data integrity after system recovery
gcloud workflows run cross-reference-validation --location=us-west2
```

## Integration Points

### With Operational Workflows
- Monitor operational workflow success rates
- Validate data quality from daily collections
- Alert on operational failures or anomalies

### With Backfill Workflows  
- Validate historical data quality during backfill
- Monitor backfill progress and performance
- Cleanup temporary backfill artifacts

### With External Systems
- **Sentry**: Error tracking and alerting integration
- **Google Cloud Monitoring**: Metrics collection and dashboards
- **Slack**: Notification and alerting channels
- **BigQuery**: Data quality metrics storage

## Development Priority

### Phase 1: Essential Monitoring
1. `system-health-check.yaml` - Basic platform health
2. `data-quality-validation.yaml` - Core data integrity  

### Phase 2: Operational Excellence
3. `cleanup-old-data.yaml` - Resource management
4. `api-usage-monitoring.yaml` - Cost control

### Phase 3: Advanced Management
5. `monitoring-dashboard-update.yaml` - Enhanced observability
6. `storage-optimization.yaml` - Cost optimization

## Design Principles

- **Non-Disruptive**: Admin workflows should never interfere with operational or backfill processes
- **Self-Healing**: Workflows should attempt automatic recovery where possible
- **Comprehensive Logging**: Detailed logs for troubleshooting and audit trails
- **Configurable Thresholds**: Alert thresholds and validation rules should be easily configurable
- **Emergency Ready**: Critical workflows should be ready for immediate execution during incidents

## Success Metrics

- **System Uptime**: >99.5% availability of critical data collection workflows
- **Data Quality**: >95% data consistency across all sources  
- **Cost Management**: API usage within budget thresholds
- **Alert Accuracy**: <5% false positive rate on monitoring alerts
- **Recovery Time**: <15 minutes to detect and begin recovery from system issues