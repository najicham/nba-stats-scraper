# workflows/late-night-recovery.yaml
# NBA Late Night Recovery Workflow - Enhanced PBP collection + core game data recovery
# Runs daily at 2 AM PT to collect Enhanced PBP (available 2+ hours after games)
# Streamlined to focus on core recovery needs only
# VERSION: 2.0 - Updated to match optimized workflow reference

main:
  params: [args]
  steps:
    - init:
        assign:
          - current_timestamp: ${sys.now()}
          - workflow_start: ${sys.now()}
          - execution_id: ${sys.get_env("GOOGLE_CLOUD_WORKFLOW_EXECUTION_ID")}

    - log_workflow_start:
        call: sys.log
        args:
          text: "Starting NBA Late Night Recovery Workflow"
          severity: INFO

    # PHASE 1: Enhanced Play-by-Play Collection (BigDataBall + NBA.com backup)
    - enhanced_pbp_collection:
        try:
          parallel:
            exception_policy: continueAll
            branches:
              - bigdataball_pbp:
                  steps:
                    - call_bigdataball_pbp:
                        call: run_scraper
                        args:
                          scraper_name: "bigdataball-pbp"
                          scraper_class: "BigDataBallPbpScraper"
                          endpoint: "bigdataball_pbp"
                          timeout: 600
                          critical: false
                        result: bigdataball_pbp_result

              - nbacom_pbp_backup:
                  steps:
                    - call_nbacom_pbp:
                        call: run_scraper
                        args:
                          scraper_name: "nbacom-pbp-backup"
                          scraper_class: "GetNbaComPlayByPlay"
                          endpoint: "nbac_play_by_play"
                          timeout: 600
                          critical: false
                        result: nbacom_pbp_result
        except:
          as: e
          steps:
            - log_pbp_error:
                call: sys.log
                args:
                  text: "Enhanced PBP collection had errors - will retry at 5AM"
                  severity: WARNING

    # PHASE 2: Core Game Data Recovery
    - core_game_data_recovery:
        try:
          steps:
            - call_bdl_box_scores:
                call: run_scraper
                args:
                  scraper_name: "bdl-box-scores-recovery"
                  scraper_class: "BdlBoxScoresScraper"
                  endpoint: "bdl_box_scores"
                  timeout: 600
                  critical: false
                result: bdl_box_scores_result
        except:
          as: e
          steps:
            - log_core_game_error:
                call: sys.log
                args:
                  text: "Core game data recovery had errors - non-critical"
                  severity: WARNING
            - assign_core_game_failure:
                assign:
                  - bdl_box_scores_result:
                      status: "failure"
                      error: ${e.message}
                      scraper_name: "bdl-box-scores-recovery"
                      timestamp: ${sys.now()}

    # SUCCESS PATH
    - workflow_success:
        assign:
          - workflow_end: ${sys.now()}
          - total_duration: ${workflow_end - workflow_start}

    - write_status_success:
        call: write_status_to_gcs
        args:
          workflow_name: "late-night-recovery"
          execution_id: ${execution_id}
          execution_time: ${current_timestamp}
          workflow_start: ${workflow_start}
          total_duration: ${total_duration}
          scrapers:
            bigdataball_pbp: ${bigdataball_pbp_result}
            nbac_play_by_play: ${nbacom_pbp_result}
            bdl_box_scores: ${bdl_box_scores_result}
          dependencies: {}
          recovery_strategy: "Streamlined recovery - core data only (2 AM PT)"
          status: "SUCCESS"

    - log_workflow_success:
        call: sys.log
        args:
          text: "NBA Late Night Recovery Workflow completed successfully"
          severity: INFO

    - return_success:
        return:
          status: "SUCCESS"
          message: "Late night recovery completed successfully"
          duration_seconds: ${total_duration}
          bigdataball_pbp_status: ${bigdataball_pbp_result.status}
          nbacom_pbp_backup_status: ${nbacom_pbp_result.status}
          core_game_recovery_attempted: true
          recovery_window: "late_night_2am"
          timestamp: ${current_timestamp}

# Reusable subworkflow for running individual scrapers
run_scraper:
  params: [scraper_name, scraper_class, endpoint, timeout, critical]
  steps:
    - log_start:
        call: sys.log
        args:
          text: "Starting scraper"
          severity: INFO

    - call_scraper:
        try:
          call: http.post
          args:
            url: "https://nba-scrapers-756957797294.us-west2.run.app/scrape"
            query:
              scraper: ${endpoint}
            timeout: ${timeout}
            headers:
              Content-Type: "application/json"
          result: scraper_response
        except:
          as: e
          steps:
            - log_failure:
                call: sys.log
                args:
                  text: "Scraper failed"
                  severity: ERROR
            - return_failure:
                return:
                  status: "failure"
                  scraper_name: ${scraper_name}
                  error: ${e.message}
                  timestamp: ${sys.now()}

    - check_response:
        switch:
          - condition: ${scraper_response.code >= 200 AND scraper_response.code < 300}
            next: log_success
          - condition: true
            next: return_http_failure

    - return_http_failure:
        return:
          status: "failure"
          scraper_name: ${scraper_name}
          http_code: ${scraper_response.code}
          timestamp: ${sys.now()}

    - log_success:
        call: sys.log
        args:
          text: "Scraper completed successfully"
          severity: INFO

    - return_success:
        return:
          status: "success"
          scraper_name: ${scraper_name}
          http_code: ${scraper_response.code}
          timestamp: ${sys.now()}

# Subworkflow for writing status to GCS
write_status_to_gcs:
  params: [workflow_name, execution_id, execution_time, workflow_start, scrapers, status, total_duration, dependencies, recovery_strategy]
  steps:
    - calculate_duration:
        assign:
          - actual_duration: ${default(total_duration, sys.now() - workflow_start)}
          - current_time: ${sys.now()}
          - date_string: ${text.split(text.split(string(current_time), "T")[0], "-")}
          - year: ${date_string[0]}
          - month: ${date_string[1]} 
          - day: ${date_string[2]}
          - hour_min: ${text.replace_all(text.split(string(current_time), "T")[1], ":", "h")}
          - time_part: ${text.split(hour_min, ".")[0]}

    - build_status_object:
        assign:
          - status_data:
              workflow: ${workflow_name}
              execution_id: ${execution_id}
              execution_time: ${execution_time}
              total_duration: ${actual_duration}
              status: ${status}
              scrapers: ${scrapers}
              dependencies: ${default(dependencies, null)}
              recovery_strategy: ${default(recovery_strategy, "Standard execution")}

    - create_gcs_path:
        assign:
          - bucket_name: "nba-props-status"
          - file_path: ${"workflow-status/" + year + "-" + month + "-" + day + "/" + workflow_name + "-" + time_part + ".json"}
          - gcs_url: ${"gs://" + bucket_name + "/" + file_path}

    - write_to_gcs:
        try:
          call: http.post
          args:
            url: ${"https://storage.googleapis.com/upload/storage/v1/b/" + bucket_name + "/o"}
            query:
              uploadType: "media"
              name: ${file_path}
            headers:
              Content-Type: "application/json"
              Authorization: ${"Bearer " + sys.get_env("GOOGLE_CLOUD_ACCESS_TOKEN")}
            body: ${json.encode(status_data)}
        except:
          as: e
          steps:
            - log_gcs_failure:
                call: sys.log
                args:
                  text: "Failed to write status to GCS"
                  severity: WARNING

    - log_status_written:
        call: sys.log
        args:
          text: ${gcs_url}
          severity: INFO