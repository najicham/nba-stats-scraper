# workflows/post-game-analysis.yaml
# NBA Post-Game Analysis Workflow - Deep game analysis and historical data
# Runs daily at 9 PM PT to capture completed games and detailed stats
# Focuses on comprehensive boxscores, player stats, and historical analysis

main:
  params: [args]
  steps:
    - init:
        assign:
          - current_timestamp: ${sys.now()}
          - workflow_start: ${sys.now()}

    - log_workflow_start:
        call: sys.log
        args:
          text: "Starting NBA Post-Game Analysis Workflow"
          severity: INFO

    # PHASE 1: Final scoreboards and game completion status
    - final_game_status:
        try:
          parallel:
            exception_policy: continueAll
            branches:
              - final_scoreboards:
                  steps:
                    - call_espn_scoreboard:
                        call: run_scraper
                        args:
                          scraper_name: "espn-scoreboard"
                          scraper_class: "EspnScoreboardApiScraper"
                          endpoint: "espn_scoreboard_api"
                          timeout: 300
                          critical: true
                        result: espn_scoreboard_result

              - nba_final_scores:
                  steps:
                    - call_nba_scoreboard:
                        call: run_scraper
                        args:
                          scraper_name: "nba-scoreboard"
                          scraper_class: "GetNbaComScoreboardV2"
                          endpoint: "nbac_scoreboard_v2"
                          timeout: 300
                          critical: true
                        result: nba_scoreboard_result
        except:
          as: e
          steps:
            - log_scoreboard_error:
                call: sys.log
                args:
                  text: "Final scoreboard collection had errors"
                  severity: WARNING

    # PHASE 2: Detailed player and game statistics
    - detailed_statistics:
        try:
          parallel:
            exception_policy: continueAll
            branches:
              - ball_dont_lie_stats:
                  steps:
                    - call_bdl_box_scores:
                        call: run_scraper
                        args:
                          scraper_name: "bdl-box-scores"
                          scraper_class: "BdlBoxScoresScraper"
                          endpoint: "bdl_box_scores"
                          timeout: 600
                          critical: false
                        result: bdl_box_scores_result

              - bdl_player_stats:
                  steps:
                    - call_bdl_player_box_scores:
                        call: run_scraper
                        args:
                          scraper_name: "bdl-player-box-scores"
                          scraper_class: "BdlPlayerBoxScoresScraper"
                          endpoint: "bdl_player_box_scores"
                          timeout: 600
                          critical: false
                        result: bdl_player_box_result

              - espn_detailed_boxscores:
                  steps:
                    - call_espn_game_boxscore:
                        call: run_scraper
                        args:
                          scraper_name: "espn-game-boxscore"
                          scraper_class: "EspnGameBoxscoreApiScraper"
                          endpoint: "espn_game_boxscore"
                          timeout: 600
                          critical: false
                        result: espn_boxscore_result
        except:
          as: e
          steps:
            - log_stats_error:
                call: sys.log
                args:
                  text: "Detailed statistics collection had errors"
                  severity: WARNING

    # PHASE 3: Historical and advanced analytics (if available)
    - advanced_analytics:
        try:
          parallel:
            exception_policy: continueAll
            branches:
              - player_averages:
                  steps:
                    - call_bdl_player_averages:
                        call: run_scraper
                        args:
                          scraper_name: "bdl-player-averages"
                          scraper_class: "BdlPlayerAveragesScraper"
                          endpoint: "bdl_player_averages"
                          timeout: 300
                          critical: false
                        result: bdl_averages_result

              - game_advanced_stats:
                  steps:
                    - call_bdl_game_adv_stats:
                        call: run_scraper
                        args:
                          scraper_name: "bdl-game-adv-stats"
                          scraper_class: "BdlGameAdvStatsScraper"
                          endpoint: "bdl_game_adv_stats"
                          timeout: 300
                          critical: false
                        result: bdl_adv_stats_result

              - pbp_enhanced_stats:
                  steps:
                    - call_pbp_enhanced:
                        call: run_scraper
                        args:
                          scraper_name: "pbp-enhanced-pbp"
                          scraper_class: "PbpStatsEnhancedPbpScraper"
                          endpoint: "pbp_enhanced_pbp"
                          timeout: 600
                          critical: false
                        result: pbp_enhanced_result
        except:
          as: e
          steps:
            - log_analytics_error:
                call: sys.log
                args:
                  text: "Advanced analytics collection had errors"
                  severity: WARNING

    # PHASE 4: Injury and roster updates (end of day)
    - end_of_day_updates:
        try:
          parallel:
            exception_policy: continueAll
            branches:
              - injury_updates:
                  steps:
                    - call_injury_report:
                        call: run_scraper
                        args:
                          scraper_name: "nba-injury-report"
                          scraper_class: "GetNbaComInjuryReport"
                          endpoint: "nbac_injury_report"
                          timeout: 300
                          critical: false
                        result: injury_result

              - player_movement:
                  steps:
                    - call_player_movement:
                        call: run_scraper
                        args:
                          scraper_name: "nba-player-movement"
                          scraper_class: "GetNbaComPlayerMovement"
                          endpoint: "nbac_player_movement"
                          timeout: 300
                          critical: false
                        result: movement_result
        except:
          as: e
          steps:
            - log_updates_error:
                call: sys.log
                args:
                  text: "End of day updates had errors"
                  severity: WARNING

    # SUCCESS PATH
    - workflow_success:
        assign:
          - workflow_end: ${sys.now()}
          - total_duration: ${workflow_end - workflow_start}

    - log_workflow_success:
        call: sys.log
        args:
          text: "NBA Post-Game Analysis Workflow completed successfully"
          severity: INFO

    - return_success:
        return:
          status: "SUCCESS"
          message: "Post-game analysis completed successfully"
          duration_seconds: ${total_duration}
          scoreboards_attempted: true
          statistics_collected: true
          advanced_analytics_attempted: true
          timestamp: ${current_timestamp}

# Reusable subworkflow for running individual scrapers
run_scraper:
  params: [scraper_name, scraper_class, endpoint, timeout, critical]
  steps:
    - log_start:
        call: sys.log
        args:
          text: "Starting scraper"
          severity: INFO

    - call_scraper:
        try:
          call: http.post
          args:
            url: "https://nba-scrapers-756957797294.us-west2.run.app/scrape"
            query:
              scraper: ${endpoint}
            timeout: ${timeout}
            headers:
              Content-Type: "application/json"
          result: scraper_response
        except:
          as: e
          steps:
            - log_failure:
                call: sys.log
                args:
                  text: "Scraper failed"
                  severity: ERROR
            - return_failure:
                return:
                  status: "failure"
                  scraper_name: ${scraper_name}
                  error: ${e.message}
                  timestamp: ${sys.now()}

    - check_response:
        switch:
          - condition: ${scraper_response.code >= 200 AND scraper_response.code < 300}
            next: log_success
          - condition: true
            next: return_http_failure

    - return_http_failure:
        return:
          status: "failure"
          scraper_name: ${scraper_name}
          http_code: ${scraper_response.code}
          timestamp: ${sys.now()}

    - log_success:
        call: sys.log
        args:
          text: "Scraper completed successfully"
          severity: INFO

    - return_success:
        return:
          status: "success"
          scraper_name: ${scraper_name}
          http_code: ${scraper_response.code}
          timestamp: ${sys.now()}
          